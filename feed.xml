<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://blog.ivanukhov.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://blog.ivanukhov.com/" rel="alternate" type="text/html" /><updated>2025-07-30T16:51:16+00:00</updated><id>https://blog.ivanukhov.com/feed.xml</id><title type="html">Good news, everyone!</title><subtitle>Solving problems that a software engineer might encounter in practice—or invent to sharpen their skills in leisure time
</subtitle><author><name>Ivan Ukhov</name><email>ivan.ukhov@gmail.com</email></author><entry><title type="html">Building guardrails with Bayesian statistics</title><link href="https://blog.ivanukhov.com/2025/07/30/guardrails.html" rel="alternate" type="text/html" title="Building guardrails with Bayesian statistics" /><published>2025-07-30T07:00:00+00:00</published><updated>2025-07-30T07:00:00+00:00</updated><id>https://blog.ivanukhov.com/2025/07/30/guardrails</id><content type="html" xml:base="https://blog.ivanukhov.com/2025/07/30/guardrails.html"><![CDATA[<p>Suppose you run several online stores, and their number keeps growing. It is
becoming increasingly difficult to monitor the performance of any given store,
simply because there are too many of them. There is a fair chance that something
unexpected will happen, and that it will have a negative impact on either the
website traffic or the conversion rate, that is, purchases—without you realizing
it. To keep your hand on the pulse, you decide to put guardrails in place, which
will inform you if something goes wrong. In this article, we shall take a look
at how to build such guardrails using Bayesian statistics.</p>

<h1 id="problem">Problem</h1>

<p>Let \(n\) be the number of stores and \(m\) be the number of weekly
observations. A weekly observation is a tuple \((i_j, t_j, x_j, y_j)\), for \(j
\in \{1, \dots, m\}\), where \(i_j \in \{1, \dots, n\}\) is the index of the
store observed, \(t_j \in \mathbb{N}_+\) is the index of the week of
observation, \(x_j \in \mathbb{N}\) is the total number of sessions that week,
and \(y_j \leq x_j\) is the number of sessions that resulted in at least one
purchase. With this notation, the conversion rate for store \(i_j\) and week
\(t_j\) is given by \(p_j = y_j / x_j\) provided that \(x_j &gt; 0\).</p>

<p>Note that there is no requirement on the alignment of observations across the
stores and the continuity of observation within a given store: different stores
might be observed on different weeks, and there might be weeks missing between
the first and the last observation of a store.</p>

<p>Given \(\{(i_j, t_j, x_j, y_j)\}_{j = 1}^m\), the goal is to find a threshold
for the number of sessions, denoted by \(\hat{x}_i\), and a threshold for the
conversion rate, denoted by \(\hat{p}_i\), so that whenever \(x_k \geq
\hat{x}_i\) and \(p_k \geq \hat{p}_i\) for an unseen week \(t_k\), the
performance of store \(i \in \{1, \dots, n\}\) is considered usual, uneventful.
Conversely, when either metric falls below the corresponding guardrail, the
situation is considered concerning enough to perform a closer investigation of
the performance of the corresponding store.</p>

<p>The problem can be classified as anomaly detection. The topic is well studied,
and there are many approaches to this end. Here we shall look at it from a
Bayesian perspective.</p>

<h1 id="solution">Solution</h1>

<p>The idea is to build a statistical model and fit it to the data. In Bayesian
inference, it means that there will be a fully fledged probability distribution
available in the end, providing an exhaustive description of the situation at
hand. This distribution can then be used to estimate a wide range of quantities
of interest. In particular, one can choose an appropriate quantile on the left
tail of the distribution and use it as a guardrail. If an upper bound is
required, one can do the same with respect to the right tail.</p>

<p>Let us start with the modeling, and we will then come back to the inference. To
begin with, we need to acknowledge the fact that the number of sessions \(x_j\),
which is a count, is very different from the conversion rate \(p_j\), which is a
proportion. Hence, one would need to build two different models. In addition, we
shall ignore the information about which week each observation belongs to, that
is, \(\{ t_j \}_{j = 1}^m\), and come back to and motivate this choice in the
conclusion.</p>

<h2 id="modeling-number-of-sessions">Modeling: Number of sessions</h2>

<p>Even though the number of sessions is a natural number, it is commonplace to
model it as a real number. One could, for instance, use a Gaussian distribution
to this end. However, to respect the fact that it cannot be negative, we shall
use a log-Gaussian distribution instead, which is even more adequate if the
popularity of the stores taken collectively spans multiple orders of magnitude:</p>

\[x_j | \mu_{i_j}, \sigma_{i_j} \sim \text{Log-Gaussian}(\mu_{i_j}, \sigma_{i_j}) \tag{1}\]

<p>where \(\mu_{i_j}\) and \(\sigma_{i_j}\) are the location and scale for store
\(i_j\). The above is the likelihood of the data. To complete the model, one has
to specify priors for the two parameters. For each one, we will use a linear
combination of a global and a store-specific component. For the location
parameter, it is just that:</p>

\[\mu_{i_j} = \mu_\text{global} + \mu_{\text{local}, i_j}. \tag{2}\]

<p>For the scale parameter, which is positive, we also apply a nonlinear
transformation on top of the linear combination to ensure the end result stays
positive:</p>

\[\sigma_{i_j} = \text{softplus}(\sigma_\text{global} + \sigma_{\text{local}, i_j}) \tag{3}\]

<p>where \(\text{softplus}(x) = \ln(1 + \text{exp}(x))\). Technically, it can be
zero if \(\sigma_\text{global} + \sigma_{\text{local}, i_j}\) goes to
\(-\infty\), but it is not a concern in practice, as we shall see when we come
to the implementation.</p>

<p>With this reparameterization, there are \(2n + 2\) parameters in the model. We
shall put a Gaussian prior on each one as follows:</p>

\[\begin{align}
\mu_\text{global} &amp; \sim \text{Gaussian}(\mu_0, 1), \tag{4} \\
\mu_{\text{local}, i_j} &amp; \sim \text{Gaussian}(0, 1), \tag{5} \\
\sigma_\text{global} &amp; \sim \text{Gaussian}(\sigma_0, 1), \text{ and} \tag{6} \\
\sigma_{\text{local}, i_j} &amp; \sim \text{Gaussian}(0, 1). \tag{7}
\end{align}\]

<p>It can be seen that the local ones are standard Gaussian, while the global ones
have the mean set to non-zero values (to be discussed shortly), with the
standard deviation set to one still. Since we work on a logarithmic scale due to
the usage of a log-Gaussian distribution in Equation 1, this standard
parameterization should be adequate for websites having a number of sessions per
week that is below a few thousand provided that the global distributions are
centered appropriately via \(\mu_0\) and \(\sigma_0\).</p>

<p>In the above formulation, there are only two hyperparameters, which require
custom values: \(\mu_0\) and \(\sigma_0\). To get a bit of intuition for what
they control, it is helpful to temporarily set the local parameters (Equations 5
and 7) to zero. Then \(\mu_{i_j}\) simplifies to \(\mu_\text{global}\) and
\(\sigma_{i_j}\) to \(\text{softplus}(\sigma_\text{global})\). Furthermore,
\(\text{softplus}\) can be dropped, since the corresponding non-linearity
manifest itself only close to zero. Hence, \(\mu_\text{global}\) and
\(\sigma_\text{global}\) can simply be thought of as the location and scale
parameters of the log-Gaussian distribution in Equation 1. With this in mind,
they can be used to control the distribution’s shape, that is, our prior
assumptions about the number of weekly sessions.</p>

<p>That does not quite help with the intuition still, as the location and scale
parameters of a log-Gaussian distribution are <em>not</em> its mean and standard
deviation, which would have been more familiar concepts to work with. However,
it is possible to derive the location and scale parameters given a mean and a
standard deviation one has in mind. More specifically, they are as follows:</p>

\[\begin{align}
\text{location} &amp; = \ln(\text{mean}) - \frac{1}{2} \ln\left( 1 + \left( \frac{\text{deviation}}{\text{mean}} \right)^2 \right) \text{ and} \\
\text{scale} &amp; = \sqrt{\ln\left( 1 + \left(\frac{\text{deviation}}{\text{mean}}\right)^2 \right)}.
\end{align}\]

<p>Bringing \(\text{softplus}\) back into the picture, we obtain the following for
the hyperparameters:</p>

\[\begin{align}
\mu_0 &amp; = \ln(\text{mean}) - \frac{1}{2} \ln\left( 1 + \left( \frac{\text{deviation}}{\text{mean}} \right)^2 \right) \text{ and} \\
\sigma_0 &amp; = \text{softplus}^{-1} \left( \sqrt{\ln\left( 1 + \left(\frac{\text{deviation}}{\text{mean}}\right)^2 \right)} \right)
\end{align}\]

<p>where \(\text{softplus}^{-1}(x) = \ln(\text{exp}(x) - 1)\). The end result is
that we can think of a mean and a standard deviation for the situation at hand,
and it would be enough to complete the model.</p>

<p>It is always a good idea to perform a prior predictive check, which can be done
by sampling from the prior distribution and performing a kernel density
estimation. For instance, assuming a mean and a standard deviation of 500 and
setting the local variable to zero for simplicity, we obtain the following prior
probability density:</p>

<p><img src="/assets/images/2025-07-30-guardrails/sessions-prior-1.svg" alt="" /></p>

<p>It can be seen that it covers well the area that we hypothesize to be plausible.
The distribution also has a very long tail, which is truncated here, allowing
for the number of sessions to be untypically large.</p>

<p>To recapitulate, the number of sessions is modeled according to Equation 1 where
the location and scale parameters are given by Equation 2 and 3, respectively,
with the priors set as in Equations 4–7 and the two hyperparameters set based on
prior expectations for the mean and standard deviation according to Equation 8
and 9, respectively.</p>

<h2 id="modeling-conversion-rate">Modeling: Conversion rate</h2>

<p>The conversion rate is a proportion, that is, a real number between zero and
one, which is obtained by dividing the number of purchases by the number of
sessions: \(p_j = y_j / x_j\). Since we have the constituents at our disposal,
it makes sense to model it using a binomial distribution:</p>

\[y_j | \alpha_{i_j} \sim \text{Binomial}(x_j, \alpha_{i_j}) \tag{8}.\]

<p>In this framework, one thinks of \(x_j\) and \(y_j\) as the number of trials and
the number of successes, respectively, and of \(\alpha_{i_j}\) as the
probability of success. In our case, a trial is a session, a success is having
at least one purchase within that session, and the probability of success is the
conversion rate.</p>

<p>Similarly to the number of sessions, we will use a linear combination for the
parameters:</p>

\[\alpha_{i_j} = \text{logit}^{-1}(\alpha_\text{global} + \alpha_{\text{local}, i_j}) \tag{9}\]

<p>where \(\text{logit}^{-1}(x) = 1 / (1 + \text{exp}(-x))\), used to ensure the
output stays in \([0, 1]\). There is a global component, which all stores share,
and each one has its own local.</p>

<p>There are \(n + 1\) parameters in the model, which we shall consider to be <em>a
priori</em> distributed according to Gaussian distributions as follows:</p>

\[\begin{align}
\alpha_\text{global} &amp; \sim \text{Gaussian}(\alpha_0, 1) \text{ and} \tag{10} \\
\alpha_{\text{local}, i_j} &amp; \sim \text{Gaussian}(0, 1). \tag{11} \\
\end{align}\]

<p>As before, the number of hyperparameters is kept to a minimum; there is only one
in this case: \(\alpha_0\). The interpretation of \(\alpha_0\) is that it
controls the base conversion rate, which one can see by temporarily setting the
local parameters (Equation 11) to zero. Equation 9 then reduces to
\(\alpha_{i_j} = \text{logit}^{-1}(\alpha_\text{global})\). Therefore, assuming
one has an average conversion rate in mind, the parameter can be set as follows:</p>

\[\alpha_0 = \text{logit}(\text{mean}) \tag{12}\]

<p>where \(\text{logit}(x) = \ln(x / (1 - x))\).</p>

<p>Let us perform a prior predictive check for the conversion rate as well.
Assuming a conversion rate of 2.5%, that is, \(\alpha_0 = \text{logit}(0.025)\),
we obtain the following prior probability density:</p>

<p><img src="/assets/images/2025-07-30-guardrails/purchases-prior-1.svg" alt="" /></p>

<p>Here we assume 500 sessions per week and divide the sampled number of
conversions by that number. It can be seen that the density is mostly
concentrated on what one might consider realistic conversion rates but allows
for optimistic scenarios as well if that turns out to be the case.</p>

<p>To summarize, the conversion rate is modeled indirectly via the number of
sessions with purchases in accordance with Equation 8 where the
success-probability parameter is given by Equation 9, with the priors set as in
Equations 10 and 11 and the hyperparameter as in Equation 12.</p>

<h2 id="inference">Inference</h2>

<p>What do we do with the two models now? Traditionally, given a model, the outcome
of Bayesian inference is a posterior distribution over the parameters of the
model:</p>

\[f(\theta | \mathcal{D}) = \int f(\mathcal{D} | \theta) \, f(\theta) \, d\theta.\]

<p>In the above, \(\theta\) is collectively referring to all parameters, which for
the number of sessions is</p>

\[\theta = \{
  \mu_\text{global}, \mu_{\text{local}, 1}, \dots, \mu_{\text{local}, n},
  \sigma_\text{global}, \sigma_{\text{local}, 1}, \dots, \sigma_{\text{local}, n}
\}\]

<p>and for the conversion rate is</p>

\[\theta = \{
  \alpha_\text{global}, \alpha_{\text{local}, 1}, \dots, \alpha_{\text{local}, n}
\},\]

<p>and \(\mathcal{D}\) is the observed data, which is \(\{ x_j \}_{j = 1}^m\) for
the number of sessions and \(\{ y_j \}_{j = 1}^m\) for the conversion rate,
assuming \(\{ x_j \}_{j = 1}^m\) to be implicitly known in the latter case.
Next, \(f(\theta)\) stands for the density of the prior distribution of the
parameters, which is given by Equations 4, 5, 6, and 7 for the number of
sessions and by Equations 10 and 11 for the conversion rate, and \(f(\mathcal{D}
| \theta)\) is the density of the likelihood of the data, which is given by
Equations 1 and 8, respectively. When the two are combined, we arrive at the
density of the posterior distribution of the parameters given the data,
\(f(\theta | \mathcal{D})\).</p>

<p>However, we are not so much after the parameters themselves, that is,
\(\theta\), but rather after the data, that is, \(\mathcal{D}\). More
specifically, we would like to know what to expect from the data in the future
given what we have seen in the past. If we acquire a probability distribution
over what we can reasonably expect to observe next week, we would be able to
judge whether what we actually observe is anomalous or not.</p>

<p>The desired distribution has a name: the posterior predictive distribution. It
is also an artifact of Bayesian inference, and formally, the distribution is as
follows:</p>

\[f(\mathcal{D}_\text{new} | \mathcal{D}) = \int f(\mathcal{D}_\text{new} | \theta) \, f(\theta | \mathcal{D}) \, d\theta.\]

<p>In other words, it is the distribution of unseen data \(\mathcal{D}_\text{new}\)
given the observed data \(\mathcal{D}\) where the uncertainty in the parameters
is integrated out via the posterior distribution of the parameters \(\theta\).</p>

<p>In practice, given a model with data, all of the above is done by the
probabilistic programming language of choice, such as <a href="https://mc-stan.org/">Stan</a>, and its tooling.
Since such languages target the general case where the model cannot be tackled
analytically, the resulting distributions are given in the form of posterior
draws. For the posterior predictive distribution, it would be a collection of
\(l\) hypothetical replicas (on the order of thousands) of the original
observations: \(\{ \mathcal{D}_\text{new}^k \}_{k = 1}^l\). That is, for each
original observation of a store on a specific week, there will be \(l\) draws.
To calculate a guardrail for a specific store then, we can simply collect all
draws that belong to that store, choose a percentile, and calculate the
corresponding quantile:</p>

\[\text{guardrail} = \text{quantile}(\text{draws}, \text{percentile}).\]

<p>For the number of sessions for store \(i\), the guardrail is as follows:</p>

\[\hat{x}_i = \text{quantile}\left( \left\{ x_{\text{new}, j}^k: \, i_j = i, \, k = 1, \dots, l \right\}, \text{percentile} \right).\]

<p>Likewise, for the conversion rate, we have the following:</p>

\[\hat{p}_i = \text{quantile}\left( \left\{ \frac{y_{\text{new}, j}^k}{x_j^k}: \, i_j = i, \, k = 1, \dots, l \right\}, \text{percentile} \right).\]

<p>If the percentile is chosen to be, for instance, 2.5%, the guardrail will be
flagging the outcomes, that is, the number of sessions or the conversion rate
for the week that has just passed, that have dropped so much that the
probability of this happening is estimated to be at most 2.5%. One can, of
course, tweak this threshold as one sees fit, depending on how cautious one
wants to be.</p>

<p>Due to the separation of the models’ parameters into global and local, they are
considered hierarchical or multilevel. This structure allows for partial pooling
of information: what is observed for one store not only helps with the inference
for that store but also for all other stores. In particular, stores with little
data get more sensible estimates due to the presence of those with more.</p>

<p>To sum up, once formulated, each model can be implemented in a probabilistic
programming language and fitted to the historical data. The result is a set of
replications of the original observations, yielding a probability distribution
over what one might expect to see in the future. The corresponding guardrail is
then an appropriately chosen quantile of this distribution.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In this article, we have taken a look at how to build guardrails using Bayesian
statistics. They are derived in a principled way as opposed to being set based
on a gut feeling.</p>

<p>What makes this approach different from other data-driven techniques is the end
product: a probability distribution. Moreover, this distribution respects one’s
prior domain knowledge—or gut feeling again—but necessarily updates it with
evidence, that is, with actual observations. Having such a probability
distribution for the situation at hand is all one can ask for, since it provides
an exhaustive description. Furthermore, the distribution is provided in the form
of draws, and working with draws is arguably more intuitive and flexible, as one
does not depend on any mathematical derivations, which might not even be
tractable. With this in mind, calculating guardrails is only one of many
possible applications, and even this very calculation can be done in numerous
ways. One can, for instance, devise a utility function assigning a cost to each
outcome and choose a guardrail by minimizing the expected cost.</p>

<p>The time aspect, that is, \(\{ t_j \}_{j = 1}^m\), has been ignored in this
article. However, it might be justified in the setting of anomaly detection
where a relatively short time horizon is considered sufficient or even desired.
One might, for instance, limit the number of weeks to a rolling quarter (around
13 weeks) and keep on estimating the guardrails for the upcoming week. In this
case, one would not expect to have any prominent annual seasonal effects or
alike, and it is then not worth complicating the model. Moreover, the rolling
nature of this approach with a shorter window also helps to accommodate any slow
trend changes, which fall outside the scope of anomaly detection. However, it is
always possible to extend the model to have the time aspect modeled explicitly
if that is desired.</p>

<h1 id="appendix">Appendix</h1>

<p>In this auxiliary section, we provide reference implementations of the two
models in <a href="https://mc-stan.org/">Stan</a>. The notation is the same as in the rest of the article. For
the number of sessions, it is as follows:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="p">{</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">n</span><span class="p">;</span> <span class="c1">// Number of stores</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">m</span><span class="p">;</span> <span class="c1">// Number of observations</span>
  <span class="n">array</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">n</span><span class="o">&gt;</span> <span class="n">i</span><span class="p">;</span> <span class="c1">// Mapping from observations to stores</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="n">x</span><span class="p">;</span> <span class="c1">// Number of sessions</span>
<span class="p">}</span>

<span class="n">transformed</span> <span class="n">data</span> <span class="p">{</span>
  <span class="n">real</span> <span class="n">mean</span> <span class="o">=</span> <span class="mi">500</span><span class="p">;</span> <span class="c1">// Prior mean</span>
  <span class="n">real</span> <span class="n">deviation</span> <span class="o">=</span> <span class="mi">500</span><span class="p">;</span> <span class="c1">// Prior standard deviation</span>
  <span class="n">real</span> <span class="n">mu_0</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span> <span class="o">-</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">pow</span><span class="p">(</span><span class="n">deviation</span> <span class="o">/</span> <span class="n">mean</span><span class="p">,</span> <span class="mi">2</span><span class="p">));</span>
  <span class="n">real</span> <span class="n">sigma_0</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">pow</span><span class="p">(</span><span class="n">deviation</span> <span class="o">/</span> <span class="n">mean</span><span class="p">,</span> <span class="mi">2</span><span class="p">)));</span>
<span class="p">}</span>

<span class="n">parameters</span> <span class="p">{</span>
  <span class="n">real</span> <span class="n">mu_global</span><span class="p">;</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="n">mu_local</span><span class="p">;</span>
  <span class="n">real</span> <span class="n">sigma_global</span><span class="p">;</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="n">sigma_local</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">transformed</span> <span class="n">parameters</span> <span class="p">{</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">mu_global</span> <span class="o">+</span> <span class="n">mu_local</span><span class="p">;</span>
  <span class="c1">// The value is shifted by a small amount to avoid numerical issues.</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">log1p_exp</span><span class="p">(</span><span class="n">sigma_global</span> <span class="o">+</span> <span class="n">sigma_local</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-3</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">model</span> <span class="p">{</span>
  <span class="c1">// Prior distributions</span>
  <span class="n">mu_global</span> <span class="o">~</span> <span class="n">normal</span><span class="p">(</span><span class="n">mu_0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
  <span class="n">mu_local</span> <span class="o">~</span> <span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
  <span class="n">sigma_global</span> <span class="o">~</span> <span class="n">normal</span><span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">sigma_0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">);</span>
  <span class="n">sigma_local</span> <span class="o">~</span> <span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
  <span class="c1">// Likelihood of the data</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">~</span> <span class="n">lognormal</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="n">j</span><span class="p">]],</span> <span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="n">j</span><span class="p">]]);</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="n">generated</span> <span class="n">quantities</span> <span class="p">{</span>
  <span class="c1">// Posterior predictive distribution</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="n">x_new</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">x_new</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">lognormal_rng</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="n">j</span><span class="p">]],</span> <span class="n">sigma</span><span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="n">j</span><span class="p">]]);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Note that the posterior predictive distribution is part of the program; once
executed, it will not require any additional postprocessing. As for the
conversion rate, the implementation is as follows:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="p">{</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">n</span><span class="p">;</span> <span class="c1">// Number of stores</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">m</span><span class="p">;</span> <span class="c1">// Number of observations</span>
  <span class="n">array</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">n</span><span class="o">&gt;</span> <span class="n">i</span><span class="p">;</span> <span class="c1">// Mapping from observations to stores</span>
  <span class="n">array</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="o">&gt;</span> <span class="n">x</span><span class="p">;</span> <span class="c1">// Number of sessions</span>
  <span class="n">array</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="o">&gt;</span> <span class="n">y</span><span class="p">;</span> <span class="c1">// Number of sessions with purchases</span>
<span class="p">}</span>

<span class="n">transformed</span> <span class="n">data</span> <span class="p">{</span>
  <span class="n">real</span> <span class="n">mean</span> <span class="o">=</span> <span class="mi">0</span><span class="p">.</span><span class="mo">025</span><span class="p">;</span> <span class="c1">// Prior mean</span>
  <span class="n">real</span> <span class="n">alpha_0</span> <span class="o">=</span> <span class="n">mean</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">parameters</span> <span class="p">{</span>
  <span class="n">real</span> <span class="n">alpha_global</span><span class="p">;</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="n">alpha_local</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">transformed</span> <span class="n">parameters</span> <span class="p">{</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha_global</span> <span class="o">+</span> <span class="n">alpha_local</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">model</span> <span class="p">{</span>
  <span class="c1">// Prior distributions</span>
  <span class="n">alpha_global</span> <span class="o">~</span> <span class="n">normal</span><span class="p">(</span><span class="n">logit</span><span class="p">(</span><span class="n">alpha_0</span><span class="p">),</span> <span class="mi">1</span><span class="p">);</span>
  <span class="n">alpha_local</span> <span class="o">~</span> <span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
  <span class="c1">// Likelihood of the data</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">y</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">~</span> <span class="n">binomial_logit</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">alpha</span><span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="n">j</span><span class="p">]]);</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="n">generated</span> <span class="n">quantities</span> <span class="p">{</span>
  <span class="c1">// Posterior predictive distribution</span>
  <span class="n">vector</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="n">y_new</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">y_new</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">.</span><span class="mi">0</span> <span class="o">*</span> <span class="n">binomial_rng</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">inv_logit</span><span class="p">(</span><span class="n">alpha</span><span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="n">j</span><span class="p">]]))</span> <span class="o">/</span> <span class="n">x</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>]]></content><author><name>Ivan Ukhov</name><email>ivan.ukhov@gmail.com</email></author><summary type="html"><![CDATA[Suppose you run several online stores, and their number keeps growing. It is becoming increasingly difficult to monitor the performance of any given store, simply because there are too many of them. There is a fair chance that something unexpected will happen, and that it will have a negative impact on either the website traffic or the conversion rate, that is, purchases—without you realizing it. To keep your hand on the pulse, you decide to put guardrails in place, which will inform you if something goes wrong. In this article, we shall take a look at how to build such guardrails using Bayesian statistics.]]></summary></entry><entry><title type="html">Out of memory, or gradient accumulation for larger models</title><link href="https://blog.ivanukhov.com/2024/01/31/gradient-accumulation.html" rel="alternate" type="text/html" title="Out of memory, or gradient accumulation for larger models" /><published>2024-01-31T07:00:00+00:00</published><updated>2024-01-31T07:00:00+00:00</updated><id>https://blog.ivanukhov.com/2024/01/31/gradient-accumulation</id><content type="html" xml:base="https://blog.ivanukhov.com/2024/01/31/gradient-accumulation.html"><![CDATA[<p>When the model grows large and does not fit on a single device, and there are no
more devices to spare, the common mitigation strategy is to reduce the batch
size, thereby allowing more space for the model at the expense of the data.
However, smaller batches lead to noisier weight updates, which is undesirable.
One solution is gradient accumulation where the weights are updated after
evaluating the gradients for several batches at a time. In this article, we show
how it can be implemented in practice.</p>

<h1 id="solution">Solution</h1>

<p>Long story short, assuming TensorFlow 2.17:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Inherit from any optimizer of choice, such as Adam.
</span><span class="k">class</span> <span class="nc">Optimizer</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Optimizer that implements gradient accumulation.</span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">accumulation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Create an instance.

        Arguments:
          accumulation: The number of iterations to accumulate gradients over.
          If it is set to one, no accumulation is performed, and the gradients
          are applied as soon as they are computed. If it is set to a value
          greater than one, the gradients will be accumulated for the specified
          number of iterations and only then applied, starting a new cycle.

        All other arguments are passed to the base optimizer.
        </span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">options</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">accumulation</span> <span class="o">=</span> <span class="n">accumulation</span>
        <span class="n">self</span><span class="p">.</span><span class="n">_gradients</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">iterations</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Return the number of iterations.</span><span class="sh">"""</span>
        <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">ops</span><span class="p">.</span><span class="nf">floor_divide</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_iterations</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">accumulation</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">apply_gradients</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> <span class="n">gradients_variables</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Apply the gradients according to the accumulation scheme.</span><span class="sh">"""</span>
        <span class="c1"># Split off the gradients from the trainable variables.
</span>        <span class="n">gradients</span><span class="p">,</span> <span class="n">variables</span> <span class="o">=</span> <span class="nf">zip</span><span class="p">(</span><span class="o">*</span><span class="nf">list</span><span class="p">(</span><span class="n">gradients_variables</span><span class="p">))</span>
        <span class="c1"># Perform the initialization if needed.
</span>        <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">init_scope</span><span class="p">():</span>
                <span class="n">self</span><span class="p">.</span><span class="nf">build</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>
        <span class="n">first</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_iterations</span> <span class="o">%</span> <span class="n">self</span><span class="p">.</span><span class="n">accumulation</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="n">last</span> <span class="o">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">self</span><span class="p">.</span><span class="n">accumulation</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="c1"># Add the new gradients to the old ones with resetting if needed.
</span>        <span class="k">for</span> <span class="nb">sum</span><span class="p">,</span> <span class="n">delta</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_gradients</span><span class="p">,</span> <span class="n">gradients</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">delta</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="nb">sum</span><span class="p">.</span><span class="nf">assign</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="o">~</span><span class="n">first</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="nb">sum</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span>
        <span class="c1"># Apply the average accumulated gradients to the trainable variables.
</span>        <span class="n">gradients</span> <span class="o">=</span> <span class="p">[</span><span class="n">gradient</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">accumulation</span> <span class="k">for</span> <span class="n">gradient</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">_gradients</span><span class="p">]</span>
        <span class="k">return</span> <span class="nf">super</span><span class="p">().</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">variables</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">update_step</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">gradient</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">variable</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Update the trainable variable with the gradient.</span><span class="sh">"""</span>
        <span class="n">update_step</span> <span class="o">=</span> <span class="nf">super</span><span class="p">().</span><span class="n">update_step</span>
        <span class="n">last</span> <span class="o">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">self</span><span class="p">.</span><span class="n">accumulation</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="c1"># Allow the update to happen only at the end of each cycle.
</span>        <span class="n">true</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="nf">update_step</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
        <span class="n">tf</span><span class="p">.</span><span class="nf">cond</span><span class="p">(</span><span class="n">last</span><span class="p">,</span> <span class="n">true</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="bp">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">variables</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Initialize the internal state.</span><span class="sh">"""</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">build</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span>
        <span class="c1"># Allocate memory for accumulation.
</span>        <span class="n">self</span><span class="p">.</span><span class="n">_gradients</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">self</span><span class="p">.</span><span class="nf">add_variable_from_reference</span><span class="p">(</span>
                <span class="n">reference_variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">gradient</span><span class="sh">"</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">variable</span> <span class="ow">in</span> <span class="n">variables</span>
        <span class="p">]</span>
</code></pre></div></div>

<p>It is important to note that the learning rate keeps on changing (if variable)
and the weights keep on decaying (if enabled) during accumulation. Therefore,
one should account for this when configuring the optimizer at hand.</p>

<p>One should also note that TensorFlow does support gradient accumulation as of
version 2.16, which is controlled by the <code class="language-plaintext highlighter-rouge">gradient_accumulation_steps</code> option of
Keras optimizers. However, it does not play well with distributed training
strategies, which will hopefully be rectified in the future.</p>

<h1 id="acknowledgments">Acknowledgments</h1>

<p>I would like to thank <a href="https://github.com/andreped">André Pedersen</a>, <a href="https://github.com/roebel">Axel Roebel</a>, and <a href="https://github.com/tno123">Tor-Arne Nordmo</a> for
their help with the implementation.</p>]]></content><author><name>Ivan Ukhov</name><email>ivan.ukhov@gmail.com</email></author><summary type="html"><![CDATA[When the model grows large and does not fit on a single device, and there are no more devices to spare, the common mitigation strategy is to reduce the batch size, thereby allowing more space for the model at the expense of the data. However, smaller batches lead to noisier weight updates, which is undesirable. One solution is gradient accumulation where the weights are updated after evaluating the gradients for several batches at a time. In this article, we show how it can be implemented in practice.]]></summary></entry><entry><title type="html">Relative positional embedding for any attention mechanism</title><link href="https://blog.ivanukhov.com/2024/01/17/relative-positional-embedding.html" rel="alternate" type="text/html" title="Relative positional embedding for any attention mechanism" /><published>2024-01-17T07:00:00+00:00</published><updated>2024-01-17T07:00:00+00:00</updated><id>https://blog.ivanukhov.com/2024/01/17/relative-positional-embedding</id><content type="html" xml:base="https://blog.ivanukhov.com/2024/01/17/relative-positional-embedding.html"><![CDATA[<p>In <a href="https://arxiv.org/abs/1803.02155">Shaw et al. (2018)</a>, the authors introduce relative positional embedding for
self-attention in transformer models, and in <a href="https://arxiv.org/abs/1809.04281">Huang et al. (2018)</a>, the authors
present a memory efficient approach to calculating this embedding in decoder
blocks, in which the self-attention is causal. In this article, the approach is
generalized to any attention mechanism, should it be self or cross or full or
causal.</p>

<h1 id="background">Background</h1>

<p>The classical attention is formalized as follows:</p>

\[A = \text{softmax}\left( \frac{QK^{T}}{\sqrt{n_d}} \right) V\]

<p>where \(K\), \(V\), and \(Q\) are the keys, values, and queries, respectively.
The keys and values are of shape \(n_s \times n_h \times n_{t_1} \times n_d\)
where \(n_s\) is the batch size (<em>s</em> for space), \(n_h\) is the number of
attention heads, \(n_{t_1}\) is the window size (<em>t</em> for time) of the <em>input</em>
sequence, and \(n_d\) is the head size. The queries are of shape \(n_s \times
n_h \times n_{t_2} \times n_d\) where \(n_{t_2}\) is the window size of the
<em>output</em> sequence.</p>

<p>The relative attention obtains one additional term in the numerator:</p>

\[A = \text{softmax}\left( \frac{QK^T + S}{\sqrt{n_d}} \right) V. \tag{1}\]

<p>In the above, \(S\) is of shape \(n_s \times n_h \times n_{t_2} \times n_{t_1}\)
and calculated based on \(Q\) and a matrix \(E\) of shape \(n_d \times n_{t_3}\)
containing relative positional embeddings. The typical context is causal
self-attention, in which \(n_{t_3}\) is thought of as the maximum allowed length
of the input sequence and set to \(n_{t_1}\), with the interpretation that the
embeddings are running from position \(-n_{t_1} + 1\) (the most distant past) up
to \(0\) (the present moment). Then \(S\) is a specific arrangement of the inner
products between the queries in \(Q\) and the embeddings in \(E\) so as to
respect the arrangement in \(QK^T\).</p>

<p>The original and more memory efficient calculations of \(S\) in the case of
causal attention, are illustrated in the figure below, which is taken from Huang
et al. (2018).</p>

<p><img src="/assets/images/2024-01-17-relative-position/huang.jpeg" alt="" /></p>

<p>The matrix to the very right shows how \(S\) is arranged. Since the use case is
causal attention, the upper triangle above the main diagonal (gray circles) is
irrelevant and can contain arbitrary values, which it does in the algorithm
proposed in Huang et al. (2018). The main diagonal (green circles) contains the
inner products of the queries and the embedding corresponding to position \(0\).
The first subdiagonal (pink circles) contains the inner products of the queries
except for the first one as it has no past, and the embedding corresponding to
position \(-1\). And it continues in this way down to \(-n_{t_1} + 1\), in which
case it is only the last query that is involved, since it comes last in the
sequence and has the longest past.</p>

<p>The calculation given in Huang et al. (2018) reduces the intermediate memory
requirement from \(\mathcal{O}(n_h \, n_d \, n_t^2)\) to \(\mathcal{O}(n_h \,
n_d \, n_t)\) where \(n_t\) is a general sequence length. However, it is limited
to self-attention with causal connectivity, which is what is found in decoder
blocks. It is not suitable for other attention patterns. Therefore, it cannot be
used in, for instance, encoder blocks and decoder blocks with cross-attention,
which usually have non-causal attention. In what follow, the limitation is
lifted.</p>

<h1 id="algorithm">Algorithm</h1>

<p>Let us extend \(E\) to be of shape \(n_d \times (2 n_{t_3} - 1)\) so that it has
an embedding for any relative position not only when looking back in the past
but also forward into the future, with \(n_{t_3}\) being the maximum allowed
length of the input sequence as before, that is, \(t_1 \leq t_3\). Let us also
interpret \(E\)’s columns as running from position \(n_{t_3} - 1\) (the most
distant future) to position \(-n_{t_3} + 1\) (the most distant past). For
instance, when the output sequence is of length \(t_3\) (the longest possible),
the first query (position 0) will be “interested” only in columns \(0\) through
\(n_{t_3} - 1\) inclusively, while the last (position \(n_{t_3} - 1\)) only in
columns \(n_{t_3} - 1\) through \(2 n_{t_3} - 2\) inclusively.</p>

<p>Similarly to Huang et al. (2018), we note that multiplying \(Q\) by \(E\)
results in a matrix that contains all the inner products necessary for
assembling \(S\) in the general case. For instance, for \(t_3 = 4\) and dropping
the batch and head dimensions for clearer visualization, the product is as
follows:</p>

\[QE = \left(
\begin{matrix}
s_{0 + 3} &amp; s_{0 + 2} &amp; s_{0 + 1} &amp; s_{0 + 0} &amp; &amp; &amp; \\
&amp; s_{1 + 2} &amp; s_{1 + 1} &amp; s_{1 + 0} &amp; s_{1 - 1} &amp; &amp; \\
&amp; &amp; s_{2 + 1} &amp; s_{2 + 0} &amp; s_{2 - 1} &amp; s_{2 - 2} &amp; \\
&amp; &amp; &amp; s_{3 + 0} &amp; s_{3 - 1} &amp; s_{3 - 2} &amp; s_{3 - 3} \\
\end{matrix}
\right)\]

<p>where \(s_{i + t}\) denotes query \(i\) embedded to look at relative time \(t\),
that is, the inner product between the query at position \(i\) and the embedding
corresponding to a relative attention shift of \(t\), whose embedding is stored
in column \(n_{t_3} - 1 - t\) of \(E\). For instance, for \(s_{2 - 1}\) with
\(t_3 = 4\) still, the inner product is between row \(2\) of \(Q\) and column
\(4 - 1 - (-1) = 4\) of \(E\).</p>

<p>The target arrangement is then simply the one where we stack the
“interesting” diagonals of \(QE\) on top of each other from diagonal \(0\) (the
main diagonal) at the bottom and diagonal \(t_3 - 1\) (the rightmost relevant
superdiagonal) at the top</p>

\[\bar{S} = \left(
\begin{matrix}
s_{0 + 0} &amp; s_{1 - 1} &amp; s_{2 - 2} &amp; s_{3 - 3} \\
s_{0 + 1} &amp; s_{1 + 0} &amp; s_{2 - 1} &amp; s_{3 - 2} \\
s_{0 + 2} &amp; s_{1 + 1} &amp; s_{2 + 0} &amp; s_{3 - 1} \\
s_{0 + 3} &amp; s_{1 + 2} &amp; s_{2 + 1} &amp; s_{3 + 0} \\
\end{matrix}
\right)\]

<p>and then transpose the result</p>

\[S = \left(
\begin{matrix}
s_{0 + 0} &amp; s_{0 + 1} &amp; s_{0 + 2} &amp; s_{0 + 3} \\
s_{1 - 1} &amp; s_{1 + 0} &amp; s_{1 + 1} &amp; s_{1 + 2} \\
s_{2 - 2} &amp; s_{2 - 1} &amp; s_{2 + 0} &amp; s_{2 + 1} \\
s_{3 - 3} &amp; s_{3 - 2} &amp; s_{3 - 1} &amp; s_{3 + 0} \\
\end{matrix}
\right).\]

<p>More generally, the algorithm can be summarized as follows:</p>

\[S = \text{transpose}\left(
  \text{diagonal}\left(
    QE, \, \text{lower}=0, \, \text{upper}=n_{t_3} - 1
  \right)
\right)\]

<p>where \(\text{diagonal}\) is a function taking a tensor and stacking its
diagonals—specified by a range with two offsets relative to the main
diagonal—from bottom up, and \(\text{transpose}\) is a function taking a tensor
and transposing it. Both functions operators on the last two dimensions of the
given tensor. This resulting matrix can then be plugged into Equation 1 to
complete the calculation.</p>

<p>In case the keys and values are shorter than the maximum allowed relative
position, that is, \(t_1 &lt; t_3\), \(S\) should be truncated to its intended
shape, \(n_s \times n_h \times n_{t_2} \times n_{t_1}\):</p>

\[S = \text{truncate}\left(
  \text{transpose}\left(
    \text{diagonal}\left(
      QE, \, \text{lower}=0, \, \text{upper}=n_{t_3} - 1
    \right)
  \right),
  \text{keep} = n_{t_1}
\right)\]

<p>where \(\text{truncate}\) is a function taking a tensor and keeping only the
specified number of its first elements in the last dimension, discarding the
rest.</p>

<p>It can be seen that the algorithm the same intermediate memory requirement than
the one proposed in Huang at al. (2018), that is, \(\mathcal{O}(n_h \, n_d \,
n_t)\); however, its application scope is larger.</p>

<h1 id="implementation">Implementation</h1>

<p>In TensorFlow, the algorithm can be implemented as an embedding layer as
follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RelativePositionalEmbedding</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">head_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">add_weight</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">head_size</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">sequence_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">initializer</span><span class="o">=</span><span class="sh">"</span><span class="s">glorot_uniform</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="n">sequence_length</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">Q</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">S</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">projection</span><span class="p">)</span>
        <span class="n">S</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">diag_part</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">sequence_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">S</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">S</span>
</code></pre></div></div>

<p>The above layer can be invoked as part of an attention layer as illustrated
below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">head_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">head_size</span> <span class="o">=</span> <span class="n">head_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">positional_embedding</span> <span class="o">=</span> <span class="nc">RelativePositionalEmbedding</span><span class="p">(</span>
            <span class="n">head_size</span><span class="o">=</span><span class="n">head_size</span><span class="p">,</span>
            <span class="n">sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">K</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">V</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Q</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># TODO: Add permutation if needed.
</span>        <span class="n">S</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">positional_embedding</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">+</span> <span class="n">S</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span> <span class="n">K</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">head_size</span><span class="o">**-</span><span class="mf">0.5</span>
        <span class="c1"># TODO: Add masking if needed.
</span>        <span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># TODO: Add dropout if needed.
</span>        <span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
        <span class="c1"># TODO: Add dropout if needed.
</span>        <span class="k">return</span> <span class="n">A</span>
</code></pre></div></div>

<h1 id="references">References</h1>

<ul>
  <li>Huang et al., “<a href="https://arxiv.org/abs/1809.04281">Music transformer: Generating music with long-term
structure</a>,” Google Brain, 2018.</li>
  <li>Shaw et al., “<a href="https://arxiv.org/abs/1803.02155">Self-attention with relative position representations</a>,” Google Brain, 2018.</li>
</ul>]]></content><author><name>Ivan Ukhov</name><email>ivan.ukhov@gmail.com</email></author><summary type="html"><![CDATA[In Shaw et al. (2018), the authors introduce relative positional embedding for self-attention in transformer models, and in Huang et al. (2018), the authors present a memory efficient approach to calculating this embedding in decoder blocks, in which the self-attention is causal. In this article, the approach is generalized to any attention mechanism, should it be self or cross or full or causal.]]></summary></entry><entry><title type="html">Breaking sticks, or estimation of probability distributions using the Dirichlet process</title><link href="https://blog.ivanukhov.com/2021/01/25/dirichlet-process.html" rel="alternate" type="text/html" title="Breaking sticks, or estimation of probability distributions using the Dirichlet process" /><published>2021-01-25T06:00:00+00:00</published><updated>2021-01-25T06:00:00+00:00</updated><id>https://blog.ivanukhov.com/2021/01/25/dirichlet-process</id><content type="html" xml:base="https://blog.ivanukhov.com/2021/01/25/dirichlet-process.html"><![CDATA[<p>Recall the last time you wanted to understand the distribution of given data.
One alternative was to plot a histogram. However, it resulted in frustration due
to the choice of the number of bins to use, which led to drastically different
outcomes. Another alternative was kernel density estimation. Despite having a
similar choice to make, it has the advantage of producing smooth estimates,
which are more realistic for continuous quantities with regularities. However,
kernel density estimation was unsatisfactory too: it did not aid in
understanding the underlying structure of the data and, moreover, provided no
means of quantifying the uncertainty associated with the results. In this
article, we discuss a Bayesian approach to the estimation of data-generating
distributions that addresses the aforementioned concerns.</p>

<p>The approach we shall discuss is based on the family of Dirichlet processes. How
specifically such processes are constructed will be described in the next
section; here, we focus on the big picture.</p>

<p>A Dirichlet process is a stochastic process, that is, an indexed sequence of
random variables. Each realization of this process is a discrete probability
distribution, which makes the process a distribution over distributions,
similarly to a Dirichlet distribution. The process has only one parameter: a
measure \(\nu: \mathcal{B} \to [0, \infty]\) in a suitable finite measure space
\((\mathcal{X}, \mathcal{B}, \nu)\) where \(\mathcal{X}\) is a set, and
\(\mathcal{B}\) is a \(\sigma\)-algebra on \(\mathcal{X}\). We shall adopt the
following notation:</p>

\[P \sim \text{Dirichlet Process}(\nu)\]

<p>where \(P\) is a <em>random</em> probability distribution that is distributed according
to the Dirichlet process. Note that measure \(\nu\) does not have to be a
probability measure; that is, \(\nu(\mathcal{X}) = 1\) is not required. To
obtain a probability measure, one can divide \(\nu\) by the total volume
\(\lambda = \nu(\mathcal{X})\):</p>

\[P_0(\cdot) = \frac{1}{\lambda} \nu(\cdot).\]

<p>Since this normalization is always possible, it is common and convenient to
replace \(\nu\) with \(\lambda P_0\) and consider the process to be
parametrized by two quantities instead of one:</p>

\[P \sim \text{Dirichlet Process}(\lambda P_0).\]

<p>Parameter \(\lambda\) is referred to as the concentration parameter of the
process.</p>

<p>There are two major alternatives of using the Dirichlet process for estimating
distributions: as a direct prior for the data at hand and as a mixing prior. We
begin with the former.</p>

<h1 id="direct-prior">Direct prior</h1>

<p>Given a data set of \(n\) observations \(\{ x_i \}_{i = 1}^n\), a Dirichlet
process can be used as a prior:</p>

\[\begin{align}
x_i | P_x &amp; \sim P_x, \text{ for } i = 1, \dots, n; \text{ and} \\
P_x &amp; \sim \text{Dirichlet Process}(\lambda P_0). \tag{1}
\end{align}\]

<p>It is important to realize that the \(x_i\)’s are assumed to be distributed
<em>not</em> according to the Dirichlet process but according to a distribution drawn
from the Dirichlet process. Parameter \(\lambda\) allows one to control the
strength of the prior: the larger it is, the more shrinkage toward the prior is
induced.</p>

<h2 id="inference">Inference</h2>

<p>Due to the conjugacy property of the Dirichlet process in the above setting, the
posterior is also a Dirichlet process and has the following simple form:</p>

\[P_x | \{ x_i \}_{i = 1}^n
\sim \text{Dirichlet Process}\left( \lambda P_0 + \sum_{i = 1}^n \delta_{x_i} \right). \tag{2}\]

<p>That is, the total volume and normalized measure are updated as follows:</p>

\[\begin{align}
\lambda &amp; := \lambda + n \quad \text{and} \\
P_0 &amp; := \frac{\lambda}{\lambda + n} P_0 + \frac{1}{\lambda + n} \sum_{i = 1}^n \delta_{x_i}.
\end{align}\]

<p>Here, \(\delta_x(\cdot)\) is the Dirac measure, meaning that \(\delta_x(X) = 1\)
if \(x \in X\) for any \(X \subseteq \mathcal{X}\), and otherwise, it is zero.
It can be seen in Equation 2 that the base measure has simply been augmented
with unit masses placed at the \(n\) observed data points.</p>

<p>The main question now is, How to draw samples from a Dirichlet process given
\(\lambda\) and \(P_0\)?</p>

<p>As noted earlier, a draw from a Dirichlet process is a discrete probability
distribution \(P_x\). The probability measure of this distribution admits the
following representation:</p>

\[P_x(\cdot) = \sum_{i = 1}^\infty p_i \delta_{x_i}(\cdot) \tag{3}\]

<p>where \(\{ p_i \}\) is a set of probabilities that sum up to one, and \(\{ x_i
\}\) is a set of points in \(\mathcal{X}\). Such a draw can be obtained using
the so-called stick-breaking construction, which prescribes \(\{ p_i \}\) and
\(\{ x_i \}\). To begin with, for practical computations, the infinite summation
is truncated to retain the only first \(m\) elements:</p>

\[P_x(\cdot) = \sum_{i = 1}^m p_i \delta_{x_i}(\cdot).\]

<p>Atoms \(\{ x_i \}_{i = 1}^m\) are drawn independently from the normalized base
measure \(P_0\). The calculation of probabilities \(\{ p_i \}\) is more
elaborate, and this is where the construction and this article get their name,
“stick breaking.” Imagine a stick of unit length, representing the total
probability. The procedure is to keep breaking the stick into two parts where,
for each iteration, the left part yields \(p_i\), and the right one, the
remainder, is carried over to the next iteration. How much to break off is
decided on by drawing \(m\) independent realizations from a carefully chosen
beta distribution:</p>

\[q_i \sim \text{Beta}(1, \lambda), \text{ for } i = 1, \dots, m. \tag{4}\]

<p>All of them lie in the unit interval and are the proportions to break off of the
remainder. When \(\lambda = 1\), these proportions (of the reminder) are
uniformly distributed. When \(\lambda &lt; 1\), the probability mass is shifted to
the right, which means that there are likely to be a small number of large
pieces, covering virtually the entire stick. When \(\lambda &gt; 1\), the
probability mass is shifted to the left, which means that there are likely to be
a large number of small pieces, struggling to reach the end of the stick.</p>

<p>Formally, the desired probabilities are given by the following expression:</p>

\[p_i = q_i \prod_{j = 1}^{i - 1} (1 - q_j), \text{ for } i = 1, \dots, m,\]

<p>which, as noted earlier, are the left parts of the remainder of the stick during
each iteration. For instance, \(p_1 = q_1\), \(p_2 = q_2 (1 - q_1)\), and so on.
Due to the truncation, the probabilities \(\{ p_i \}_{i = 1}^m\) do not sum up
to one, and it is common to set \(q_m := 1\) so that \(p_m\) takes up the
remaining probability mass.</p>

<p>To recapitulate, a single draw from a Dirichlet process is obtained in two
steps: prescribe atoms \(\{ x_i \}\) via draws from the normalized base measure
and prescribe the corresponding probabilities \(\{ p_i \}\) via the
stick-breaking construction. The two give a complete description of a discrete
probability distribution. Recall that this distribution is still a single draw.
By repeating this process many times, one obtains the distribution of this
distribution, which can be used to, for instance, quantify uncertainty in the
estimation.</p>

<h2 id="illustration">Illustration</h2>

<p>It is time to demonstrate how the Dirichlet process behaves as a direct prior.
To this end, we shall use a <a href="https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/galaxies.html">data set</a> containing velocities of “82
galaxies from 6 well-separated conic sections of an unfilled survey of the
Corona Borealis region.” It was studied in <a href="https://doi.org/10.2307/2289993">Roeder (1990)</a>, which gives us a
reference point.</p>

<blockquote>
  <p>For the curious reader, the source code of this <a href="https://github.com/IvanUkhov/blog/blob/master/_posts/2021-01-25-dirichlet-process.Rmd">notebook</a> along with
auxiliary <a href="https://github.com/IvanUkhov/blog/tree/master/_scripts/2021-01-25-dirichlet-process">scripts</a> that are used for performing all the calculations
presented below can be found on GitHub.</p>
</blockquote>

<p>The empirical cumulative distribution function of the velocity is as follows:</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/data-cdf-1.svg" alt="" /></p>

<p>Already here, it is apparent that the distribution is multimodal: there are two
distinct regions, one to the left and one to the right, where the curve is flat,
meaning there are no observations there. The proverbial histogram gives a
confirmation:</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/data-histogram-1.svg" alt="" /></p>

<p>It can be seen that there is a handful of galaxies moving relatively slowly and
relatively fast compared to the majority located somewhere in the middle around
twenty thousand kilometers per second. For completeness, kernel density
estimation results in the following plot:</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/data-kde-1.svg" alt="" /></p>

<p>How many clusters of galaxies are there? What are their average velocities? How
uncertain are these estimates? Our goal is to answer these questions by virtue
of the Dirichlet process.</p>

<p>Now that the intention is to apply the presented theory in practice, we have to
make all choices we have conveniently glanced over. Specifically, \(P_0\) has to
be chosen, and we shall use the following:</p>

\[P_0(\cdot) = \text{Gaussian}(\, \cdot \, | \mu_0, \sigma_0^2). \tag{5}\]

<p>In the above, \(\text{Gaussian}(\cdot)\) refers to the probability measure of a
Gaussian distribution with parameters \(\mu_0\) and \(\sigma_0\). In addition to
these two, there is one more: \(\lambda\). We shall set \(\mu_0\) and
\(\sigma_0\) to 20 and 5, respectively—which correspond roughly to the mean and
standard deviation of the data—and present results for different \(\lambda\)’s
to investigate how the prior volume affects shrinkage toward the prior.</p>

<p>First, we do not condition on the data to get a better understanding of the
prior itself, which corresponds to Equation 1. The following figure shows a
single draw from four Dirichlet processes with different \(\lambda\)’s (the gray
curves show the cumulative distribution function of the data as a reference):</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/direct-prior-1.svg" alt="" /></p>

<p>It can be seen that the larger the prior volume, the smoother the curve. This is
because larger \(\lambda\)’s “break” the stick into more pieces, allowing the
normalized base measure to be extensively sampled, which, in the limit,
converges to this very measure; see Equation 5.</p>

<p>Now, conditioning on the observed velocities of galaxies—that is, sampling as
shown in Equation 2—we obtain the following draws from the posterior Dirichlet
distributions with different \(\lambda\)’s:</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/direct-posterior-1.svg" alt="" /></p>

<p>When the prior volume is small, virtually no data points come from \(P_0\);
instead, they are mostly uniform draws from the observed data set, leading to a
curve that is nearly indistinguishable from the one of the data (the top curve).
As \(\lambda\) gets larger, the prior gets stronger, and the estimate gets
shrunk toward it, up to a point where the observations appear to be entirely
ignored (the bottom curve).</p>

<p>The above model has a serious limitation: it assumes a discrete probability
distribution for the data-generating process, which can be seen in the prior and
posterior given in Equation 1 and 2, respectively, and it is also apparent in
the decomposition given in Equation 3. In some cases, it might be appropriate;
however, there is arguably more situations where it is inadequate, including the
running example.</p>

<h1 id="mixing-prior">Mixing prior</h1>

<p>Instead of using a Dirichlet process as a direct prior for the given data, it
can be used as a prior for mixing distributions from a given family. The
resulting posterior will then naturally inherit the properties of the family,
such as continuity. The general structure is as follows:</p>

\[\begin{align}
x_i | \theta_i &amp; \sim P_x \left( \theta_i \right), \text{ for } i = 1, \dots, n; \tag{6} \\
\theta_i | P_\theta &amp; \sim P_\theta, \text{ for } i = 1, \dots, n; \text{ and} \\
P_\theta &amp; \sim \text{Dirichlet Process}(\lambda P_0). \\
\end{align}\]

<p>The \(i\)th data point, \(x_i\), is distributed according to distribution
\(P_x\) with parameters \(\theta_i\). For instance, \(P_x\) could refer to the
Gaussian family with \(\theta_i = (\mu_i, \sigma_i)\) identifying a particular
member of the family by its mean and standard deviation. Parameters \(\{
\theta_i \}_{i = 1}^n\) are unknown and distributed according to distribution
\(P_\theta\). Distribution \(P_\theta\) is not known either and gets a Dirichlet
process prior with measure \(\lambda P_0\).</p>

<p>It can be seen in Equation 6 that each data point can potentially have its own
unique set of parameters. However, this is not what usually happens in practice.
If \(\lambda\) is reasonably small, the vast majority of the stick—the one we
explained how to break in the previous section—tends to be consumed by a small
number of pieces. This makes many data points share the same parameters, which
is akin to clustering. In fact, clustering is a prominent use case for the
Dirichlet process.</p>

<h2 id="inference-1">Inference</h2>

<p>Unlike the previous model, there is no conjugacy in this case, and hence the
posterior is not a Dirichlet process. There is, however, a simple Markov chain
Monte Carlo sampling strategy based on the stick-breaking construction. It
belongs to the class of Gibbs samplers and is as follows.</p>

<p>Similarly to Equation 3, we have the following decomposition:</p>

\[P_m(\cdot) = \sum_{i = 1}^\infty p_i P_x(\cdot | \theta_i)\]

<p>where \(P_m\) is the probability measure of the mixture. As before, the infinite
decomposition has to be made finite to be usable in practice:</p>

\[P_m(\cdot) = \sum_{i = 1}^m p_i P_x(\cdot | \theta_i).\]

<p>Here, \(m\) represents an upper limit on the number of mixture components. Each
data point \(x_i\), for \(i = 1, \dots, n\), is mapped to one of the \(m\)
components, which we denote by \(k_i \in \{ 1, \dots, m \}\). In other words,
\(k_i\) takes values from 1 to \(m\) and gives the index of the component of
the \(i\)th observation.</p>

<p>There are \(m + m \times |\theta| + n\) parameters to be inferred where
\(|\theta|\) denotes the number of parameters of \(P_x\). These parameters are
\(\{ p_i \}_{i = 1}^m\), \(\{ \theta_i \}_{i = 1}^m\), and \(\{ k_i \}_{i =
1}^n\). As usual in Gibbs sampling, the parameters assume arbitrary but
compatible initial values. The sampler has the following three steps.</p>

<p>First, given \(\{ p_i \}\), \(\{ \theta_i \}\), and \(\{ x_i \}\), the mapping
of the observations to the mixture components, \(\{ k_i \}\), is updated as
follows:</p>

\[k_i \sim \text{Categorical}\left(
  m,
  \left\{ \frac{p_j P_x(x_i | \theta_j)}{\sum_{l = 1}^m p_l P_x(x_i | \theta_l)} \right\}_{j = 1}^m
\right), \text{ for } i = 1, \dots, n.\]

<p>That is, \(k_i\) is a draw from a categorical distribution with \(m\) categories
whose unnormalized probabilities are given by \(p_j P_x(x_i | \theta_j)\), for
\(j = 1, \dots, m\).</p>

<p>Second, given \(\{ k_i \}\), the probabilities of the mixture components, \(\{ p_i
\}\), are updated using the stick-breaking construction described earlier. This
time, however, the beta distribution for sampling \(\{ q_i \}\) in Equation 4 is
replaced with the following:</p>

\[q_i \sim \text{Beta}\left( 1 + n_i, \lambda + \sum_{j = i + 1}^m n_j \right), \text{ for } i = 1, \dots, m,\]

<p>where</p>

\[n_i = \sum_{j = 1}^n I_{\{i\}}(k_j), \text{ for } i = 1, \dots, m,\]

<p>is the number of data points that are currently allocated to component \(i\).
Here, \(I_A\) is the indicator function of a set \(A\). As before, in order for
the \(p_i\)’s to sum up to one, it is common to set \(q_m := 1\).</p>

<p>Third, given \(\{ k_i \}\) and \(\{ x_i \}\), the parameters of the mixture
components, \(\{ \theta_i \}\), are updated. This is done by sampling from the
posterior distribution of each component. In this case, the posterior is a prior
of choice that is updated using the data points that are currently allocated to
the corresponding component. To streamline this step, a conjugate prior for the
data distribution, \(P_x\), is commonly utilized, which we shall illustrate
shortly.</p>

<p>To recapitulate, a single draw from the posterior is obtained in a number of
steps where parameters or groups of parameters are updated in turn, while
treating the other parameters as known. This Gibbs procedure is very flexible.
Other parameters can be inferred too, instead of setting them to fixed values.
An important example is the concentration parameter, \(\lambda\). This parameter
controls the formation of clusters, and one might let the data decide what the
value should be, in which case a step similar to the third one is added to the
procedure to update \(\lambda\). This will be also illustrated below.</p>

<h2 id="illustration-1">Illustration</h2>

<p>We continue working with the galaxy data. For concreteness, consider the
following choices:</p>

\[\begin{align}
\theta_i &amp;= (\mu_i, \sigma_i), \text{ for } i = 1, \dots, n; \\
P_x (\theta_i) &amp;= \text{Gaussian}(\mu_i, \sigma_i^2), \text{ for } i = 1, \dots, n; \text{ and} \\
P_0(\cdot) &amp;= \text{Gaussian–Scaled-Inverse-}\chi^2(\, \cdot \, | \mu_0, \kappa_0, \nu_0, \sigma_0^2).
\end{align} \tag{7}\]

<p>In the above, \(\text{Gaussian–Scaled-Inverse-}\chi^2(\cdot)\) refers to the
probability measure of a bivariate distribution composed of a conditional
Gaussian and an unconditional scaled inverse chi-squared distribution. Some
intuition about this distribution can be built via the following decomposition:</p>

\[\begin{align}
\mu_i | \sigma_i^2 &amp; \sim \text{Gaussian}\left(\mu_0, \frac{\sigma_i^2}{\kappa_0}\right) \text{ and} \\
\sigma_i^2 &amp; \sim \text{Scaled-Inverse-}\chi^2(\nu_0, \sigma_0^2).
\end{align} \tag{8}\]

<p>This prior is a conjugate prior for a Gaussian data distribution with unknown
mean and variance, which we assume here. This means that the posterior is also a
Gaussian–scaled-inverse-chi-squared distribution. Given a data set with
\(n\) observations \(x_1, \dots, x_n\), the four parameters of the prior
are updated simultaneously (not sequentially) as follows:</p>

\[\begin{align}
\mu_0 &amp; := \frac{\kappa_0}{\kappa_0 + n} \mu_0 + \frac{n}{\kappa_0 + n} \mu_x, \\
\kappa_0 &amp; := \kappa_0 + n, \\
\nu_0 &amp; := \nu_0 + n, \text{ and} \\
\sigma_0^2 &amp; := \frac{1}{\nu_0 + n} \left( \nu_0 \sigma_0^2 + ss_x + \frac{\kappa_0 n}{\kappa_0 + n}(\mu_x - \mu_0)^2 \right)
\end{align}\]

<p>where \(\mu_x = \sum_{i = 1}^n x_i / n\) and \(ss_x = \sum_{i = 1}^n (x_i -
\mu_x)^2\). It can be seen that \(\kappa_0\) and \(\nu_0\) act as counters of
the number of observations; \(\mu_0\) is a weighted sum of two means; and
\(\nu_0 \sigma_0^2\) is a sum of two sums of squares and a third term increasing
the uncertainty due to the difference in the means. In the Gibbs sampler, each
component (each cluster of galaxies) will have its own posterior based on the
data points that are assigned to that component during each iteration of the
process. Therefore, \(n\), \(\mu_x\), and \(ss_x\) will generally be different
for different components and, moreover, will vary from iteration to iteration.</p>

<p>We set \(\mu_0\) to 20, which is roughly the mean of the data, and \(\nu_0\) to
3, which is the smallest integer that allows the scaled chi-squared distribution
to have a finite expectation. The choice of \(\kappa_0\) and \(\sigma_0\) is
more subtle. Recall Equation 8. What we would like from the prior is to allow
for free formation of clusters in a region generously covering the support of
the data. To this end, the uncertainty in the mean, \(\mu_i\), has to be high;
however, it should not come from \(\sigma_i\), since it would produce very
diffuse clusters. We set \(\kappa_0\) to 0.01 to magnify the variance of
\(\mu_i\) without affecting \(\sigma_i\), and \(\sigma_0\) to 1 to keep clusters
compact.</p>

<p>Now, let us take a look at what the above choices entail. The following figure
illustrates the prior for the mean of a component:</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/mixture-prior-mu-1.svg" alt="" /></p>

<p>The negative part is unrealistic for velocity; however, it is rarely a problem
in practice. What is important is that there is a generous coverage of the
plausible values. The following figure shows the prior for the standard
deviation of a component:</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/mixture-prior-sigma-1.svg" alt="" /></p>

<p>The bulk is below the standard deviation of the data; however, this is by
choice: we expect more than one cluster of galaxies with similar velocities.</p>

<p>As mentioned earlier, we intend to include \(\lambda\) in the inference. First,
we put the following prior:</p>

\[\lambda \sim \text{Gamma}(\alpha_0, \beta_0). \tag{9}\]

<p>Note this is the rate parameterization of the Gamma family. Conditionally, this
is a conjugate prior with the following update rule for the two parameters:</p>

\[\begin{align}
\alpha_0 &amp; := \alpha_0 + m - 1 \quad \text{and} \\
\beta_0 &amp; := \beta_0 - \sum_{i = 1}^{m - 1} \ln(1 - q_i)
\end{align}\]

<p>where \(\{ q_i \}\) come from the stick-breaking construction. This is a fourth
step in the Gibbs sampler. We set \(\alpha_0\) and \(\beta_0\) to 2 and 0.1,
respectively, which entails the following prior assumption about \(\lambda\):</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/mixture-prior-lambda-1.svg" alt="" /></p>

<p>The parameter is allowed to vary freely from small to large values, as desired.</p>

<p>Having chosen all priors and their hyperparameters, we are ready to investigate
the behavior of the entire model; see Equations 6, 7, and 9. In what follows, we
shall limit the number of mixture components to 25; that is, \(m = 25\).
Furthermore, we shall perform 10000 Gibbs iterations and discard the first 1000
as a warm-up period. As before, we start without conditioning on the data to
observe draws from the prior itself. The following figure shows two sample
draws:</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/mixture-prior-check-1.svg" alt="" /></p>

<p>It can be seen that clusters of galaxies can appear anywhere in the region of
interest and can be of various sizes. We conclude that the prior is adequate.
When taking the observed velocities into account, we obtain a full posterior
distribution in the form of 9000 draws. The following shows two random draws:</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/mixture-posterior-check-1.svg" alt="" /></p>

<p>Indeed, mixture components have started to appear in the regions where there are
observations.</p>

<p>Before we proceed to the final summary of results, it is prudent to inspect
sample chains for a few parameters in order to ensure there are not problems
with convergence to the stationary distribution. The following shows the number
of occupied components among the 25 permitted:</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/mixture-posterior-k-1.svg" alt="" /></p>

<p>The chain fluctuates around a fixed level without any prominent pattern, as it
should. One can plot the actual marginal posterior distribution for the number
of components; however, it is already clear that the distribution of the number
of clusters of galaxies is mostly between 5 and 15 with a median of 10.</p>

<p>As for the concentration parameter, \(\lambda\), the chain is as follows:</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/mixture-posterior-lambda-1.svg" alt="" /></p>

<p>There is occasional turbulence, but overall, the behavior is relatively adequate</p>

<p>Let us now take a look at the posterior distributions of the first 10 components
(note the different scales on the vertical axes):</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/mixture-posterior-mu-1.svg" alt="" /></p>

<p>The components clearly exchange roles, as suggested by the multimodal nature of
the distributions. Components 1 and 2 are the most stable ones, which can be
seen by the high-density regions at around 20 and 23 (times \(10^6\) m/s),
respectively. The distributions of other components are more spread out (again,
pay attention to the scale). However, with velocities 20 and 23 out of the way,
they allow one to see more clearly smaller clusters. More specifically, they
suggest clustering at around 10, 16, and 33.</p>

<p>Lastly, we summarize the inference using the following figure where the median
distribution and a 95% uncertainty band—composed of distributions at the 0.025
and 0.975 quantiles—are plotted:</p>

<p><img src="/assets/images/2021-01-25-dirichlet-process/mixture-posterior-summary-1.svg" alt="" /></p>

<p>The aforementioned five components are visible to the naked eye. The median
curve matches well the findings in <a href="https://doi.org/10.2307/2289993">Roeder (1990)</a>. Judging by the width of the
uncertainty band, there is a lot of plausible alternatives, and it is important
to communicate this uncertainty to those who base decisions on the inference.
The ability to quantify uncertainty with such ease is a prominent advantage of
Bayesian inference.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In this article, the family of Dirichlet processes has been presented in the
context of Bayesian inference. More specifically, it has been shown how a
Dirichlet process can be utilized as a prior for an unknown discrete
distribution and as a prior for mixing distributions from a given family. In
both cases, it has been illustrated how to perform inference via a finite
approximation and the stick-breaking construction.</p>

<p>Clearly, the overall procedure is more complicated than counting observations
falling in a number of fixed bins, which is what a histogram does, or placing
kernels all over the place, which is what a kernel density estimator does.
However, “anything in life worth having is worth working for.” The advantages of
the Bayesian approach include the ability to incorporate prior knowledge, which
is crucial in situations with little data, and the ability to propagate and
quantify uncertainty, which is a must.</p>

<blockquote>
  <p>Recall that the source code of this <a href="https://github.com/IvanUkhov/blog/blob/master/_posts/2021-01-25-dirichlet-process.Rmd">notebook</a> along with auxiliary <a href="https://github.com/IvanUkhov/blog/tree/master/_scripts/2021-01-25-dirichlet-process">scripts</a>
that were used for performing the calculations presented above can be found on
GitHub. Any feedback is welcome!</p>
</blockquote>

<h1 id="acknowledgments">Acknowledgments</h1>

<p>I would like to thank <a href="https://www.mattiasvillani.com/">Mattias Villani</a> for the insightful and informative
graduate course in Bayesian statistics titled “<a href="https://github.com/mattiasvillani/AdvBayesLearnCourse">Advanced Bayesian
learning</a>,” which was the inspiration behind writing this
article, and for his guidance regarding the implementation.</p>

<h1 id="follow-up">Follow-up</h1>

<p>In June 2025, <a href="https://www.plymouth.ac.uk/staff/julian-stander">Julian Stander</a> drew my attention to a typo in the implementation
of the sampling procedure for the posterior distribution of \(\lambda\), which I
am grateful for.</p>

<h1 id="references">References</h1>

<ul>
  <li>Andrew Gelman et al., <em><a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian Data Analysis</a></em>, Chapman and
Hall/CRC, 2014.</li>
  <li>Kathryn Roeder, “<a href="https://doi.org/10.2307/2289993">Density estimation with confidence sets exemplified by
superclusters and voids in galaxies</a>,” Journal of the American
Statistical Association, 1990.</li>
  <li>Rick Durrett, <em><a href="https://services.math.duke.edu/~rtd/PTE/pte.html">Probability: Theory and Examples</a></em>, Cambridge
University Press, 2010.</li>
</ul>]]></content><author><name>Ivan Ukhov</name><email>ivan.ukhov@gmail.com</email></author><summary type="html"><![CDATA[Recall the last time you wanted to understand the distribution of given data. One alternative was to plot a histogram. However, it resulted in frustration due to the choice of the number of bins to use, which led to drastically different outcomes. Another alternative was kernel density estimation. Despite having a similar choice to make, it has the advantage of producing smooth estimates, which are more realistic for continuous quantities with regularities. However, kernel density estimation was unsatisfactory too: it did not aid in understanding the underlying structure of the data and, moreover, provided no means of quantifying the uncertainty associated with the results. In this article, we discuss a Bayesian approach to the estimation of data-generating distributions that addresses the aforementioned concerns.]]></summary></entry><entry><title type="html">Heteroscedastic Gaussian process regression</title><link href="https://blog.ivanukhov.com/2020/06/22/gaussian-process.html" rel="alternate" type="text/html" title="Heteroscedastic Gaussian process regression" /><published>2020-06-22T06:00:00+00:00</published><updated>2020-06-22T06:00:00+00:00</updated><id>https://blog.ivanukhov.com/2020/06/22/gaussian-process</id><content type="html" xml:base="https://blog.ivanukhov.com/2020/06/22/gaussian-process.html"><![CDATA[<p>Gaussian process regression is a nonparametric Bayesian technique for modeling
relationships between variables of interest. The vast flexibility and rigor
mathematical foundation of this approach make it the default choice in many
problems involving small- to medium-sized data sets. In this article, we
illustrate how Gaussian process regression can be utilized in practice. To make
the case more compelling, we consider a setting where linear regression would be
inadequate. The focus will be <em>not</em> on getting the job done as fast as possible
but on learning the technique and understanding the choices being made.</p>

<h1 id="data">Data</h1>

<p>Consider the following example taken from <a href="http://www.stat.tamu.edu/~carroll/semiregbook"><em>Semiparametric
Regression</em></a> by Ruppert <em>et al.</em>:</p>

<p><img src="/assets/images/2020-06-22-gaussian-process/data-1.svg" alt="" /></p>

<p>The figure shows 221 observations collected in a <a href="https://en.wikipedia.org/wiki/Lidar">light detection and
ranging</a> experiment. Each observation can be interpreted as the sum of
the true underlying response at the corresponding distance and random noise. It
can be clearly seen that the variance of the noise varies with the distance: the
spread is substantially larger toward the right-hand side. This phenomenon is
known as heteroscedasticity. Homoscedasticity (the absence of
heteroscedasticity) is one of the key assumptions of linear regression. Applying
linear regression to the above problem would yield suboptimal results. The
estimates of the regression coefficients would still be unbiased; however, the
standard errors of the coefficients would be incorrect and hence misleading. A
different modeling technique is needed in this case.</p>

<p>The above data set will be our running example. For formally and slightly more
generally, we assume that there is a data set of \(m\) observations:</p>

\[\left\{
  (\mathbf{x}_i, y_i): \,
  \mathbf{x}_i \in \mathbb{R}^d; \,
  y_i \in \mathbb{R}; \,
  i = 1, \dots, m
\right\}\]

<p>where the independent variable, \(\mathbf{x}\), is \(d\)-dimensional, and the
dependent variable, \(y\), is scalar. In the running example, \(d\) is 1, and
\(m\) is 221. It is time for modeling.</p>

<h1 id="model">Model</h1>

<p>To begin with, consider the following model with additive noise:</p>

\[y_i = f(\mathbf{x}_i) + \epsilon_i, \text{ for } i = 1, \dots, m. \tag{1}\]

<p>In the above, \(f: \mathbb{R}^d \to \mathbb{R}\) represents the true but unknown
underlying function, and \(\epsilon_i\) represents the perturbation of the
\(i\)th observation by random noise. In the classical linear-regression setting,
the unknown function is modeled as a linear combination of (arbitrary
transformations of) the \(d\) covariates. Instead of assuming any particular
functional form, we put a Gaussian process prior on the function:</p>

\[f(\mathbf{x}) \sim \text{Gaussian Process}\left( 0, k(\mathbf{x}, \mathbf{x}') \right).\]

<p>The above notation means that, before observing any data, the function is a draw
from a Gaussian process with zero mean and a covariance function \(k\). The
covariance function dictates the degree of correlation between two arbitrary
locations \(\mathbf{x}\) and \(\mathbf{x}'\) in \(\mathbb{R}^d\). For instance,
a frequent choice for \(k\) is the squared-exponential covariance function:</p>

\[k(\mathbf{x}, \mathbf{x}')
= \sigma_\text{process}^2 \exp\left( -\frac{\|\mathbf{x} - \mathbf{x}'\|_2^2}{2 \, \ell_\text{process}^2} \right)\]

<p>where \(\|\cdot\|_2\) stands for the Euclidean norm, \(\sigma_\text{process}^2\)
is the variance (to see this, substitute \(\mathbf{x}\) for \(\mathbf{x}'\)),
and \(\ell_\text{process}\) is known as the length scale. While the variance
parameter is intuitive, the length-scale one requires an illustration. The
parameter controls the speed with which the correlation fades with the distance.
The following figure shows 10 random draws for \(\ell_\text{process} = 0.1\):</p>

<p><img src="/assets/images/2020-06-22-gaussian-process/prior-process-short-1.svg" alt="" /></p>

<p>With \(\ell_\text{process} = 0.5\), the behavior changes to the following:</p>

<p><img src="/assets/images/2020-06-22-gaussian-process/prior-process-long-1.svg" alt="" /></p>

<p>It can be seen that it takes a greater distance for a function with a larger
length scale (<em>top</em>) to change to the same extent compared to a function with a
smaller length scale (<em>bottom</em>).</p>

<p>Let us now return to Equation 1 and discuss the error terms, \(\epsilon_i\). In
linear regression, they are modeled as independent identically distributed
Gaussian random variables:</p>

\[\epsilon_i \sim \text{Gaussian}\left( 0, \sigma_\text{noise}^2 \right),
\text{ for } i = 1, \dots, m. \tag{2}\]

<p>This is also the approach one can take with Gaussian process regression;
however, one does not have to. There are reasons to believe the problem at hand
is heteroscedastic, and it should be reflected in the model. To this end, the
magnitude of the noise is allowed to vary with the covariates:</p>

\[\epsilon_i | \mathbf{x}_i \sim \text{Gaussian}\left(0, \sigma^2_{\text{noise}, i}\right),
\text{ for } i = 1, \dots, m. \tag{3}\]

<p>The error terms are still independent (given the covariates) but not identically
distributed. At this point, one has to make a choice about the dependence of
\(\sigma_{\text{noise}, i}\) on \(\mathbf{x}_i\). This dependence could be
modeled with another Gaussian process with an appropriate link function to
ensure \(\sigma_{\text{noise}, i}\) is nonnegative. Another reasonable choice is
a generalized linear model, which is what we shall use:</p>

\[\ln \sigma^2_{\text{noise}, i} = \alpha_\text{noise} + \boldsymbol{\beta}^\intercal_\text{noise} \, \mathbf{x}_i,
\text{ for } i = 1, \dots, m, \tag{4}\]

<p>where \(\alpha\) is the intercept of the regression line, and
\(\boldsymbol{\beta} \in \mathbb{R}^d\) contains the slopes.</p>

<p>Thus far, a model for the unknown function \(f\) and a model for the noise have
been prescribed. In total, there are \(d + 3\) parameters:
\(\sigma_\text{process}\), \(\ell_\text{process}\), \(\alpha_\text{noise}\), and
\(\beta_{\text{noise}, i}\) for \(i = 1, \dots, d\). The first two are
positive, and the rest are arbitrary. The final piece is prior distributions for
these parameters.</p>

<p>The variance of the coveriance function, \(\sigma^2_\text{process}\),
corresponds to the amount of variance in the data that is explained by the
Gaussian process. It poses no particular problem and can be tackled with a
half-Gaussian or a half-Student’s t distribution:</p>

\[\sigma_\text{process} \sim \text{Half-Gaussian}\left( 0, 1 \right).\]

<p>The notation means that the standard Gaussian distribution is truncated at zero
and renormalized. The nontrivial mass around zero implied by the prior is
considered to be beneficial in this case.<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup></p>

<p>A prior for the length scale of the covariance function,
\(\ell_\text{process}\), should be chosen with care. Small values—especially,
those below the resolution of the data—give the Gaussian process extreme
flexibility and easily leads to overfitting. Moreover, there are numerical
ramifications of the length scale approaching zero as well: the quality of
Hamiltonian Monte Carlo sampling degrades.<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> The bottom line is that a prior
penalizing values close to zero is needed. A reasonable choice is an inverse
gamma distribution:</p>

\[\ell_\text{process} \sim \text{Inverse Gamma}\left( 1, 1 \right).\]

<p>To understand the implications, let us perform a prior predictive check for this
component in isolation:</p>

<p><img src="/assets/images/2020-06-22-gaussian-process/prior-process-length-scale-1.svg" alt="" /></p>

<p>It can be seen that the density is very low in the region close to zero, while
being rather permissive to the right of that region, especially considering the
scale of the distance in the data; recall the very first figure. Consequently,
the choice is adequate.</p>

<p>The choice of priors for the parameters of the noise is complicated by the
nonlinear link function; see Equation 4. What is important to realize is that
small amounts of noise correspond to negative values in the linear space, which
is probably what one should be expecting given the scale of the response.
Therefore, the priors should allow for large negative values. Let us make an
educated assumption and perform a prior predictive check to understand the
consequences. Consider the following:</p>

\[\begin{align}
\alpha_\text{noise} &amp; \sim \text{Gaussian}\left( -1, 1 \right) \text{ and} \\
\beta_{\text{noise}, i} &amp; \sim \text{Gaussian}\left( 0, 1 \right),
\text{ for } i = 1, \dots, d.\\
\end{align}\]

<p>The density of \(\sigma_\text{noise}\) without considering the regression slopes
is depicted below (note the logarithmic scale on the horizontal axis):</p>

<p><img src="/assets/images/2020-06-22-gaussian-process/prior-noise-sigma-1.svg" alt="" /></p>

<p>The variability in the intercept, \(\alpha_\text{noise}\), allows the standard
deviation, \(\sigma_\text{noise}\), to comfortably vary from small to large
values, keeping in mind the scale of the response. Here are two draws from the
prior distribution of the noise, including Equations 3 and 4:</p>

<p><img src="/assets/images/2020-06-22-gaussian-process/prior-noise-1.svg" alt="" /></p>

<p>The large ones are perhaps unrealistic and could be addressed by further
shifting the distribution of the intercept. However, they should not cause
problems for the inference.</p>

<p>Putting everything together, the final model is as follows:</p>

\[\begin{align}
y_i
&amp; = f(\mathbf{x}_i) + \epsilon_i,
\text{ for } i = 1, \dots, m; \\

f(\mathbf{x})
&amp; \sim \text{Gaussian Process}\left( 0, k(\mathbf{x}, \mathbf{x}') \right); \\

k(\mathbf{x}, \mathbf{x}')
&amp; = \sigma_\text{process}^2 \exp\left( -\frac{\|\mathbf{x} - \mathbf{x}'\|_2^2}{2 \, \ell_\text{process}^2} \right); \\

\epsilon_i | \mathbf{x}_i
&amp; \sim \text{Gaussian}\left( 0, \sigma^2_{\text{noise}, i} \right),
\text{ for } i = 1, \dots, m; \\

\ln \sigma^2_{\text{noise}, i}
&amp; = \alpha_\text{noise} + \boldsymbol{\beta}_\text{noise}^\intercal \, \mathbf{x}_i,
\text{ for } i = 1, \dots, m; \\

\sigma_\text{process}
&amp; \sim \text{Half-Gaussian}\left( 0, 1 \right); \\

\ell_\text{process}
&amp; \sim \text{Inverse Gamma}\left( 1, 1 \right); \\

\alpha_\text{noise}
&amp; \sim \text{Gaussian}\left( -1, 1 \right); \text{ and} \\

\beta_{\text{noise}, i}
&amp; \sim \text{Gaussian}\left( 0, 1 \right),
\text{ for } i = 1, \dots, d.\\
\end{align}\]

<p>This concludes the modeling part. The remaining two steps are to infer the
parameters and to make predictions using the posterior predictive distribution.</p>

<h1 id="inference">Inference</h1>

<p>The model is analytically intractable; one has to resort to sampling or
variational methods for inferring the parameters. We shall use Hamiltonian
Markov chain Monte Carlo sampling via <a href="https://mc-stan.org/">Stan</a>. The model can be seen in the
following listing, where the notation closely follows the one used throughout
the article:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="p">{</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span> <span class="o">=</span> <span class="mi">1</span><span class="o">&gt;</span> <span class="n">d</span><span class="p">;</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span> <span class="o">=</span> <span class="mi">1</span><span class="o">&gt;</span> <span class="n">m</span><span class="p">;</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="n">x</span><span class="p">[</span><span class="n">m</span><span class="p">];</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="n">y</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">transformed</span> <span class="n">data</span> <span class="p">{</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">rep_vector</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">m</span><span class="p">);</span>
  <span class="n">matrix</span><span class="p">[</span><span class="n">m</span><span class="p">,</span> <span class="n">d</span><span class="p">]</span> <span class="n">X</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="err">'</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="n">parameters</span> <span class="p">{</span>
  <span class="n">real</span><span class="o">&lt;</span><span class="n">lower</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span> <span class="n">sigma_process</span><span class="p">;</span>
  <span class="n">real</span><span class="o">&lt;</span><span class="n">lower</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span> <span class="n">ell_process</span><span class="p">;</span>
  <span class="n">real</span> <span class="n">alpha_noise</span><span class="p">;</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="n">beta_noise</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">model</span> <span class="p">{</span>
  <span class="n">matrix</span><span class="p">[</span><span class="n">m</span><span class="p">,</span> <span class="n">m</span><span class="p">]</span> <span class="n">K</span> <span class="o">=</span> <span class="n">cov_exp_quad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sigma_process</span><span class="p">,</span> <span class="n">ell_process</span><span class="p">);</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="n">sigma_noise_squared</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">alpha_noise</span> <span class="o">+</span> <span class="n">X</span> <span class="o">*</span> <span class="n">beta_noise</span><span class="p">);</span>
  <span class="n">matrix</span><span class="p">[</span><span class="n">m</span><span class="p">,</span> <span class="n">m</span><span class="p">]</span> <span class="n">L</span> <span class="o">=</span> <span class="n">cholesky_decompose</span><span class="p">(</span><span class="n">add_diag</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">sigma_noise_squared</span><span class="p">));</span>

  <span class="n">y</span> <span class="o">~</span> <span class="n">multi_normal_cholesky</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">L</span><span class="p">);</span>
  <span class="n">sigma_process</span> <span class="o">~</span> <span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
  <span class="n">ell_process</span> <span class="o">~</span> <span class="n">inv_gamma</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
  <span class="n">alpha_noise</span> <span class="o">~</span> <span class="n">normal</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
  <span class="n">beta_noise</span> <span class="o">~</span> <span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>In the <code class="language-plaintext highlighter-rouge">parameters</code> block, one can find the \(d + 3\) parameters identified
earlier. In regards to the <code class="language-plaintext highlighter-rouge">model</code> block, it is worth noting that there is no
any Gaussian process distribution in Stan. Instead, a multivariate Gaussian
distribution is utilized to model \(f\) at \(\mathbf{X} = (\mathbf{x}_i)_{i =
1}^m \in \mathbb{R}^{m \times d}\) and eventually \(\mathbf{y} = (y_i)_{i =
1}^m\), which is for a good reason. Even though a Gaussian process is an
infinite-dimensional object, in practice, one always works with finite amounts
of data. For instance, in the running example, there are only 221 data points.
By definition, a Gaussian process is a stochastic process with the condition
that any finite collection of points from this process has a multivariate
Gaussian distribution. This fact combined with the conditional independence of
the process and the noise given the covariates yields the following and explains
the usage of a multivariate Gaussian distribution:</p>

\[\mathbf{y} | \mathbf{X}, \sigma_\text{process}, \ell_\text{process}, \alpha_\text{noise}, \boldsymbol{\beta}_\text{noise}
\sim \text{Multivariate Gaussian}\left( \mathbf{0}, \mathbf{K} + \mathbf{D} \right)\]

<p>where \(\mathbf{K} \in \mathbb{R}^{m \times m}\) is a covariance matrix computed
by evaluating the covariance function \(k\) at all pairs of locations in the
observed data, and \(\mathbf{D} = \text{diag}(\sigma^2_{\text{noise}, i})_{i =
1}^m \in \mathbb{R}^{m \times m}\) is a diagonal matrix of the variances of the
noise at the corresponding locations.</p>

<p>After running the inference, the following posterior distributions are obtained:</p>

<p><img src="/assets/images/2020-06-22-gaussian-process/posterior-parameters-1.svg" alt="" /></p>

<p>The intervals are at the bottom of the densities are 66% and 95% equal-tailed
probability intervals, and the dots indicate the medians. Let us also take a
look at the 95% probability interval for the noise with respect to the distance:</p>

<p><img src="/assets/images/2020-06-22-gaussian-process/posterior-predictive-noise-1.svg" alt="" /></p>

<p>As expected, the variance of the noise increases with the distance.</p>

<h1 id="prediction">Prediction</h1>

<p>Suppose there are \(n\) locations \(\mathbf{X}_\text{new} =
(\mathbf{x}_{\text{new}, i})_{i = 1}^n \in \mathbb{R}^{n \times d}\) where one
wishes to make predictions. Let \(\mathbf{f}_\text{new} \in \mathbb{R}^n\) be
the values of \(f\) at those locations. Assuming all the data and parameters
given, the joint distribution of \(\mathbf{y}\) and \(\mathbf{f}_\text{new}\) is
as follows:</p>

\[\left[
  \begin{matrix}
    \mathbf{y} \\
    \mathbf{f}_\text{new}
  \end{matrix}
\right]
\sim \text{Multivariate Gaussian}\left(
  \mathbf{0},
  \left[
    \begin{matrix}
      \mathbf{K} + \mathbf{D} &amp; k(\mathbf{X}, \mathbf{X}_\text{new}) \\
      k(\mathbf{X}_\text{new}, \mathbf{X}) &amp; k(\mathbf{X}_\text{new}, \mathbf{X}_\text{new})
    \end{matrix}
  \right]
\right)\]

<p>where, with a slight abuse of notation, \(k(\cdot, \cdot)\) stands for a
covariance matrix computed by evaluating the covariance function \(k\) at the
specified locations, which is analogous to \(\mathbf{K}\). It is well known (see
<a href="http://www.gaussianprocess.org/gpml">Rasmussen et al. 2006</a>, for instance) that the marginal
distribution of \(\mathbf{f}_\text{new}\) is a multivariate Gaussian with the
following mean vector and covariance matrix, respectively:</p>

\[\begin{align}
E(\mathbf{f}_\text{new})
&amp; = k(\mathbf{X}_\text{new}, \mathbf{X})(\mathbf{K} + \mathbf{D})^{-1} \, \mathbf{y} \quad \text{and} \\
\text{cov}(\mathbf{f}_\text{new})
&amp; = k(\mathbf{X}_\text{new}, \mathbf{X}_\text{new})
- k(\mathbf{X}_\text{new}, \mathbf{X})(\mathbf{K} + \mathbf{D})^{-1} k(\mathbf{X}, \mathbf{X}_\text{new}).
\end{align}\]

<p>The final component is the noise, as per Equation 1. The noise does not change
the mean of the multivariate Gaussian distribution but does magnify the
variance:</p>

\[\begin{align}
E(\mathbf{y}_\text{new})
&amp; = k(\mathbf{X}_\text{new}, \mathbf{X})(\mathbf{K} + \mathbf{D})^{-1} \, \mathbf{y} \quad \text{and} \\
\text{cov}(\mathbf{y}_\text{new})
&amp; = k(\mathbf{X}_\text{new}, \mathbf{X}_\text{new})
- k(\mathbf{X}_\text{new}, \mathbf{X})(\mathbf{K} + \mathbf{D})^{-1} k(\mathbf{X}, \mathbf{X}_\text{new})
+ \text{diag}(\sigma^2_\text{noise}(\mathbf{X}_\text{new}))
\end{align}\]

<p>where \(\text{diag}(\sigma^2_\text{noise}(\cdot))\) stands for a diagonal matrix
composed of the noise variance evaluated at the specified locations, which is
analogous to \(\mathbf{D}\).</p>

<p>Given a set of draws from the joint posterior distribution of the parameters and
the last two expressions, it is now straightforward to draw samples from the
posterior predictive distribution of the response: for each draw of the
parameters, one has to evaluate the mean vector and the covariance matrix and
sample the corresponding multivariate Gaussian distribution. The result is given
in the following figure:</p>

<p><img src="/assets/images/2020-06-22-gaussian-process/posterior-predictive-heteroscedastic-1.svg" alt="" /></p>

<p>The graph shows the mean value of the posterior predictive distribution given by
the black line along with a 95% equal-tailed probability band about the mean. It
can be seen that the uncertainty in the predictions is adequately captured along
the entire support. Naturally, the full predictive posterior distribution is
available at any location of interest.</p>

<p>Before we conclude, let us illustrate what would happen if the data were modeled
as having homogeneous noise. To this end, the variance of the noise is assumed
to be independent of the covariates, as in Equation 2. After repeating the
inference and prediction processes, the following is obtained:</p>

<p><img src="/assets/images/2020-06-22-gaussian-process/posterior-predictive-homoscedastic-1.svg" alt="" /></p>

<p>The inference is inadequate, which can be seen by the probability band: the
variance is largely overestimated on the left-hand side and underestimated on
the right-hand side. This justifies well the choice of heteroscedastic
regression presented earlier.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In this article, it has been illustrated how a functional relationship can be
modeled using a Gaussian process as a prior. Particular attention has been
dedicated to adequately capturing error terms in the presence of
heteroscedasticity. In addition, a practical implementation has been discussed,
and the experimental results have demonstrated the appropriateness of this
approach.</p>

<p>For the curious reader, the source code of this <a href="https://github.com/IvanUkhov/blog/blob/master/_posts/2020-06-22-gaussian-process.Rmd">notebook</a> along with a number
of auxiliary <a href="https://github.com/IvanUkhov/blog/tree/master/_scripts/2020-06-22-gaussian-process">scripts</a>, such as the definition of the model in Stan, can be
found on GitHub.</p>

<h1 id="acknowledgments">Acknowledgments</h1>

<p>I would like to thank <a href="https://www.mattiasvillani.com/">Mattias Villani</a> for the insightful and informative
graduate course in statistics titled “<a href="https://github.com/mattiasvillani/AdvBayesLearnCourse">Advanced Bayesian learning</a>,” which was the inspiration behind writing this article.</p>

<h1 id="references">References</h1>

<ul>
  <li>Carl Rasmussen <em>et al.</em>, <a href="http://www.gaussianprocess.org/gpml"><em>Gaussian Processes for Machine
Learning</em></a>, the MIT Press, 2006.</li>
  <li>David Ruppert <em>et al.</em>, <a href="http://www.stat.tamu.edu/~carroll/semiregbook"><em>Semiparametric Regression</em></a>, Cambridge
University Press, 2003.</li>
</ul>

<h1 id="footnotes">Footnotes</h1>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>“<a href="https://mc-stan.org/docs/2_19/stan-users-guide/fit-gp-section.html#priors-for-marginal-standard-deviation">Priors for marginal standard deviation</a>,”
  Stan User’s Guide, 2020. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>“<a href="https://mc-stan.org/docs/2_19/stan-users-guide/fit-gp-section.html#priors-for-length-scale">Priors for length-scale</a>,” Stan User’s Guide,
  2020. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Ivan Ukhov</name><email>ivan.ukhov@gmail.com</email></author><summary type="html"><![CDATA[Gaussian process regression is a nonparametric Bayesian technique for modeling relationships between variables of interest. The vast flexibility and rigor mathematical foundation of this approach make it the default choice in many problems involving small- to medium-sized data sets. In this article, we illustrate how Gaussian process regression can be utilized in practice. To make the case more compelling, we consider a setting where linear regression would be inadequate. The focus will be not on getting the job done as fast as possible but on learning the technique and understanding the choices being made.]]></summary></entry><entry><title type="html">What is the easiest way to compare two data sets?</title><link href="https://blog.ivanukhov.com/2020/04/10/comparison.html" rel="alternate" type="text/html" title="What is the easiest way to compare two data sets?" /><published>2020-04-10T06:00:00+00:00</published><updated>2020-04-10T06:00:00+00:00</updated><id>https://blog.ivanukhov.com/2020/04/10/comparison</id><content type="html" xml:base="https://blog.ivanukhov.com/2020/04/10/comparison.html"><![CDATA[<p>One has probably come across this problem numerous times. There are two versions
of a tabular data set with a lot of columns of different types, and one wants to
quickly identify any differences between the two. For example, the pipeline
providing data to a predictive model might have been updated, and the goal is to
understand if there have been any side effects of this update for the training
data.</p>

<p>One solution is to start to iterate over the columns of the two tables,
computing five-number summaries and plotting histograms or identifying distinct
values and plotting bar charts, depending on the column’s type. However, this
can quickly get out of hand and evolve into an endeavor for the rest of the day.</p>

<p>An alternative is to leverage the amazing tools that already exist in the data
community.</p>

<h1 id="solution">Solution</h1>

<p>The key takeaway is the following three lines of code, excluding the import:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow_data_validation</span> <span class="k">as</span> <span class="n">dv</span>

<span class="n">statistics_1</span> <span class="o">=</span> <span class="n">dv</span><span class="p">.</span><span class="nf">generate_statistics_from_dataframe</span><span class="p">(</span><span class="n">data_1</span><span class="p">)</span>
<span class="n">statistics_2</span> <span class="o">=</span> <span class="n">dv</span><span class="p">.</span><span class="nf">generate_statistics_from_dataframe</span><span class="p">(</span><span class="n">data_2</span><span class="p">)</span>
<span class="n">dv</span><span class="p">.</span><span class="nf">visualize_statistics</span><span class="p">(</span><span class="n">lhs_statistics</span><span class="o">=</span><span class="n">statistics_1</span><span class="p">,</span>
                        <span class="n">rhs_statistics</span><span class="o">=</span><span class="n">statistics_2</span><span class="p">)</span>
</code></pre></div></div>

<p>This is all it takes to get a versatile dashboard embedded right into a cell of
a Jupyter notebook. The visualization itself is based on <a href="https://pair-code.github.io/facets">Facets</a>, and it is
conveniently provided by <a href="https://www.tensorflow.org/tfx/data_validation/get_started">TensorFlow Data Validation</a> (which does not have much
to do with TensorFlow and can be used stand-alone).</p>

<p>It is pointless to try to describe in words what the dashboard can do; instead,
here is a demonstration taken from <a href="https://pair-code.github.io/facets">Facets</a> where the tool is applied the <a href="http://archive.ics.uci.edu/ml/datasets/Census+Income">UCI
Census Income</a> data set:</p>

<div id="facets-overview-container"></div>

<p>Go ahead and give a try to all the different controls!</p>

<p>In this case, it is helpful to toggle the “percentages” checkbox, since the data
sets are of different sizes. Then it becomes apparent that the two partitions
are fairly balanced. The only problem is that <code class="language-plaintext highlighter-rouge">Target</code>, which represents income,
happened to be encoded incorrectly in the partition for testing.</p>

<p>Lastly, an example in a Jupyter notebook can be found on <a href="https://github.com/chain-rule/example-comparison/blob/master/census.ipynb">GitHub</a>.</p>

<h1 id="conclusion">Conclusion</h1>

<p>It can be difficult to navigate and particularly challenging to compare wide
data sets. A lot of effort can be put into this exercise. However, the landscape
of open-source tools has a lot to offer too. Facets is one such example. The
library and its straightforward availability via TensorFlow Data Validation are
arguably less known. This short note can hopefully rectify this to some extent.</p>]]></content><author><name>Ivan Ukhov</name><email>ivan.ukhov@gmail.com</email></author><summary type="html"><![CDATA[One has probably come across this problem numerous times. There are two versions of a tabular data set with a lot of columns of different types, and one wants to quickly identify any differences between the two. For example, the pipeline providing data to a predictive model might have been updated, and the goal is to understand if there have been any side effects of this update for the training data.]]></summary></entry><entry><title type="html">Bayesian inference of the net promoter score via multilevel regression with poststratification</title><link href="https://blog.ivanukhov.com/2020/02/03/net-promoter.html" rel="alternate" type="text/html" title="Bayesian inference of the net promoter score via multilevel regression with poststratification" /><published>2020-02-03T07:00:00+00:00</published><updated>2020-02-03T07:00:00+00:00</updated><id>https://blog.ivanukhov.com/2020/02/03/net-promoter</id><content type="html" xml:base="https://blog.ivanukhov.com/2020/02/03/net-promoter.html"><![CDATA[<p>Customer surveys are naturally prone to biases. One prominent example is
participation bias, which arises when individuals decide not to respond to the
survey, and this pattern is not random. For instance, new customers might reply
less eagerly than those who are senior. This renders the obtained responses
unrepresentative of the target population. In this article, we tackle
participation bias for the case of the net promoter survey by means of
multilevel regression and poststratification.</p>

<p>More specifically, the discussion here is a sequel to “<a href="/2019/08/19/net-promoter.html">A Bayesian approach to
the inference of the net promoter score</a>,” where we built a
hierarchical model for inferring the net promoter score for an arbitrary
segmentation of a customer base. The reader is encouraged to skim over that
article to recall the mechanics of the score and the structure of the model that
was constructed. In that article, there was an assumption made that the sample
was representative of the population, which, as mentioned earlier, is often not
the case. In what follows, we mitigate this problem using a technique called
poststratification. The technique works by matching proportions observed in the
sample with those observed in the population with respect to several dimensions,
such as age, country, and gender. However, in order to be able to poststratify,
the model has to have access to all these dimensions at once, which the model
built earlier is not suited for. To enable this, we switch gears to multilevel
multinomial regression.</p>

<h1 id="problem">Problem</h1>

<p>Suppose the survey is to measure the net promoter score for a population that
consists of \(N\) customers. The score is to be reported with respect to
individual values of \(M\) grouping variables where variable \(i\) has \(m_i\)
possible values, for \(i = 1, \dots, M\). For instance, it might be important to
know the score for different age groups, in which case the variable would be the
customer’s age with values such as 18–25, 26–35, and so on. This implies that,
in total, \(\sum_i m_i\) scores have to be estimated.</p>

<p>Depending on the size of the business, one might or might not try to reach out
to all customers, except for those who have opted out of communications.
Regardless of the decision, the resulting sample size, which is denoted by
\(n\), is likely to be substantially smaller than \(N\), as the response rate is
typically low. Therefore, there is uncertainty about the opinion of those who
abstained or were not targeted.</p>

<p>More importantly, a random sample is desired; however, certain subpopulations of
customers might end up being significantly overrepresented due to participation
bias, driving the score astray. Let us quantify this concern. We begin by taking
the Cartesian product of the aforementioned \(M\) variables. This results in \(K
= \prod_i m_i\) distinct combinations of the variables’ values, which are
referred to as cells in what follows. For each cell, the number of detractors,
neutrals, and promoters observed in the sample are computed and denoted by
\(d_i\), \(u_i\), and \(p_i\), respectively. The number of respondents in cell
\(i\) is then</p>

\[n_i = d_i + u_i + p_i \tag{1}\]

<p>for \(i = 1, \dots, K\). For convenience, all counts are arranged in the
following matrix:</p>

\[y = \left(
\begin{matrix}
y_1 \\
\vdots \\
y_i \\
\vdots \\
y_K
\end{matrix}
\right)
= \left(
\begin{matrix}
d_1 &amp; u_1 &amp; p_1 \\
\vdots &amp; \vdots &amp; \vdots \\
d_i &amp; u_i &amp; p_i \\
\vdots &amp; \vdots &amp; \vdots \\
d_K &amp; u_K &amp; p_K
\end{matrix}
\right). \tag{2}\]

<p>Given \(y\), the observed net promoter score for value \(j\) of variable \(i\)
can be evaluated as follows:</p>

\[s^i_j = 100 \times \frac{\sum_{k \in I^i_j}(p_k - d_k)}{\sum_{k \in I^i_j} n_k} \tag{3}\]

<p>where \(I^i_j\) is an index set traversing cells with variable \(i\) set to
value \(j\), which has the effect of marginalizing out other variables
conditioned on the chosen value of variable \(i\), that is, on value \(j\).</p>

<p>We can now compare \(n_i\), computed according to Equation 1, with its
counterpart in the population (the total number of customers who belong to cell
\(i\)), which is denoted by \(N_i\), taking into consideration the sample size
\(n\) and the population size \(N\). Problems occur when the ratios within one
or more of the following tuples largely disagree:</p>

\[\left(\frac{n_i}{n}, \frac{N_i}{N}\right) \tag{4}\]

<p>for \(i = 1, \dots, K\). When this happens, the scores given by Equation 3 or
any analyses oblivious of this disagreement cannot be trusted, since they
misrepresent the population. (It should be noted, however, that equality within
each tuple does not guarantee the absence of participation bias, since there
might be other, potentially unobserved, dimensions along which there are
deviations.)</p>

<p>The survey has been conducted, and there are deviations. What do we do with all
these responses that have come in? Should we discard and run a new survey,
hoping that, this time, it would be different?</p>

<h1 id="solution">Solution</h1>

<p>The fact that the sample covers only a fraction of the population is, of course,
no news, and the solution is standard: one has to infer the net promoter score
for the population given the sample and domain knowledge. This is what was done
in the <a href="/2019/08/19/net-promoter.html">previous article</a> for one grouping variable. However, due to
participation bias, additional measures are needed as follows.</p>

<p>Taking inspiration from political science, we proceed in two steps.</p>

<ol>
  <li>
    <p>Using an adequate model, \(K = \prod_i m_i\) net promoter scores are
inferred—one for each cell, that is, for each combination of the values of
the grouping variables.</p>
  </li>
  <li>
    <p>The \(\prod_i m_i\) “cell-scores” are combined to produce \(\sum_i m_i\)
“value-scores”—one for each value of each variable. This is done in such a
way that the contribution of each cell to the score is equal to the relative
size of that cell in the population given by Equation 4.</p>
  </li>
</ol>

<p>The two steps are discussed in the following two subsections.</p>

<h2 id="modeling">Modeling</h2>

<p>Step 1 can, in principle, be undertaken by any model of choice. A prominent
candidate is multilevel multinomial regression, which is what we shall explore.
<em>Multilevel</em> refers to having a hierarchical structure where parameters on a
higher level give birth to parameters on a lower level, which, in particular,
enables information exchange through a common ancestor. <em>Multinomial</em> refers to
the distribution used for modeling the response variable. The family of
multinomial distributions is appropriate, since we work with counts of events
falling into one of several categories: detractors, neutrals, and promoters; see
Equation 2. The response for each cell is then as follows:</p>

\[y_i | \theta_i \sim \text{Multinomial}(n_i, \theta_i)\]

<p>where \(n_i\) is given by Equation 1, and</p>

\[\theta_i = \left\langle\theta^d_i, \theta^u_i, \theta^p_i\right\rangle\]

<p>is a simplex (sums up to one) of probabilities of the three categories.</p>

<p>Multinomial regression belongs to the class of generalized linear models. This
means that the inference takes place in a linear domain, and that \(\theta_i\)
is obtained by applying a deterministic transformation to the corresponding
linear model or models; the inverse of this transformation is known as the link
function. In the case of multinomial regression, the aforementioned
transformation is the softmax function, which is a generalization of the
logistic function allowing more than two categories:</p>

\[\theta_i = \text{Softmax}\left(\mu_i\right)\]

<p>where</p>

\[\mu_i = \left(0, \mu^u_i, \mu^p_i\right)\]

<p>is the average log-odds of the three categories with respect to a reference
category, which, by conventions, is taken to be the first one, that is,
detractors. The first entry is zero, since \(\ln(1) = 0\). Therefore, there are
only two linear models: one is for neutrals (\(\mu^u_i\)), and one is for
promoters (\(\mu^p_i\)).</p>

<p>Now, there are many alternatives when it comes to the two linear parts. In this
article, we use the following architecture. Both the model for neutrals and the
one for promoters have the same structure, and for brevity, only the former is
described. For the log-odds of neutrals, the model is</p>

\[\mu^u_i = b^u + \sum_{j = 1}^M \delta^{uj}_{I_j[i]}\]

<p>where</p>

\[\delta^{uj} = \left(\delta^{uj}_1, \dots, \delta^{uj}_{m_j}\right)\]

<p>is a vector of deviations from intercept \(b^u\) specific to grouping variable
\(j\) (one entry for each value of the variable), and \(I_j[i]\) yields the
index of the value that cell \(i\) has, for \(i = 1, \dots, K\) and \(j = 1,
\dots, M\).</p>

<p>Let us now turn to the multilevel aspect. For each grouping variable, the
corresponding values, represented by the elements of \(\delta^{uj}\), are
allowed to be different but assumed to have something in common and thus
originate from a common distribution. To this end, they are assigned
distributions with a shared parameter as follows:</p>

\[\delta^{uj}_i | \sigma^{uj} \sim \text{Gaussian}\left(0, \sigma^{uj}\right)\]

<p>for \(i = 1, \dots, m_j\). The mean is zero, since \(\delta^{uj}_i\) represents
a deviation.</p>

<p>Lastly, we have to decide on prior distributions of the intercept, \(b^u\), and
the standard deviations, \(\sigma^{uj}\) for \(j = 1, \dots, M\). The intercept
is given the following prior:</p>

\[b^u \sim \text{Student’s t}(5, 0, 1).\]

<p>The mean is zero in order to center at even odds. Regarding the standard
deviations, they are given the following prior:</p>

\[\sigma^{uj} \sim \text{Half-Student’s t}(5, 0, 1).\]

<p>In order to understand the implications of these prior choices, let us take a
look at the prior distribution assuming two grouping variables:</p>

<p><img src="/assets/images/2020-02-03-net-promoter/prior-distribution-1.svg" alt="" /></p>

<p>The left and right dashed lines demarcate tail regions that, for practical
purposes, can be thought of as “never” and “always,” respectively. For instance,
log-odds of five or higher are so extreme that detractors are rendered nearly
non-existent when compared to neutrals. These regions are arguably unrealistic.
The prior does not exclude these possibilities; however, it does not favor them
either. The vast majority of the probability mass is still in the middle around
zero.</p>

<p>The overall model is then as follow:</p>

\[\begin{align}
&amp; y_i | \theta_i \sim \text{Multinomial}(n_i, \theta_i),
\text{ for } i = 1, \dots, K; \\
&amp; \theta_i = \text{Softmax}\left(\mu_i\right),
\text{ for } i = 1, \dots, K; \\
&amp; \mu_i = (0, \mu^u_i, \mu^p_i),
\text{ for } i = 1, \dots, K; \\
&amp; \mu^u_i = b^u + \sum_{j = 1}^M \delta^{uj}_{I_j[i]},
\text{ for } i = 1, \dots, K; \\
&amp; \mu^p_i = b^p + \sum_{j = 1}^M \delta^{pj}_{I_j[i]},
\text{ for } i = 1, \dots, K; \\
&amp; b^u \sim \text{Student’s t}(5, 0, 1); \\
&amp; b^p \sim \text{Student’s t}(5, 0, 1); \\
&amp; \delta^{uj}_k | \sigma^{uj} \sim \text{Gaussian}\left(0, \sigma^{uj}\right),
\text{ for } j = 1, \dots, M \text{ and } k = 1, \dots, m_j; \tag{5a} \\
&amp; \delta^{pj}_k | \sigma^{pj} \sim \text{Gaussian}\left(0, \sigma^{pj}\right),
\text{ for } j = 1, \dots, M \text{ and } k = 1, \dots, m_j; \tag{5b} \\
&amp; \sigma^{uj} \sim \text{Half-Student’s t}(5, 0, 1),
\text{ for } j = 1, \dots, M; \text{ and} \\
&amp; \sigma^{pj} \sim \text{Half-Student’s t}(5, 0, 1),
\text{ for } j = 1, \dots, M.
\end{align}\]

<p>The model has \(2 \times (1 + \sum_i m_i + M)\) parameters in total. The
structure that can be seen in Equations 5a and 5b is what makes the model
multilevel. This is an important feature, since it allows for information
sharing between the individual values of the grouping variables. In particular,
this has a regularizing effect on the estimates, which is also known as
shrinkage resulting from partial pooling.</p>

<p>Having defined the model, the posterior distribution can now be obtained by
means of Markov chain Monte Carlo sampling. This procedure is standard and can
be performed using, for instance, Stan or a higher-level package, such as
<a href="https://github.com/paul-buerkner/brms"><code class="language-plaintext highlighter-rouge">brms</code></a>, which is what is exemplified in the Implementation section. The result
is a collection of draws of the parameters from the posterior distribution. For
each draw of the parameters, a draw of the net promoter score can be computed
using the following formula:</p>

\[s_i = 100 \times (\theta^p_i - \theta^d_i) \tag{6}\]

<p>for \(i = 1, \dots, K\). This means that we have obtained a (joint) posterior
distribution of the net promoter score over the \(K\) cells. It is now time to
combine the scores for the cells on the level of the values of the \(M\)
grouping variables, which results in \(\sum_i m_i\) scores in total.</p>

<h2 id="poststratification">Poststratification</h2>

<p>Step 2 is poststratification, whose purpose is to correct for potential
deviations of the sample from the population; recall the discussion around
Equation 4. The foundation laid in the previous subsection makes the work here
straightforward. The idea is as follows. Each draw from the posterior
distribution consists of \(K\) values for the net promoter score, one for each
cell. All one has to do in order to correct for a mismatch in proportions is to
take a weighted average of these scores where the weights are the counts
observed in the population:</p>

\[s^i_j = \frac{\sum_{k \in I^i_j} N_k \, s_k}{\sum_{k \in I^i_j} N_k}\]

<p>where \(I^i_j\) is as in Equation 3, for \(i = 1, \dots, M\) and \(j = 1,
\dots, m_i\). The above gives a poststratified draw from the posterior
distribution of the net promoter score for variable \(i\) and value \(j\). In
practice, depending on the tool used, one might perform the poststratification
procedure differently, such as predicting counts of detractors, neutrals, and
promoters in the cells given their in-population sizes and then aggregating
those counts and following the definition of the net promoter score.</p>

<h1 id="implementation">Implementation</h1>

<p>In what follows, we consider a contrived example with the sole purpose of
illustrating how the presented workflow can be implemented in practice. To this
end, we generate some data with two grouping variables, age and seniority, and
then perform inference using <a href="https://github.com/paul-buerkner/brms"><code class="language-plaintext highlighter-rouge">brms</code></a>, which leverages Stan under the hood. For
a convenient manipulation of posterior draws, <a href="https://github.com/mjskay/tidybayes"><code class="language-plaintext highlighter-rouge">tidybayes</code></a> is used as well.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">brms</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">tidybayes</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span><span class="w">

</span><span class="n">set.seed</span><span class="p">(</span><span class="m">42</span><span class="p">)</span><span class="w">
</span><span class="n">options</span><span class="p">(</span><span class="n">mc.cores</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">parallel</span><span class="o">::</span><span class="n">detectCores</span><span class="p">())</span><span class="w">

</span><span class="c1"># Load data</span><span class="w">
</span><span class="n">data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">load_data</span><span class="p">()</span><span class="w">
</span><span class="c1"># =&gt; list(</span><span class="w">
</span><span class="c1"># =&gt;   population = tibble(age, seniority, cell_size),</span><span class="w">
</span><span class="c1"># =&gt;   sample = tibble(age, seniority, cell_size,</span><span class="w">
</span><span class="c1"># =&gt;                   cell_counts = (detractors, neutrals, promoters))</span><span class="w">
</span><span class="c1"># =&gt; )</span><span class="w">

</span><span class="c1"># Modeling</span><span class="w">
</span><span class="n">priors</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="w">
  </span><span class="n">prior</span><span class="p">(</span><span class="s1">'student_t(5, 0, 1)'</span><span class="p">,</span><span class="w"> </span><span class="n">class</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'Intercept'</span><span class="p">,</span><span class="w"> </span><span class="n">dpar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'muneutral'</span><span class="p">),</span><span class="w">
  </span><span class="n">prior</span><span class="p">(</span><span class="s1">'student_t(5, 0, 1)'</span><span class="p">,</span><span class="w"> </span><span class="n">class</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'Intercept'</span><span class="p">,</span><span class="w"> </span><span class="n">dpar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'mupromoter'</span><span class="p">),</span><span class="w">
  </span><span class="n">prior</span><span class="p">(</span><span class="s1">'student_t(5, 0, 1)'</span><span class="p">,</span><span class="w"> </span><span class="n">class</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'sd'</span><span class="p">,</span><span class="w"> </span><span class="n">dpar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'muneutral'</span><span class="p">),</span><span class="w">
  </span><span class="n">prior</span><span class="p">(</span><span class="s1">'student_t(5, 0, 1)'</span><span class="p">,</span><span class="w"> </span><span class="n">class</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'sd'</span><span class="p">,</span><span class="w"> </span><span class="n">dpar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'mupromoter'</span><span class="p">)</span><span class="w">
</span><span class="p">)</span><span class="w">
</span><span class="n">formula</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">brmsformula</span><span class="p">(</span><span class="w">
  </span><span class="n">cell_counts</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">trials</span><span class="p">(</span><span class="n">cell_size</span><span class="p">)</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">age</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">seniority</span><span class="p">))</span><span class="w">
</span><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">brm</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">$</span><span class="n">sample</span><span class="p">,</span><span class="w"> </span><span class="n">multinomial</span><span class="p">(),</span><span class="w"> </span><span class="n">priors</span><span class="p">,</span><span class="w">
             </span><span class="n">control</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">adapt_delta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.99</span><span class="p">),</span><span class="w"> </span><span class="n">seed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">42</span><span class="p">)</span><span class="w">

</span><span class="c1"># Poststratification</span><span class="w">
</span><span class="n">prediction</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data</span><span class="o">$</span><span class="n">population</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">add_predicted_draws</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">spread</span><span class="p">(</span><span class="n">.category</span><span class="p">,</span><span class="w"> </span><span class="n">.prediction</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">group_by</span><span class="p">(</span><span class="n">age</span><span class="p">,</span><span class="w"> </span><span class="n">.draw</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">summarize</span><span class="p">(</span><span class="n">score</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">promoter</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">detractor</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">cell_size</span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">mean_hdi</span><span class="p">()</span><span class="w">
</span></code></pre></div></div>

<p>The final aggregation is given for age; it is similar for seniority. It can be
seen in the above listing that modern tools allow for rather complex ideas to be
expressed and explored in a very laconic way.</p>

<p>The curious reader is encouraged to run the above code. The appendix contains a
function for generating synthetic data. It should be noted, however, that <code class="language-plaintext highlighter-rouge">brms</code>
and <code class="language-plaintext highlighter-rouge">tidybayes</code> should be of versions greater than 2.11.1 and 2.0.1,
respectively, which, at the time of writing, are available for installation only
on GitHub. The appendix contains instructions for updating the packages.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In this article, we have discussed a multilevel multinomial model for inferring
the net promoter score with respect to several grouping variables in accordance
with the business needs. It has been argued that poststratification is an
essential stage of the inference process, since it mitigates the deleterious
consequences of participation bias on the subsequent decision-making.</p>

<p>There are still some aspects that could be improved. For instance, there is a
natural ordering to the three categories of customers, detractors, neutrals, and
promoters; however, it is currently ignored. Furthermore, there is some
information thrown away when customer-level scores, which range from zero to
ten, are aggregated on the category level. Lastly, the net promoter survey often
happens in periodic waves, which calls for a single model capturing and learning
from changes over time.</p>

<h1 id="acknowledgments">Acknowledgments</h1>

<p>I would like to thank <a href="http://www.stat.columbia.edu/~gelman/">Andrew Gelman</a> for the guidance on multilevel modeling
and <a href="https://paul-buerkner.github.io/">Paul-Christian Bürkner</a> for the help with understanding the <code class="language-plaintext highlighter-rouge">brms</code> package.</p>

<h1 id="references">References</h1>

<ul>
  <li>Andrew Gelman et al., “<a href="http://www.stat.columbia.edu/~gelman/research/unpublished/MRT(1).pdf">Using multilevel regression and poststratification to
estimate dynamic public opinion</a>,” 2018.</li>
  <li>Andrew Gelman and Jennifer Hill, <em><a href="https://doi.org/10.1017/CBO9780511790942">Data Analysis Using Regression and
Multilevel/Hierarchical Models</a></em>, Cambridge University Press, 2006.</li>
  <li>Andrew Gelman and Thomas Little, “<a href="http://www.stat.columbia.edu/~gelman/research/published/poststrat3.pdf">Poststratification into many categories
using hierarchical logistic regression</a>,” Survey Methodology, 1997.</li>
  <li>Paul-Christian Bürkner, “<a href="http://dx.doi.org/10.18637/jss.v080.i01">brms: An R package for Bayesian multilevel models
using Stan</a>,” Journal of Statistical Software, 2017.</li>
</ul>

<h1 id="appendix">Appendix</h1>

<p>The following listing defines a function that makes the illustrative example
given in the Implementation section self-sufficient. By default, the population
contains one million customers, and the sample contains one percent. There are
two grouping variables: age with six values and seniority with seven values.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">load_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000000</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">softmax</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="nf">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="nf">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="w">

  </span><span class="c1"># Age</span><span class="w">
  </span><span class="n">age_values</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s1">'18–25'</span><span class="p">,</span><span class="w"> </span><span class="s1">'26–35'</span><span class="p">,</span><span class="w"> </span><span class="s1">'36–45'</span><span class="p">,</span><span class="w"> </span><span class="s1">'46–55'</span><span class="p">,</span><span class="w"> </span><span class="s1">'56–65'</span><span class="p">,</span><span class="w"> </span><span class="s1">'66+'</span><span class="p">)</span><span class="w">
  </span><span class="n">age_probabilities</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">softmax</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">))</span><span class="w">

  </span><span class="c1"># Seniority</span><span class="w">
  </span><span class="n">seniority_values</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s1">'6M'</span><span class="p">,</span><span class="w"> </span><span class="s1">'1Y'</span><span class="p">,</span><span class="w"> </span><span class="s1">'2Y'</span><span class="p">,</span><span class="w"> </span><span class="s1">'3Y'</span><span class="p">,</span><span class="w"> </span><span class="s1">'4Y'</span><span class="p">,</span><span class="w"> </span><span class="s1">'5Y'</span><span class="p">,</span><span class="w"> </span><span class="s1">'6Y+'</span><span class="p">)</span><span class="w">
  </span><span class="n">seniority_probabilities</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">softmax</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">))</span><span class="w">

  </span><span class="c1"># Score</span><span class="w">
  </span><span class="n">score_values</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">)</span><span class="w">
  </span><span class="n">score_probabilities</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">softmax</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">))</span><span class="w">

  </span><span class="c1"># Generate a population</span><span class="w">
  </span><span class="n">population</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tibble</span><span class="p">(</span><span class="n">age</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">age_values</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w">
                                    </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">age_probabilities</span><span class="p">,</span><span class="w">
                                    </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),</span><span class="w">
                       </span><span class="n">seniority</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">seniority_values</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w">
                                          </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">seniority_probabilities</span><span class="p">,</span><span class="w">
                                          </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">))</span><span class="w">

  </span><span class="c1"># Take a sample from the population</span><span class="w">
  </span><span class="n">sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">population</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
    </span><span class="n">sample_n</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
    </span><span class="n">mutate</span><span class="p">(</span><span class="n">score</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">score_values</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w">
                          </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">score_probabilities</span><span class="p">,</span><span class="w">
                          </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
    </span><span class="n">mutate</span><span class="p">(</span><span class="n">category</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">case_when</span><span class="p">(</span><span class="n">score</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">7</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="s1">'detractor'</span><span class="p">,</span><span class="w">
                                </span><span class="n">score</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="s1">'promoter'</span><span class="p">,</span><span class="w">
                                </span><span class="kc">TRUE</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="s1">'neutral'</span><span class="p">))</span><span class="w">

  </span><span class="c1"># Summarize the population</span><span class="w">
  </span><span class="n">population</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">population</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
    </span><span class="n">group_by</span><span class="p">(</span><span class="n">age</span><span class="p">,</span><span class="w"> </span><span class="n">seniority</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
    </span><span class="n">count</span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'cell_size'</span><span class="p">)</span><span class="w">

  </span><span class="c1"># Summarize the sample</span><span class="w">
  </span><span class="n">sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
    </span><span class="n">group_by</span><span class="p">(</span><span class="n">age</span><span class="p">,</span><span class="w"> </span><span class="n">seniority</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
    </span><span class="n">summarize</span><span class="p">(</span><span class="n">detractors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">category</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">'detractor'</span><span class="p">),</span><span class="w">
              </span><span class="n">neutrals</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">category</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">'neutral'</span><span class="p">),</span><span class="w">
              </span><span class="n">promoters</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">category</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">'promoter'</span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
    </span><span class="n">mutate</span><span class="p">(</span><span class="n">cell_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">detractors</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">neutrals</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">promoters</span><span class="p">)</span><span class="w">

  </span><span class="c1"># Bind counts of neutrals, detractors, and promoters (needed for brms)</span><span class="w">
  </span><span class="n">sample</span><span class="o">$</span><span class="n">cell_counts</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">with</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="n">detractors</span><span class="p">,</span><span class="w"> </span><span class="n">neutrals</span><span class="p">,</span><span class="w"> </span><span class="n">promoters</span><span class="p">))</span><span class="w">
  </span><span class="n">colnames</span><span class="p">(</span><span class="n">sample</span><span class="o">$</span><span class="n">cell_counts</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s1">'detractor'</span><span class="p">,</span><span class="w"> </span><span class="s1">'neutral'</span><span class="p">,</span><span class="w"> </span><span class="s1">'promoter'</span><span class="p">)</span><span class="w">

  </span><span class="c1"># Remove unused columns</span><span class="w">
  </span><span class="n">sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">select</span><span class="p">(</span><span class="o">-</span><span class="n">detractors</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="n">neutrals</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="n">promoters</span><span class="p">)</span><span class="w">

  </span><span class="nf">list</span><span class="p">(</span><span class="n">population</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">population</span><span class="p">,</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Lastly, the following snippet shows how to update <code class="language-plaintext highlighter-rouge">brms</code> and <code class="language-plaintext highlighter-rouge">tidybayes</code> from
GitHub:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">packageVersion</span><span class="p">(</span><span class="s1">'brms'</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="s1">'2.11.2'</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">remotes</span><span class="o">::</span><span class="n">install_github</span><span class="p">(</span><span class="s1">'paul-buerkner/brms'</span><span class="p">,</span><span class="w"> </span><span class="n">upgrade</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'never'</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">packageVersion</span><span class="p">(</span><span class="s1">'tidybayes'</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="s1">'2.0.1.9000'</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">remotes</span><span class="o">::</span><span class="n">install_github</span><span class="p">(</span><span class="s1">'mjskay/tidybayes'</span><span class="p">,</span><span class="w"> </span><span class="n">upgrade</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'never'</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>]]></content><author><name>Ivan Ukhov</name><email>ivan.ukhov@gmail.com</email></author><summary type="html"><![CDATA[Customer surveys are naturally prone to biases. One prominent example is participation bias, which arises when individuals decide not to respond to the survey, and this pattern is not random. For instance, new customers might reply less eagerly than those who are senior. This renders the obtained responses unrepresentative of the target population. In this article, we tackle participation bias for the case of the net promoter survey by means of multilevel regression and poststratification.]]></summary></entry><entry><title type="html">Ingestion of sequential data from BigQuery into TensorFlow</title><link href="https://blog.ivanukhov.com/2019/11/08/sequential-data.html" rel="alternate" type="text/html" title="Ingestion of sequential data from BigQuery into TensorFlow" /><published>2019-11-08T07:00:00+00:00</published><updated>2019-11-08T07:00:00+00:00</updated><id>https://blog.ivanukhov.com/2019/11/08/sequential-data</id><content type="html" xml:base="https://blog.ivanukhov.com/2019/11/08/sequential-data.html"><![CDATA[<p>How hard can it be to ingest sequential data into a <a href="https://www.tensorflow.org">TensorFlow</a> model? As
always, the answer is, “It depends.” Where are the sequences in question stored?
Can they fit in main memory? Are they of the same length? In what follows, we
shall build a flexible and scalable workflow for feeding sequential observations
into a TensorFlow graph starting from <a href="https://cloud.google.com/bigquery/">BigQuery</a> as the data warehouse.</p>

<p>To make the discussion tangible, consider the following problem. Suppose the
goal is to predict the peak temperature at an arbitrary weather station present
in the <a href="https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-ghcn">Global Historical Climatology Network</a> for each day between June 1 and
August 31. More concretely, given observations from June 1 up to an arbitrary
day before August 31, the objective is to complete the sequence until August 31.
For instance, if we find ourselves in Stockholm on June 12, we ask for the
maximum temperatures from June 12 to August 31 given the temperature values
between June 1 to June 11 at a weather station in Stockholm.</p>

<p>To set the expectations right, in this article, we are not going to build a
predictive model but to cater for its development by making the data from the
aforementioned database readily available in a TensorFlow graph. The final chain
of states and operations is as follows:</p>

<ol>
  <li>
    <p>Historical temperature measurements from the Global Historical Climatology
Network are stored in a <a href="https://console.cloud.google.com/marketplace/details/noaa-public/ghcn-d">public data set</a> in BigQuery. Each row
corresponds to a weather station and a date. There are missing observations
due to such reasons as measurements not passing quality checks.</p>
  </li>
  <li>
    <p>Relevant measurements are grouped in BigQuery by the weather station and
year. Therefore, each row corresponds to a weather station and a year,
implying that all information about a particular example (a specific weather
station on a specific year) is gathered in one place.</p>
  </li>
  <li>
    <p>The sequences are read, analyzed, and transformed by <a href="https://cloud.google.com/dataflow/">Cloud Dataflow</a>.</p>

    <ul>
      <li>
        <p>The data are split into a training, a validation, and a testing set of
examples.</p>
      </li>
      <li>
        <p>The training set is used to compute statistics needed for transforming the
measurements to a form suitable for the subsequent modeling.
Standardization is used as an example.</p>
      </li>
      <li>
        <p>The training and validation sets are transformed using the statistics
computed with respect to the training set in order to avoid performing
these computations during the training-with-validation phase. The
corresponding transform is available for the testing phase.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>The processed training and validation examples and the raw testing examples
are written by Dataflow to <a href="https://cloud.google.com/storage/">Cloud Storage</a> in the <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord">TFRecord</a> format, which is
a format native to TensorFlow.</p>
  </li>
  <li>
    <p>The files containing TFRecords are read by the <a href="https://www.tensorflow.org/guide/data"><code class="language-plaintext highlighter-rouge">tf.data</code></a> API of TensorFlow
and eventually transformed into a data set of appropriately padded batches of
examples.</p>
  </li>
</ol>

<p>The above workflow is not as simple as reading data from a Pandas DataFrame
comfortably resting in main memory; however, it is much more scalable. This
pipeline can handle arbitrary amounts of data. Moreover, it operates on
complete examples, not on individual measurements.</p>

<p>In the rest of the article, the aforementioned steps will be described in more
detail. The corresponding source code can be found in the following repository
on GitHub:</p>

<ul>
  <li><a href="https://github.com/chain-rule/example-weather-forecast">example-weather-forecast</a>.</li>
</ul>

<h1 id="data">Data</h1>

<p>It all starts with data. The data come from the Global Historical Climatology
Network, which is <a href="https://console.cloud.google.com/marketplace/details/noaa-public/ghcn-d">available in BigQuery</a> for public use. Steps 1 and 2
in the list above are covered by the <a href="https://github.com/chain-rule/example-weather-forecast/blob/master/configs/training/data.sql">following query</a>:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">WITH</span>
<span class="c1">-- Select relevant measurements</span>
<span class="n">data_1</span> <span class="k">AS</span> <span class="p">(</span>
  <span class="k">SELECT</span>
    <span class="n">id</span><span class="p">,</span>
    <span class="nb">date</span><span class="p">,</span>
    <span class="c1">-- Find the date of the previous observation</span>
    <span class="n">LAG</span><span class="p">(</span><span class="nb">date</span><span class="p">)</span> <span class="n">OVER</span> <span class="p">(</span><span class="n">station_year</span><span class="p">)</span> <span class="k">AS</span> <span class="n">date_last</span><span class="p">,</span>
    <span class="n">latitude</span><span class="p">,</span>
    <span class="n">longitude</span><span class="p">,</span>
    <span class="c1">-- Convert to degrees Celsius</span>
    <span class="n">value</span> <span class="o">/</span> <span class="mi">10</span> <span class="k">AS</span> <span class="n">temperature</span>
  <span class="k">FROM</span>
    <span class="nv">`bigquery-public-data.ghcn_d.ghcnd_201*`</span>
  <span class="k">INNER</span> <span class="k">JOIN</span>
    <span class="nv">`bigquery-public-data.ghcn_d.ghcnd_stations`</span> <span class="k">USING</span> <span class="p">(</span><span class="n">id</span><span class="p">)</span>
  <span class="k">WHERE</span>
    <span class="c1">-- Take years from 2010 to 2019</span>
    <span class="k">CAST</span><span class="p">(</span><span class="n">_TABLE_SUFFIX</span> <span class="k">AS</span> <span class="n">INT64</span><span class="p">)</span> <span class="k">BETWEEN</span> <span class="mi">0</span> <span class="k">AND</span> <span class="mi">9</span>
    <span class="c1">-- Take months from June to August</span>
    <span class="k">AND</span> <span class="k">EXTRACT</span><span class="p">(</span><span class="k">MONTH</span> <span class="k">FROM</span> <span class="nb">date</span><span class="p">)</span> <span class="k">BETWEEN</span> <span class="mi">6</span> <span class="k">AND</span> <span class="mi">8</span>
    <span class="c1">-- Take the maximum temperature</span>
    <span class="k">AND</span> <span class="n">element</span> <span class="o">=</span> <span class="s1">'TMAX'</span>
    <span class="c1">-- Take observations passed spatio-temporal quality-control checks</span>
    <span class="k">AND</span> <span class="n">qflag</span> <span class="k">IS</span> <span class="k">NULL</span>
  <span class="k">WINDOW</span>
    <span class="n">station_year</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">PARTITION</span> <span class="k">BY</span> <span class="n">id</span><span class="p">,</span> <span class="k">EXTRACT</span><span class="p">(</span><span class="nb">YEAR</span> <span class="k">FROM</span> <span class="nb">date</span><span class="p">)</span>
      <span class="k">ORDER</span> <span class="k">BY</span> <span class="nb">date</span>
    <span class="p">)</span>
<span class="p">),</span>
<span class="c1">-- Group into examples (a specific station and a specific year)</span>
<span class="n">data_2</span> <span class="k">AS</span> <span class="p">(</span>
  <span class="k">SELECT</span>
    <span class="n">id</span><span class="p">,</span>
    <span class="k">MIN</span><span class="p">(</span><span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="nb">date</span><span class="p">,</span>
    <span class="n">latitude</span><span class="p">,</span>
    <span class="n">longitude</span><span class="p">,</span>
    <span class="c1">-- Compute gaps between observations</span>
    <span class="n">ARRAY_AGG</span><span class="p">(</span>
      <span class="n">DATE_DIFF</span><span class="p">(</span><span class="nb">date</span><span class="p">,</span> <span class="n">IFNULL</span><span class="p">(</span><span class="n">date_last</span><span class="p">,</span> <span class="nb">date</span><span class="p">),</span> <span class="k">DAY</span><span class="p">)</span>
      <span class="k">ORDER</span> <span class="k">BY</span> <span class="nb">date</span>
    <span class="p">)</span> <span class="k">AS</span> <span class="n">duration</span><span class="p">,</span>
    <span class="n">ARRAY_AGG</span><span class="p">(</span><span class="n">temperature</span> <span class="k">ORDER</span> <span class="k">BY</span> <span class="nb">date</span><span class="p">)</span> <span class="k">AS</span> <span class="n">temperature</span>
  <span class="k">FROM</span>
    <span class="n">data_1</span>
  <span class="k">GROUP</span> <span class="k">BY</span>
    <span class="n">id</span><span class="p">,</span> <span class="n">latitude</span><span class="p">,</span> <span class="n">longitude</span><span class="p">,</span> <span class="k">EXTRACT</span><span class="p">(</span><span class="nb">YEAR</span> <span class="k">FROM</span> <span class="nb">date</span><span class="p">)</span>
<span class="p">)</span>
<span class="c1">-- Partition into training, validation, and testing sets</span>
<span class="k">SELECT</span>
  <span class="o">*</span><span class="p">,</span>
  <span class="k">CASE</span>
    <span class="k">WHEN</span> <span class="k">EXTRACT</span><span class="p">(</span><span class="nb">YEAR</span> <span class="k">FROM</span> <span class="nb">date</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2019</span> <span class="k">THEN</span> <span class="s1">'analysis,training'</span>
    <span class="k">WHEN</span> <span class="k">MOD</span><span class="p">(</span><span class="k">ABS</span><span class="p">(</span><span class="n">FARM_FINGERPRINT</span><span class="p">(</span><span class="n">id</span><span class="p">)),</span> <span class="mi">100</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">50</span> <span class="k">THEN</span> <span class="s1">'validation'</span>
    <span class="k">ELSE</span> <span class="s1">'testing'</span>
  <span class="k">END</span> <span class="k">AS</span> <span class="k">mode</span>
<span class="k">FROM</span>
  <span class="n">data_2</span>
</code></pre></div></div>

<p>The query fetches peak temperatures, denoted by <code class="language-plaintext highlighter-rouge">temperature</code>, for all available
weather stations between June and August in 2010–2019. The crucial part is the
usage of <code class="language-plaintext highlighter-rouge">ARRAY_AGG</code>, which is what makes it possible to gather all relevant
data about a specific station and a specific year in the same row. The number of
days since the previous measurement, which is denoted by <code class="language-plaintext highlighter-rouge">duration</code>, is also
computed. Ideally, <code class="language-plaintext highlighter-rouge">duration</code> should always be one (except for the first day,
which has no predecessor); however, this is not the case, which makes the
resulting time series vary in length.</p>

<p>In addition, in order to illustrate the generality of this approach, two
contextual (that is, non-sequential) explanatory variables are added: <code class="language-plaintext highlighter-rouge">latitude</code>
and <code class="language-plaintext highlighter-rouge">longitude</code>. They are scalars stored side by side with <code class="language-plaintext highlighter-rouge">duration</code> and
<code class="language-plaintext highlighter-rouge">temperature</code>, which are arrays.</p>

<p>Another important moment in the final <code class="language-plaintext highlighter-rouge">SELECT</code> statement, which defines a column
called <code class="language-plaintext highlighter-rouge">mode</code>. This column indicates what each example is used for, allowing one
to use the same query for different purposes and to avoid inconsistencies due to
multiple queries. In this case, observations prior to 2019 are reserved for
training, while the rest is split pseudo-randomly and reproducibly into two
approximately equal parts: one is for validation, and one is for testing. This
last operation is explained in detail in “<a href="https://www.oreilly.com/learning/repeatable-sampling-of-data-sets-in-bigquery-for-machine-learning">Repeatable sampling of data sets in
BigQuery for machine learning</a>” by Lak Lakshmanan.</p>

<h1 id="preprocessing">Preprocessing</h1>

<p>In this section, we cover Steps 4 and 5 in the list given at the beginning. This
job is done by <a href="https://www.tensorflow.org/tfx">TensorFlow Extended</a>, which is a library for building
machine-learning pipelines. Internally, it relies on <a href="https://beam.apache.org/">Apache Beam</a> as a language
for defining pipelines. Once an adequate pipeline is created, it can be executed
using an executor, and the executor that we shall use is <a href="https://cloud.google.com/dataflow/">Cloud Dataflow</a>.</p>

<p>Before we proceed to the pipeline itself, the construction process is
orchestrated by a <a href="https://github.com/chain-rule/example-weather-forecast/blob/master/configs/training/preprocessing.json">configuration file</a>, which will
be referred to as <code class="language-plaintext highlighter-rouge">config</code> in the pipeline code (to be discussed shortly):</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"data"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"path"</span><span class="p">:</span><span class="w"> </span><span class="s2">"configs/training/data.sql"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"schema"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"latitude"</span><span class="p">,</span><span class="w"> </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"float32"</span><span class="p">,</span><span class="w"> </span><span class="nl">"transform"</span><span class="p">:</span><span class="w"> </span><span class="s2">"z"</span><span class="w"> </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"longitude"</span><span class="p">,</span><span class="w"> </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"float32"</span><span class="p">,</span><span class="w"> </span><span class="nl">"transform"</span><span class="p">:</span><span class="w"> </span><span class="s2">"z"</span><span class="w"> </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"duration"</span><span class="p">,</span><span class="w"> </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"float32"</span><span class="p">],</span><span class="w"> </span><span class="nl">"transform"</span><span class="p">:</span><span class="w"> </span><span class="s2">"z"</span><span class="w"> </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"temperature"</span><span class="p">,</span><span class="w"> </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"float32"</span><span class="p">],</span><span class="w"> </span><span class="nl">"transform"</span><span class="p">:</span><span class="w"> </span><span class="s2">"z"</span><span class="w"> </span><span class="p">}</span><span class="w">
    </span><span class="p">]</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"modes"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"analysis"</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"training"</span><span class="p">,</span><span class="w"> </span><span class="nl">"transform"</span><span class="p">:</span><span class="w"> </span><span class="s2">"analysis"</span><span class="p">,</span><span class="w"> </span><span class="nl">"shuffle"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"validation"</span><span class="p">,</span><span class="w"> </span><span class="nl">"transform"</span><span class="p">:</span><span class="w"> </span><span class="s2">"analysis"</span><span class="w"> </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"testing"</span><span class="p">,</span><span class="w"> </span><span class="nl">"transform"</span><span class="p">:</span><span class="w"> </span><span class="s2">"identity"</span><span class="w"> </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>It is worth noting that this way of working with a separate configuration file
is not something standard that comes with TensorFlow or Beam. It is a
convenience that we build for ourselves in order to keep the main logic reusable
and extendable without touching the code.</p>

<p>The <code class="language-plaintext highlighter-rouge">data</code> block describes where the data can be found and provides a schema for
the columns that are used. (Recall the SQL query given earlier and note that
<code class="language-plaintext highlighter-rouge">id</code>, <code class="language-plaintext highlighter-rouge">date</code>, and <code class="language-plaintext highlighter-rouge">partition</code> are omitted.) For instance, <code class="language-plaintext highlighter-rouge">latitude</code> is a scale
of type <code class="language-plaintext highlighter-rouge">FLOAT32</code>, while <code class="language-plaintext highlighter-rouge">temperature</code> is a sequence of type <code class="language-plaintext highlighter-rouge">FLOAT32</code>. Both are
standardized to have a zero mean and a unit standard deviation, which is
indicated by <code class="language-plaintext highlighter-rouge">"transform": "z"</code> and is typically needed for training neural
networks.</p>

<p>The <code class="language-plaintext highlighter-rouge">modes</code> block defines four passes over the data, corresponding to four
operating modes. In each mode, a specific subset of examples is considered,
which is given by the <code class="language-plaintext highlighter-rouge">mode</code> column returned by the query. There are two types
of modes: analysis and transform; recall Step 3. Whenever the <code class="language-plaintext highlighter-rouge">transform</code> key is
present, it is a transform mode; otherwise, it is an analysis mode. In this
example, there are one analysis and three transform modes.</p>

<p>Below is an excerpt from a <a href="https://github.com/chain-rule/example-weather-forecast/blob/master/forecast/pipeline.py">Python class</a> responsible for building
the pipeline:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># config = ...
# schema = ...
</span>
<span class="c1"># Read the SQL code
</span><span class="n">query</span> <span class="o">=</span> <span class="nf">open</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">data</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">path</span><span class="sh">'</span><span class="p">]).</span><span class="nf">read</span><span class="p">()</span>
<span class="c1"># Create a BigQuery source
</span><span class="n">source</span> <span class="o">=</span> <span class="n">beam</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="nc">BigQuerySource</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">use_standard_sql</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># Create metadata needed later
</span><span class="n">spec</span> <span class="o">=</span> <span class="n">schema</span><span class="p">.</span><span class="nf">to_feature_spec</span><span class="p">()</span>
<span class="n">meta</span> <span class="o">=</span> <span class="n">dataset_metadata</span><span class="p">.</span><span class="nc">DatasetMetadata</span><span class="p">(</span>
    <span class="n">schema</span><span class="o">=</span><span class="n">dataset_schema</span><span class="p">.</span><span class="nf">from_feature_spec</span><span class="p">(</span><span class="n">spec</span><span class="p">))</span>
<span class="c1"># Read data from BigQuery
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pipeline</span> \
    <span class="o">|</span> <span class="sh">'</span><span class="s">read</span><span class="sh">'</span> <span class="o">&gt;&gt;</span> <span class="n">beam</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="nc">Read</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
<span class="c1"># Loop over modes whose purpose is analysis
</span><span class="n">transform_functions</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">mode</span> <span class="ow">in</span> <span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">modes</span><span class="sh">'</span><span class="p">]:</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">transform</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">mode</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">mode</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span>
    <span class="c1"># Select examples that belong to the current mode
</span>    <span class="n">data_</span> <span class="o">=</span> <span class="n">data</span> \
        <span class="o">|</span> <span class="n">name</span> <span class="o">+</span> <span class="sh">'</span><span class="s">-filter</span><span class="sh">'</span> <span class="o">&gt;&gt;</span> <span class="n">beam</span><span class="p">.</span><span class="nc">Filter</span><span class="p">(</span><span class="nf">partial</span><span class="p">(</span><span class="n">_filter</span><span class="p">,</span> <span class="n">mode</span><span class="p">))</span>
    <span class="c1"># Analyze the examples
</span>    <span class="n">transform_functions</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_</span><span class="p">,</span> <span class="n">meta</span><span class="p">)</span> \
        <span class="o">|</span> <span class="n">name</span> <span class="o">+</span> <span class="sh">'</span><span class="s">-analyze</span><span class="sh">'</span> <span class="o">&gt;&gt;</span> <span class="n">tt_beam</span><span class="p">.</span><span class="nc">AnalyzeDataset</span><span class="p">(</span><span class="n">_analyze</span><span class="p">)</span>
    <span class="n">path</span> <span class="o">=</span> <span class="nf">_locate</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="sh">'</span><span class="s">transform</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1"># Store the transform function
</span>    <span class="n">transform_functions</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> \
        <span class="o">|</span> <span class="n">name</span> <span class="o">+</span> <span class="sh">'</span><span class="s">-write-transform</span><span class="sh">'</span> <span class="o">&gt;&gt;</span> <span class="n">transform_fn_io</span><span class="p">.</span><span class="nc">WriteTransformFn</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="c1"># Loop over modes whose purpose is transformation
</span><span class="k">for</span> <span class="n">mode</span> <span class="ow">in</span> <span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">modes</span><span class="sh">'</span><span class="p">]:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="sh">'</span><span class="s">transform</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">mode</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">mode</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span>
    <span class="c1"># Select examples that belong to the current mode
</span>    <span class="n">data_</span> <span class="o">=</span> <span class="n">data</span> \
        <span class="o">|</span> <span class="n">name</span> <span class="o">+</span> <span class="sh">'</span><span class="s">-filter</span><span class="sh">'</span> <span class="o">&gt;&gt;</span> <span class="n">beam</span><span class="p">.</span><span class="nc">Filter</span><span class="p">(</span><span class="nf">partial</span><span class="p">(</span><span class="n">_filter</span><span class="p">,</span> <span class="n">mode</span><span class="p">))</span>
    <span class="c1"># Shuffle examples if needed
</span>    <span class="k">if</span> <span class="n">mode</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="bp">False</span><span class="p">):</span>
        <span class="n">data_</span> <span class="o">=</span> <span class="n">data_</span> \
            <span class="o">|</span> <span class="n">name</span> <span class="o">+</span> <span class="sh">'</span><span class="s">-shuffle</span><span class="sh">'</span> <span class="o">&gt;&gt;</span> <span class="n">beam</span><span class="p">.</span><span class="n">transforms</span><span class="p">.</span><span class="nc">Reshuffle</span><span class="p">()</span>
    <span class="c1"># Transform the examples using an appropriate transform function
</span>    <span class="k">if</span> <span class="n">mode</span><span class="p">[</span><span class="sh">'</span><span class="s">transform</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">identity</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">coder</span> <span class="o">=</span> <span class="n">tft</span><span class="p">.</span><span class="n">coders</span><span class="p">.</span><span class="nc">ExampleProtoCoder</span><span class="p">(</span><span class="n">meta</span><span class="p">.</span><span class="n">schema</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data_</span><span class="p">,</span> <span class="n">meta_</span> <span class="o">=</span> <span class="p">((</span><span class="n">data_</span><span class="p">,</span> <span class="n">meta</span><span class="p">),</span> <span class="n">transform_functions</span><span class="p">[</span><span class="n">mode</span><span class="p">[</span><span class="sh">'</span><span class="s">transform</span><span class="sh">'</span><span class="p">]])</span> \
            <span class="o">|</span> <span class="n">name</span> <span class="o">+</span> <span class="sh">'</span><span class="s">-transform</span><span class="sh">'</span> <span class="o">&gt;&gt;</span> <span class="n">tt_beam</span><span class="p">.</span><span class="nc">TransformDataset</span><span class="p">()</span>
        <span class="n">coder</span> <span class="o">=</span> <span class="n">tft</span><span class="p">.</span><span class="n">coders</span><span class="p">.</span><span class="nc">ExampleProtoCoder</span><span class="p">(</span><span class="n">meta_</span><span class="p">.</span><span class="n">schema</span><span class="p">)</span>
    <span class="n">path</span> <span class="o">=</span> <span class="nf">_locate</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="sh">'</span><span class="s">examples</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">part</span><span class="sh">'</span><span class="p">)</span>
    <span class="c1"># Store the transformed examples as TFRecords
</span>    <span class="n">data_</span> \
        <span class="o">|</span> <span class="n">name</span> <span class="o">+</span> <span class="sh">'</span><span class="s">-encode</span><span class="sh">'</span> <span class="o">&gt;&gt;</span> <span class="n">beam</span><span class="p">.</span><span class="nc">Map</span><span class="p">(</span><span class="n">coder</span><span class="p">.</span><span class="n">encode</span><span class="p">)</span> \
        <span class="o">|</span> <span class="n">name</span> <span class="o">+</span> <span class="sh">'</span><span class="s">-write-examples</span><span class="sh">'</span> <span class="o">&gt;&gt;</span> <span class="n">beam</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">tfrecordio</span><span class="p">.</span><span class="nc">WriteToTFRecord</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</code></pre></div></div>

<p>At the very beginning, a BigQuery source is created, which is then branched out
according to the operating modes found in the configuration file. Specifically,
the first for-loop corresponds to the analysis modes, and the second for-loop
goes over the transform modes. The former ends with <code class="language-plaintext highlighter-rouge">WriteTransformFn</code>, which
saves the resulting transform, and the latter ends with <code class="language-plaintext highlighter-rouge">WriteToTFRecord</code>, which
writes the resulting examples as TFRecords.</p>

<p>The distinction between the contextual and sequential features is given by the
<a href="https://github.com/chain-rule/example-weather-forecast/blob/master/forecast/schema.py"><code class="language-plaintext highlighter-rouge">schema</code></a> object created based on the <code class="language-plaintext highlighter-rouge">schema</code> block in the
configuration file. The call <code class="language-plaintext highlighter-rouge">schema.to_feature_spec()</code> shown above alternates
between <a href="https://www.tensorflow.org/api_docs/python/tf/io/FixedLenFeature"><code class="language-plaintext highlighter-rouge">tf.io.FixedLenFeature</code></a> and <a href="https://www.tensorflow.org/api_docs/python/tf/io/VarLenFeature"><code class="language-plaintext highlighter-rouge">tf.io.VarLenFeature</code></a> and produces a
feature specification that is understood by TensorFlow and TensorFlow Extended.</p>

<p>The <a href="https://github.com/chain-rule/example-weather-forecast">repository</a> provides a wrapper for executing the
pipeline on Cloud Dataflow. The following figure shows the flow of the data with
respect to the four operating modes:</p>

<p><img src="/assets/images/2019-11-08-sequential-data/dataflow.svg" alt="" /></p>

<p>The outcome is a hierarchy of files on Cloud Storage:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.
└── data/
    └── training/
        └── 2019-11-01-12-00-00/
            ├── analysis/
            │   └── transform/
            │       ├── transform_fn/...
            │       └── transform_metadata/...
            ├── testing/
            │   └── examples/
            │       ├── part-000000-of-00004
            │       ├── ...
            │       └── part-000003-of-00004
            ├── training/
            │   └── examples/
            │       ├── part-000000-of-00006
            │       ├── ...
            │       └── part-000005-of-00006
            └── validation/
                └── examples/
                    ├── part-000000-of-00004
                    ├── ...
                    └── part-000003-of-00004
</code></pre></div></div>

<p>Here, <code class="language-plaintext highlighter-rouge">data/training</code> contains all data needed for the training phase, which
collectively refers to training entwined with validation and followed by
testing. Moving forward, this hierarchy is meant to accommodate the application
phase as well by populating a <code class="language-plaintext highlighter-rouge">data/application</code> entry next to the
<code class="language-plaintext highlighter-rouge">data/training</code> one. It can also accommodate trained models and the results of
applying these models by having a <code class="language-plaintext highlighter-rouge">model</code> entry with a structure similar to the
one of the <code class="language-plaintext highlighter-rouge">data</code> entry.</p>

<p>In the listing above, the files whose name starts with <code class="language-plaintext highlighter-rouge">part-</code> are the ones
containing TFRecords. It can be seen that, for each mode, the corresponding
examples have been split into multiple files, which is done for more efficient
access during the usage stage discussed in the next section.</p>

<h1 id="execution">Execution</h1>

<p>At this point, the data have made it all the way to the execution phase,
referring to training, validation, and testing; however, the data are yet to be
injected into a TensorFlow graph, which is the topic of this section. As before,
relevant parameters are kept in a <a href="https://github.com/chain-rule/example-weather-forecast/blob/master/configs/training/execution.json">separate configuration file</a>:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"data"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"schema"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"latitude"</span><span class="p">,</span><span class="w"> </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"float32"</span><span class="w"> </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"longitude"</span><span class="p">,</span><span class="w"> </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="s2">"float32"</span><span class="w"> </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"duration"</span><span class="p">,</span><span class="w"> </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"float32"</span><span class="p">]</span><span class="w"> </span><span class="p">},</span><span class="w">
      </span><span class="p">{</span><span class="w"> </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"temperature"</span><span class="p">,</span><span class="w"> </span><span class="nl">"kind"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"float32"</span><span class="p">]</span><span class="w"> </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"modes"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"training"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"spec"</span><span class="p">:</span><span class="w"> </span><span class="s2">"transformed"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"shuffle_macro"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"buffer_size"</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"interleave"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"cycle_length"</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="nl">"num_parallel_calls"</span><span class="p">:</span><span class="w"> </span><span class="mi">-1</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"shuffle_micro"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"buffer_size"</span><span class="p">:</span><span class="w"> </span><span class="mi">512</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"map"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"num_parallel_calls"</span><span class="p">:</span><span class="w"> </span><span class="mi">-1</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"batch"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"batch_size"</span><span class="p">:</span><span class="w"> </span><span class="mi">128</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"prefetch"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"buffer_size"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"repeat"</span><span class="p">:</span><span class="w"> </span><span class="p">{}</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="nl">"validation"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"spec"</span><span class="p">:</span><span class="w"> </span><span class="s2">"transformed"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"shuffle_macro"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"buffer_size"</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"interleave"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"cycle_length"</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="nl">"num_parallel_calls"</span><span class="p">:</span><span class="w"> </span><span class="mi">-1</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"map"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"num_parallel_calls"</span><span class="p">:</span><span class="w"> </span><span class="mi">-1</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"batch"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"batch_size"</span><span class="p">:</span><span class="w"> </span><span class="mi">128</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"prefetch"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"buffer_size"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"repeat"</span><span class="p">:</span><span class="w"> </span><span class="p">{}</span><span class="w">
      </span><span class="p">},</span><span class="w">
      </span><span class="nl">"testing"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"spec"</span><span class="p">:</span><span class="w"> </span><span class="s2">"original"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"interleave"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"cycle_length"</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="nl">"num_parallel_calls"</span><span class="p">:</span><span class="w"> </span><span class="mi">-1</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"map"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"num_parallel_calls"</span><span class="p">:</span><span class="w"> </span><span class="mi">-1</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"batch"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"batch_size"</span><span class="p">:</span><span class="w"> </span><span class="mi">128</span><span class="w"> </span><span class="p">},</span><span class="w">
        </span><span class="nl">"prefetch"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"buffer_size"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">}</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>It can be seen that the file contains only one block: <code class="language-plaintext highlighter-rouge">data</code>. This is sufficient
for the purposes of this article; however, it is also meant to cover the
construction of the model in mind, including its hyperparameters, and the
execution process, including the optimizer and evaluation metrics.</p>

<p>The <code class="language-plaintext highlighter-rouge">data</code> block is similar to the one we saw before. In this case, <code class="language-plaintext highlighter-rouge">modes</code>
describes various calls to the <a href="https://www.tensorflow.org/guide/data"><code class="language-plaintext highlighter-rouge">tf.data</code></a> API related to shuffling, batching,
and so on. Those who are familiar with the API will probably immediately
recognize them. It is now instructive to go straight to the Python code.</p>

<p>Below is an excerpt from a <a href="https://github.com/chain-rule/example-weather-forecast/blob/master/forecast/data.py">Python class</a> responsible for building the
pipeline on the TensorFlow side:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># config = ...
</span>
<span class="c1"># List all files matching a given pattern
</span><span class="n">pattern</span> <span class="o">=</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">path</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="sh">'</span><span class="s">examples</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">part-*</span><span class="sh">'</span><span class="p">]</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">list_files</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="o">*</span><span class="n">pattern</span><span class="p">))</span>
<span class="c1"># Shuffle the files if needed
</span><span class="k">if</span> <span class="sh">'</span><span class="s">shuffle_macro</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">shuffle_macro</span><span class="sh">'</span><span class="p">])</span>
<span class="c1"># Convert the files into datasets of examples stored as TFRecords and
# amalgamate these datasets into one dataset of examples
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span> \
    <span class="p">.</span><span class="nf">interleave</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">TFRecordDataset</span><span class="p">,</span> <span class="o">**</span><span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">interleave</span><span class="sh">'</span><span class="p">])</span>
<span class="c1"># Shuffle the examples if needed
</span><span class="k">if</span> <span class="sh">'</span><span class="s">shuffle_micro</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">shuffle_micro</span><span class="sh">'</span><span class="p">])</span>
<span class="c1"># Preprocess the examples with respect to a given spec, pad the examples
# and form batches of different sizes, and postprocess the batches
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span> \
    <span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="n">_preprocess</span><span class="p">,</span> <span class="o">**</span><span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">map</span><span class="sh">'</span><span class="p">])</span> \
    <span class="p">.</span><span class="nf">padded_batch</span><span class="p">(</span><span class="n">padded_shapes</span><span class="o">=</span><span class="nf">_shape</span><span class="p">(),</span> <span class="o">**</span><span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">batch</span><span class="sh">'</span><span class="p">])</span> \
    <span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="n">_postprocess</span><span class="p">,</span> <span class="o">**</span><span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">map</span><span class="sh">'</span><span class="p">])</span>
<span class="c1"># Prefetch the batches if needed
</span><span class="k">if</span> <span class="sh">'</span><span class="s">prefetch</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">prefetch</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">prefetch</span><span class="sh">'</span><span class="p">])</span>
<span class="c1"># Repeat the data once the source is exhausted if needed
</span><span class="k">if</span> <span class="sh">'</span><span class="s">repeat</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">repeat</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<p>The pipeline is self-explanatory. It is simply a chain of operations stacked on
top of each other. It is, however, worth taking a closer look at the
preprocessing and postprocessing mappings, which can be seen before and after
the padding step, respectively:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_preprocess</span><span class="p">(</span><span class="n">proto</span><span class="p">):</span>
    <span class="n">spec</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">transforms</span><span class="p">[</span><span class="n">config</span><span class="p">[</span><span class="sh">'</span><span class="s">transform</span><span class="sh">'</span><span class="p">]]</span> \
        <span class="p">.</span><span class="nf">transformed_feature_spec</span><span class="p">()</span>
    <span class="n">example</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="nf">parse_single_example</span><span class="p">(</span><span class="n">proto</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span>
    <span class="nf">return </span><span class="p">(</span>
        <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">example</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">contextual_names</span><span class="p">},</span>
        <span class="p">{</span>
            <span class="c1"># Convert the sequential columns from sparse to dense
</span>            <span class="n">name</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">schema</span><span class="p">[</span><span class="n">name</span><span class="p">].</span><span class="nf">to_dense</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">sequential_names</span>
        <span class="p">},</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">_postprocess</span><span class="p">(</span><span class="n">contextual</span><span class="p">,</span> <span class="n">sequential</span><span class="p">):</span>
    <span class="n">sequential</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># Convert the sequential columns from dense to sparse
</span>        <span class="n">name</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">schema</span><span class="p">[</span><span class="n">name</span><span class="p">].</span><span class="nf">to_sparse</span><span class="p">(</span><span class="n">sequential</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">sequential_names</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">contextual</span><span class="p">,</span> <span class="o">**</span><span class="n">sequential</span><span class="p">}</span>
</code></pre></div></div>

<p>Currently, <code class="language-plaintext highlighter-rouge">tf.data</code> does not support padding sparse tensors, which is the
representation used for sequential features in TensorFlow. In the running
example about forecasting weather, such features are <code class="language-plaintext highlighter-rouge">duration</code> and
<code class="language-plaintext highlighter-rouge">temperature</code>. This is the reason such features are converted to their dense
counterparts in <code class="language-plaintext highlighter-rouge">_preprocess</code>. However, the final representation has to be
sparse still. Therefore, the sequential features are converted back to the
sparse format in <code class="language-plaintext highlighter-rouge">_postprocess</code>. Hopefully, this back-and-forth conversion will
be rendered obsolete in future versions.</p>

<p>Having executed the above steps, we have an instance of <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset"><code class="language-plaintext highlighter-rouge">tf.data.Dataset</code></a>,
which is the ultimate goal, as it is the standard way of ingesting data into a
TensorFlow graph. At this point, one might create a Keras model leveraging
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/DenseFeatures"><code class="language-plaintext highlighter-rouge">tf.keras.layers.DenseFeatures</code></a> and <a href="https://www.tensorflow.org/api_docs/python/tf/keras/experimental/SequenceFeatures"><code class="language-plaintext highlighter-rouge">tf.keras.experimental.SequenceFeatures</code></a>
for constructing the input layer and then pass the data set to the <code class="language-plaintext highlighter-rouge">fit</code>
function of the model. A <a href="https://github.com/chain-rule/example-weather-forecast/blob/master/forecast/model.py">skeleton</a> for this part can be found in the
repository.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In this article, we have discussed a scalable approach to the ingestion of
sequential observations from BigQuery into a TensorFlow graph. The key tools
that have been used to this end are TensorFlow Extended in combination with
Cloud Dataflow and the <code class="language-plaintext highlighter-rouge">tf.data</code> API of TensorFlow.</p>

<p>In addition, the provided code has been written to be general and easily
customizable. It has been achieved by separating the configuration part from the
implementation one.</p>

<h1 id="references">References</h1>

<ul>
  <li>Lak Lakshmanan, “<a href="https://www.oreilly.com/learning/repeatable-sampling-of-data-sets-in-bigquery-for-machine-learning">Repeatable sampling of data sets in BigQuery for machine
learning</a>,” 2016.</li>
</ul>]]></content><author><name>Ivan Ukhov</name><email>ivan.ukhov@gmail.com</email></author><summary type="html"><![CDATA[How hard can it be to ingest sequential data into a TensorFlow model? As always, the answer is, “It depends.” Where are the sequences in question stored? Can they fit in main memory? Are they of the same length? In what follows, we shall build a flexible and scalable workflow for feeding sequential observations into a TensorFlow graph starting from BigQuery as the data warehouse.]]></summary></entry><entry><title type="html">Sample size determination using historical data and simulation</title><link href="https://blog.ivanukhov.com/2019/09/25/bootstrap.html" rel="alternate" type="text/html" title="Sample size determination using historical data and simulation" /><published>2019-09-25T06:00:00+00:00</published><updated>2019-09-25T06:00:00+00:00</updated><id>https://blog.ivanukhov.com/2019/09/25/bootstrap</id><content type="html" xml:base="https://blog.ivanukhov.com/2019/09/25/bootstrap.html"><![CDATA[<p>In order to test a hypothesis, one has to design and execute an adequate
experiment. Typically, it is neither feasible nor desirable to involve the whole
population. Instead, a relatively small subset of the population is studied, and
given the outcome for this small sample, relevant conclusions are drawn with
respect to the population. An important question to answer is then, What is the
minimal sample size needed for the experiment to succeed? In what follows, we
answer this question using solely historical data and computer simulation,
without invoking any classical statistical procedures.</p>

<p>Although, as we shall see, the ideas are straightforward, direct calculations
were impossible to perform before computers. To be able to answer this kind of
questions back then, statisticians developed mathematical theories in order to
approximate the calculations for specific situations. Since nothing else was
possible, these approximations and the various terms and conditions under which
they operate made up a large part of traditional textbooks and courses in
statistics. However, the advent of today’s computing power has enabled one to
estimate required sample sizes in a more direct and intuitive way, with the only
prerequisites being an understanding of statistical inference, the availability
of historical data describing the status quo, and the ability to write a few
lines of code in a programming language.</p>

<h1 id="problem">Problem</h1>

<p>For concreteness, consider the following scenario. We run an online business and
hypothesize that a specific change in promotion campaigns, such as making them
personalized, will have a positive effect on a specific performance metric, such
as the average deposit. In order to investigate if it is the case, we decide to
perform a two-sample test. There are the following two competing hypotheses.</p>

<ul>
  <li>
    <p>The null hypothesis postulates that the change has no effect on the metric.</p>
  </li>
  <li>
    <p>The alternative hypothesis postulates that the change has a positive effect on
the metric.</p>
  </li>
</ul>

<p>There will be two groups: a control group and a treatment group. The former will
be exposed to the current promotion policy, while the latter to the new one.
There are also certain requirements imposed on the test. First, we have a level
of statistical significance \(\alpha\) and a level of practical significance
\(\delta\) in mind. The former puts a limit on the false-positive rate, and the
latter indicates the smallest effect that we still care about; anything smaller
is as good as zero for any practical purpose. In addition, we require the test
to have a prescribed false-negative rate \(\beta\), ensuring that the test has
enough statistical power.</p>

<p>For our purposes, the test is considered well designed if it is capable of
detecting a difference as small as \(\delta\) so that the false-positive and
false-negative rates are controlled to levels \(\alpha\) and \(\beta\),
respectively. Typically, parameters \(\alpha\) and \(\delta\) are held constant,
and the desired false-positive rate \(\beta\) is attained by varying the number
of participants in each group, which we denote by \(n\). Note that we do not
want any of the parameters to be smaller than the prescribed values, as it would
be wasteful.</p>

<p>So what should the sample size be for the test to be well designed?</p>

<h1 id="solution">Solution</h1>

<p>Depending on the distribution of the data and on the chosen metric, one might or
might not be able to find a suitable test among the standard ones, while
ensuring that the test’s assumptions can safely be considered satisfied. More
importantly, a textbook solution might not be the most intuitive one, which, in
particular, might lead to misuse of the test. It is the understanding that
matters.</p>

<p>Here we take a more pragmatic and rather general approach that circumvents the
above concerns. It requires only historical data and basic programming skills.
Despite its simplicity, the method below goes straight to the core of what the
famed statistical tests are doing behind all the math. The approach belongs to
the class of so-called bootstrap techniques and is as follows.</p>

<p>Suppose we have historical data on customers’ behavior under the current
promotion policy, which is commonplace in practice. An important realization is
that this data set represents what we expect to observe in the control group. It
is also what is expected of the treatment group provided that the null
hypothesis is true, that is, when the proposed change has no effect. This
realization enables one to simulate what would happen if each group was limited
to an arbitrary number of participants. Then, by varying this size parameter, it
is possible to find the smallest value that makes the test well designed, that
is, make the test satisfy the requirements on \(\alpha\), \(\beta\), and
\(\delta\), as discussed in the previous section.</p>

<p>This is all. The rest is an elaboration of the above idea.</p>

<p>The simulation entails the following. To begin with, note that what we are
interested in testing is the difference between the performance metric applied
to the treatment group and the same metric applied to the control group, which
is referred to as the test statistic:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Test statistic = Metric(Treatment sample) - Metric(Control sample).
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Treatment sample</code> and <code class="language-plaintext highlighter-rouge">Control sample</code> stand for sets of observations, and
<code class="language-plaintext highlighter-rouge">Metric(Sample)</code> stands for computing the performance metric given such a
sample. For instance, each observation could be the total deposit of a customer,
and the metric could be the average value:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Metric(Sample) = Sum of observations / Number of observations.
</code></pre></div></div>

<p>Note, however, that it is an example; the metric can be arbitrary, and this is a
huge advantage of this approach to sample size determination based on data and
simulation.</p>

<p>Large positive values of the test statistic speak in favor of the treatment
(that is, the new promotion policy in our example), while those that are close
to zero suggest that the treatment is futile.</p>

<p>A sample of \(n\) observations corresponding to the status quo (that is, the
current policy in our example) can be easily obtained by drawing \(n\) data
points with replacement from the historical data:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Sample = Choose random with replacement(Data, N).
</code></pre></div></div>

<p>This expression is used for <code class="language-plaintext highlighter-rouge">Control sample</code> under both the null and alternative
hypotheses. As alluded to earlier, this is also how <code class="language-plaintext highlighter-rouge">Treatment sample</code> is
obtained under the null. Regarding the alternative hypothesis being true, one
has to express the hypothesized outcome as a distribution for the case of the
minimal detectable difference, \(\delta\). The simplest and reasonable solution
is to sample the data again, apply the metric, and then adjust the result to
reflect the alternative hypothesis:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Metric(Choose random with replacement(Data, N)) + Delta.
</code></pre></div></div>

<p>Here, again, one is free to change the logic under the alternative according to
the situation at hand. For instance, instead of an additive effect, one could
simulate a multiplicative one.</p>

<p>The above is a way to simulate a single instance of the experiment under either
the null or alternative hypothesis; the result is a single value for the test
statistic. The next step is to estimate how the test statistic would vary if the
experiment was repeated many times in the two scenarios. This simply means that
the procedure should be repeated multiple times:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Repeat many times {
  Sample 1 = Choose random with replacement(Data, N)
  Sample 2 = Choose random with replacement(Data, N)
  Metric 1 = Metric(Sample 1)
  Metric 2 = Metric(Sample 2)
  Test statistic under null = Metric 1 - Metric 2

  Sample 3 = Choose random with replacement(Data, N)
  Sample 4 = Choose random with replacement(Data, N)
  Metric 3 = Metric(Sample 3) + Delta
  Metric 4 = Metric(Sample 4)
  Test statistic under alternative = Metric 3 - Metric 4
}
</code></pre></div></div>

<p>This yields a collection of values for the test statistic under the null
hypothesis and a collection of values for the test statistic under the
alternative hypothesis. Each one contains realizations from the so-called
sampling distribution in the corresponding scenario. The following figure gives
an illustration:</p>

<p><img src="/assets/images/2019-09-25-bootstrap/sampling-distribution-1.svg" alt="" /></p>

<p>The blue shape is the sampling distribution under the null hypothesis, and the
red one is the sampling distribution under the alternative hypothesis. We shall
come back to this figure shortly.</p>

<p>These two distributions of the test statistic are what we are after, as they
allow one to compute the false-positive rate and eventually choose a sample
size. First, given \(\alpha\), the sampling distribution under the null (the
blue one) is used in order to find a value beyond which the probability mass is
equal to \(\alpha\):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Critical value = Quantile([Test statistic under null], 1 - alpha).
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Quantile</code> computes the quantile specified by the second argument given a set of
observations. This quantity is called the critical value of the test. In the
figure above, it is denoted by a dashed line. When the test statistic falls to
the right of the critical value, we reject the null hypothesis; otherwise, we
fail to reject it. Second, the sampling distribution in the case of the
alternative hypothesis being true (the red one) is used in order to compute the
false-negative rate:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Attained beta = Mean([Test statistic under alternative &lt; Critical value]).
</code></pre></div></div>

<p>It corresponds to the probability mass of the sampling distribution under the
alternative to the left of the critical value. In the figure, it is the red area
to the left of the dashed line.</p>

<p>The final step is to put the above procedure in an optimization loop that
minimizes the distance between the target and attained \(\beta\)’s with respect
to the sample size:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Optimize N until Attained beta is close to Target beta {
  Repeat many times {
    Test statistic under null = ...
    Test statistic under alternative = ...
  }
  Critical value = ...
  Attained beta = ...
}
</code></pre></div></div>

<p>This concludes the calculation of the size that the control and treatment groups
should have in order for the upcoming test in promotion campaigns to be well
designed in terms of the level of statistical significance \(\alpha\), the
false-negative rate \(\beta\), and the level of practical significance
\(\delta\).</p>

<p>An example of how this technique could be implemented in practice can be found
in the appendix.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In this article, we have discussed an approach to sample size determination that
is based on historical data and computer simulation rather than on mathematical
formulae tailored for specific situations. It is general and straightforward to
implement. More importantly, the technique is intuitive, since it directly
follows the narrative of null hypothesis significance testing. It does require
prior knowledge of the key concepts in statistical inference. However, this
knowledge is arguably essential for those who are involved in scientific
experimentation. It constitutes the core of statistical literacy.</p>

<h1 id="acknowledgments">Acknowledgments</h1>

<p>This article was inspired by a blog post authored by <a href="http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html">Allen Downey</a> and a talk
given by <a href="https://www.youtube.com/watch?v=5Dnw46eC-0o">John Rauser</a>. I also would like to thank <a href="http://users.stat.umn.edu/~rend0020/">Aaron Rendahl</a> for his
feedback on the introduction to the method presented here and for his help with
the implementation given in the appendix.</p>

<h1 id="references">References</h1>

<ul>
  <li>Allen Downey, “<a href="http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html">There is only one test!</a>,” 2011.</li>
  <li>John Rauser, “<a href="https://www.youtube.com/watch?v=5Dnw46eC-0o">Statistics without the agonizing pain</a>,” 2014.</li>
  <li>Joseph Lee Rodgers, “<a href="https://doi.org/10.1207/S15327906MBR3404_2">The bootstrap, the jackknife, and the randomization
test: A sampling taxonomy</a>,” Multivariate Behavioral Research,
2010.</li>
</ul>

<h1 id="appendix">Appendix</h1>

<p>The following listing shows an implementation of the bootstrap approach in R:</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span><span class="w">

</span><span class="n">set.seed</span><span class="p">(</span><span class="m">42</span><span class="p">)</span><span class="w">

</span><span class="c1"># Artificial data for illustration</span><span class="w">
</span><span class="n">observation_count</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">20000</span><span class="w">
</span><span class="n">data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tibble</span><span class="p">(</span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rlnorm</span><span class="p">(</span><span class="n">observation_count</span><span class="p">))</span><span class="w">

</span><span class="c1"># Performance metric</span><span class="w">
</span><span class="n">metric</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="w">
</span><span class="c1"># Statistical significance</span><span class="w">
</span><span class="n">alpha</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.05</span><span class="w">
</span><span class="c1"># False-negative rate</span><span class="w">
</span><span class="n">beta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.2</span><span class="w">
</span><span class="c1"># Practical significance</span><span class="w">
</span><span class="n">delta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">metric</span><span class="p">(</span><span class="n">data</span><span class="o">$</span><span class="n">value</span><span class="p">)</span><span class="w">

</span><span class="n">simulate</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span><span class="w"> </span><span class="n">replication_count</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="c1"># Function for drawing a single sample of size sample_size</span><span class="w">
  </span><span class="n">run_one</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">()</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">data</span><span class="o">$</span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="n">sample_size</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
  </span><span class="c1"># Function for drawing replication_count samples of size sample_size</span><span class="w">
  </span><span class="n">run_many</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">()</span><span class="w"> </span><span class="n">replicate</span><span class="p">(</span><span class="n">replication_count</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">metric</span><span class="p">(</span><span class="n">run_one</span><span class="p">())</span><span class="w"> </span><span class="p">})</span><span class="w">

  </span><span class="c1"># Simulation under the null hypothesis</span><span class="w">
  </span><span class="n">control_null</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">run_many</span><span class="p">()</span><span class="w">
  </span><span class="n">treatment_null</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">run_many</span><span class="p">()</span><span class="w">
  </span><span class="n">difference_null</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">treatment_null</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">control_null</span><span class="w">

  </span><span class="c1"># Simulation under the alternative hypothesis</span><span class="w">
  </span><span class="n">control_alternative</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">run_many</span><span class="p">()</span><span class="w">
  </span><span class="n">treatment_alternative</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">run_many</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">delta</span><span class="w">
  </span><span class="n">difference_alternative</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">treatment_alternative</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">control_alternative</span><span class="w">

  </span><span class="c1"># Computation of the critical value</span><span class="w">
  </span><span class="n">critical_value</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">quantile</span><span class="p">(</span><span class="n">difference_null</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w">
  </span><span class="c1"># Computation of the false-negative rate</span><span class="w">
  </span><span class="n">beta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">difference_alternative</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">critical_value</span><span class="p">)</span><span class="w">

  </span><span class="nf">list</span><span class="p">(</span><span class="n">difference_null</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">difference_null</span><span class="p">,</span><span class="w">
       </span><span class="n">difference_alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">difference_alternative</span><span class="p">,</span><span class="w">
       </span><span class="n">critical_value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">critical_value</span><span class="p">,</span><span class="w">
       </span><span class="n">beta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">beta</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># Number of replications</span><span class="w">
</span><span class="n">replication_count</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1000</span><span class="w">
</span><span class="c1"># Interval of possible values for the sample size</span><span class="w">
</span><span class="n">search_interval</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">10000</span><span class="p">)</span><span class="w">
</span><span class="c1"># Root finding to attain the desired value by varying the sample size</span><span class="w">
</span><span class="n">target</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="n">beta</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">simulate</span><span class="p">(</span><span class="nf">as.integer</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">replication_count</span><span class="p">)</span><span class="o">$</span><span class="n">beta</span><span class="w">
</span><span class="n">sample_size</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.integer</span><span class="p">(</span><span class="n">uniroot</span><span class="p">(</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">search_interval</span><span class="p">)</span><span class="o">$</span><span class="n">root</span><span class="p">)</span></code></pre></figure>

<p>The illustrative figure shown in the solution section displays the sampling
distribution of the test statistic under the null and alternative for the sample
size found by this code snippet.</p>]]></content><author><name>Ivan Ukhov</name><email>ivan.ukhov@gmail.com</email></author><summary type="html"><![CDATA[In order to test a hypothesis, one has to design and execute an adequate experiment. Typically, it is neither feasible nor desirable to involve the whole population. Instead, a relatively small subset of the population is studied, and given the outcome for this small sample, relevant conclusions are drawn with respect to the population. An important question to answer is then, What is the minimal sample size needed for the experiment to succeed? In what follows, we answer this question using solely historical data and computer simulation, without invoking any classical statistical procedures.]]></summary></entry><entry><title type="html">A Bayesian approach to the inference of the net promoter score</title><link href="https://blog.ivanukhov.com/2019/08/19/net-promoter.html" rel="alternate" type="text/html" title="A Bayesian approach to the inference of the net promoter score" /><published>2019-08-19T06:00:00+00:00</published><updated>2019-08-19T06:00:00+00:00</updated><id>https://blog.ivanukhov.com/2019/08/19/net-promoter</id><content type="html" xml:base="https://blog.ivanukhov.com/2019/08/19/net-promoter.html"><![CDATA[<p>The net promoter score is a widely adopted metric for gauging customers’
satisfaction with a product. The popularity of the score is arguably attributed
to the simplicity of measurement and the intuitiveness of interpretation.
Moreover, it is claimed to be correlated with revenue growth, which, ignoring
causality, makes it even more appealing. In this article, we leverage Bayesian
statistics in order to infer the net promoter score for an arbitrary
segmentation of a customer base. The outcome of the inference is a distribution
over all possible values of the score weighted by probabilities, which provides
exhaustive information for the subsequent decision-making.</p>

<p>A bare-bones net promoter survey is composed of only one question: “How likely
are you to recommend us to a friend?” The answer is an integer ranging from 0 to
10 inclusively. If the grade is between 0 and 6 inclusively, the person in
question is said to be a detractor. If it is 7 or 8, the person is said to be a
neutral. Lastly, if it is 9 or 10, the person is deemed a promoter. The net
promoter score itself is then the percentage of promoters minus the percentage
of detractors. The minimum and maximum attainable values of the score are −100
and 100, respectively. In this case, the greater, the better.</p>

<p>As it is usually the case with surveys, a small but representative subset of
customers is reached out to, and the collected responses are then used to draw
conclusions about the target population of customers. Our objective is to
facilitate this last step by estimating the net promoter score given a set of
responses and necessarily quantify and put front and center the uncertainty in
our estimates.</p>

<p>Before we proceed, since a net promoter survey is an observational study, which
is prone to such biases as participation and response biases, great care must be
taken when analyzing the results. In this article, however, we focus on the
inference of the net promoter score under the assumption that the given sample
of responses is representative of the target population.</p>

<h1 id="problem">Problem</h1>

<p>In practice, one is interested to know the net promoter scope for different
subpopulations of customers, such as countries of operation and age groups,
which is the scenario that we shall target. To this end, suppose that there are
\(m\) segments of interest, and each customer belongs to strictly one of them.
The results of a net promoter survey can then be summarized using the following
\(m \times 3\) matrix:</p>

\[y = \left(
\begin{matrix}
d_1 &amp; n_1 &amp; p_1 \\
\vdots &amp; \vdots &amp; \vdots \\
d_i &amp; n_i &amp; p_i \\
\vdots &amp; \vdots &amp; \vdots \\
d_m &amp; n_m &amp; p_m
\end{matrix}
\right)\]

<p>where \(d_i\), \(n_i\), and \(p_i\) denote the number of detractors, neutrals,
and promoters in segment \(i\), respectively. For segment \(i\), the <em>observed</em>
net promoter score can be computed as follows:</p>

\[\hat{s}_i = 100 \times \frac{p_i - d_i}{d_i + n_i + p_i}.\]

<p>However, this observed score is a single scalar value calculated using \(d_i +
n_i + p_i\) data points, which is only a subset of the corresponding
subpopulation. It may or may not correspond well to the actual net promoter
score of that subpopulation. We have no reason to trust it, since the above
estimate alone does not tell us anything about the uncertainty associated with
it. Uncertainty quantification is essential for sound decision-making, which is
what we are after.</p>

<p>Ideally, for each segment, given the observed data, we would like to have a
distribution of all possible values of the score with probabilities attached.
Such a probability distribution would be exhaustive information, from which any
other statistic could be easily derived. Here we tackle the problem by means of
Bayesian inference, which we discuss next.</p>

<h1 id="solution">Solution</h1>

<p>In order to perform Bayesian inference of the net promoter score, we need to
decide on an adequate Bayesian model for the problem at hand. Recall first that
we are interested in inferring scores for several segments. Even though there
might be segment-specific variations in the product, such as special offers in
certain countries, or in customers’ perception of the product, such as
age-related preferences, it is conceptually the same product that the customers
were asked to evaluate. It is then sensible to expect the scores in different
segments to have something in common. With this in mind, we construct a
hierarchical model with parameters shared by the segments.</p>

<p>First, let</p>

\[\theta_i = (\theta_{id}, \theta_{in}, \theta_{ip}) \in \langle 0, 1 \rangle^3\]

<p>be a triplet of parameters corresponding to the proportion of detractors,
neutrals, and promoters in segment \(i\), respectively, with the constraint that
they have to sum up to one. The constraint makes the triplet a simplex, which is
what is emphasized by the angle brackets on the right-hand side. These are the
main parameters we are interested in inferring. If the true value of
\(\theta_i\) was known, the net promoter score would be computed as follows:</p>

\[\hat{s}_i = 100 \times (\theta_{ip} - \theta_{id}).\]

<p>Parameter \(\theta_i\) can also be thought of as a vector of probabilities of
observing one of the three types of customers in segment \(i\), that is,
detractors, neutrals, and promoters. Then the natural model for the observed
data is a multinomial distribution with \(d_i + n_i + p_i\) trials and
probabilities \(\theta_i\):</p>

\[y_i | \theta_i \sim \text{Multinomial}(d_i + n_i + p_i, \theta_i)\]

<p>where \(y_i\) refers to the \(i\)th row of matrix \(y\) introduced earlier. The
family of multinomial distributions is a generalization of the family of
binomial distributions to more than two outcomes.</p>

<p>The above gives a data distribution. In order to complete the modeling part, we
need to decide on a prior probability distribution for \(\theta_i\). Each
\(\theta_i\) is a simplex of probabilities. In such a case, a reasonable choice
is a Dirichlet distribution:</p>

\[\theta_i | \phi \sim \text{Dirichlet}(\phi)\]

<p>where \(\phi = (\phi_d, \phi_n, \phi_p)\) is a vector of strictly positive
parameters. This family of distributions is a generalization of the family of
beta distributions to more than two categories. Note that \(\phi\) is the same
for all segments, which is what enables information sharing. In particular, it
means that the less reliable estimates for segments with fewer observations will
be shrunk toward the more reliable estimates for segments with more
observations. In other words, with this architecture, segments with fewer
observations are able to draw strength from those with more observations.</p>

<p>How about \(\phi\)? This triplet is a characteristic of the product irrespective
of the segment. Its individual components can be utilized in order to encode
one’s prior knowledge about the net promoter score. Specifically, \(\phi_d\),
\(\phi_n\), and \(\phi_p\) could be set to imaginary observations of detractors,
neutrals, and promoters, respectively, reflecting one’s beliefs prior to
conducting the survey. The higher these imaginary counts are, the more certain
one claims to be about the true score. One could certainly set these
hyperparameters to fixed values; however, a more comprehensive solution is to
infer them from the data as well, giving the model more flexibility by making it
hierarchical. In addition, an inspection of \(\phi\) afterward can provide
insights into the overall satisfaction with the product.</p>

<p>We now need to specify a prior, or rather a hyperprior, for \(\phi\). We proceed
under the assumption that we have little knowledge about the true score. Even if
there were surveys in the past, it is still a valid choice, especially when the
product evolves rapidly, rendering prior surveys marginally relevant.</p>

<p>Now, it is more convenient to think in terms of expected values and variances
instead of imaginary counts, which is what \(\phi\) represents. Let us find an
alternative parameterization of the Dirichlet distribution. The expected value
of this distribution is as follows:</p>

\[\mu = (\mu_d, \mu_n, \mu_p) = \frac{\phi}{\phi_d + \phi_n + \phi_p} \in \langle 0, 1 \rangle^3.\]

<p>It can be seen that it is a simplex of proportions of detractors, neutrals, and
promoters of the whole population, which is similar to \(\theta_i\) describing
segment \(i\). Regarding the variance,</p>

\[\sigma^2 = \frac{1}{\phi_d + \phi_n + \phi_p}\]

<p>is considered to capture it sufficiently well. Solving the system of the last
two equations for \(\phi\) yields the following result:</p>

\[\phi = \frac{\mu}{\sigma^2}.\]

<p>The prior for \(\theta_i\) can then be rewritten as follows:</p>

\[\theta_i | \mu, \sigma \sim \text{Dirichlet}\left(\frac{\mu}{\sigma^2}\right).\]

<p>This new parameterization requires two hyperpriors: one is for \(\mu\), and one
is for \(\sigma\). For \(\mu\), a reasonable choice is a uniform distribution
(over a simplex), and for \(\sigma\), a half-Cauchy distribution:</p>

\[\begin{align}
&amp; \mu \sim \text{Uniform}(\langle 0, 1 \rangle^3) \text{ and} \\
&amp; \sigma \sim \text{Half-Cauchy}(0, 1).
\end{align}\]

<p>The two distributions are relatively week, which is intended in order to let the
data speak for themselves. At this point, all parameters have been defined. Of
course, one could go further if the problem at hand had a deeper structure;
however, in this case, it is arguably not justifiable.</p>

<p>The final model is as follows:</p>

\[\begin{align}
y_i | \theta_i &amp; \sim \text{Multinomial}(d_i + n_i + p_i, \theta_i), \\
\theta_i | \mu, \sigma &amp; \sim \text{Dirichlet}(\mu / \sigma^2), \\
\mu &amp; \sim \text{Uniform}(\langle 0, 1 \rangle^3), \text{ and} \\
\sigma &amp; \sim \text{Half-Cauchy}(0, 1).
\end{align}\]

<p>The posterior distribution factorizes as follows:</p>

\[p(\theta_1, \dots, \theta_m, \mu, \sigma | y) \propto
p(y | \theta_1, \dots, \theta_m) \,
p(\theta_1 | \mu, \sigma) \cdots
p(\theta_m | \mu, \sigma) \,
p(\mu) \,
p(\sigma),\]

<p>which relies on the usual assumption of independence given the parameters. One
could make a few simplifications by, for instance, leveraging the conjugacy of
the Dirichlet distribution with respect to the multinomial distribution;
however, it is not needed in practice, as we shall see shortly.</p>

<p>The above posterior distribution is our ultimate goal. It is the one that gives
us a complete picture of what the true net promoter score in each segment might
be given the available evidence, that is, the responses from the survey. All
that is left is to draw a large enough sample from this distribution and start
to summarize and visualize the results.</p>

<p>Unfortunately, as one might probably suspect, drawing samples from the posterior
is not an easy task. It does not correspond to any standard distribution and
hence does not have a readily available random number generator. Fortunately,
the topic is sufficiently mature, and there have been developed techniques for
sampling complex distributions, such as the family of Markov chain Monte Carlo
methods. Unfortunately, the most effective and efficient of these techniques are
notoriously complex themselves, and it might be extremely difficult and tedious
to implement and apply them correctly in practice. Fortunately, the need for
versatile tools for modeling and inference with the focus on the problem at hand
and not on implementation details has been recognized and addressed. Nontrivial
scenarios can be tackled with a surprisingly small amount of effort nowadays,
which we illustrate next.</p>

<h1 id="implementation">Implementation</h1>

<p>In this section, we implement the model using the probabilistic programming
language <a href="https://mc-stan.org/">Stan</a>. Stan is straightforward to integrate into one’s workflow, as it
has interfaces for many general-purpose programming languages, including Python
and R. Here we only highlight the main points of the implementation and leave it
to the curious reader to discover Stan on their own.</p>

<p>The following listing is a complete implementation of the model:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="p">{</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span> <span class="n">m</span><span class="p">;</span> <span class="c1">// The number of segments</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span> <span class="n">n</span><span class="p">;</span> <span class="c1">// The number of categories, which is always three</span>
  <span class="kt">int</span> <span class="n">y</span><span class="p">[</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">];</span> <span class="c1">// The observed counts of detractors, neutrals, and promoters</span>
<span class="p">}</span>

<span class="n">parameters</span> <span class="p">{</span>
  <span class="n">simplex</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="n">mu</span><span class="p">;</span>
  <span class="n">real</span><span class="o">&lt;</span><span class="n">lower</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span> <span class="n">sigma</span><span class="p">;</span>
  <span class="n">simplex</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="n">theta</span><span class="p">[</span><span class="n">m</span><span class="p">];</span>
<span class="p">}</span>

<span class="n">transformed</span> <span class="n">parameters</span> <span class="p">{</span>
  <span class="n">vector</span><span class="o">&lt;</span><span class="n">lower</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="n">phi</span><span class="p">;</span>
  <span class="n">phi</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">/</span> <span class="n">sigma</span><span class="o">^</span><span class="mi">2</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">model</span> <span class="p">{</span>
  <span class="n">mu</span> <span class="o">~</span> <span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
  <span class="n">sigma</span> <span class="o">~</span> <span class="n">cauchy</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">i</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">dirichlet</span><span class="p">(</span><span class="n">phi</span><span class="p">);</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">~</span> <span class="n">multinomial</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>It can be seen that the code is very laconic and follows closely the development
given in the previous section, including the notation. It is worth noting that,
in the model block, we seemingly use unconstrained uniform and Cauchy
distributions; however, the constraints are enforced by the definitions of the
corresponding hyperparameters, <code class="language-plaintext highlighter-rouge">mu</code> and <code class="language-plaintext highlighter-rouge">sigma</code>.</p>

<p>This is practically all that is needed; the rest will be taken care of by Stan,
which is actually a lot of work, including an adequate initialization, an
efficient execution, and necessary diagnostics and quality checks. Under the
hood, the sampling of the posterior in Stan is based on the Hamiltonian Monte
Carlo algorithm and the no-U-turn sampler, which are considered to be the
state-of-the-art.</p>

<p>The output of the sampling procedure is a set of draws from the posterior
distribution, which, again, is exhaustive information about the net promoter
score in the segments of interest. In particular, one can quantify the
uncertainty in and the probability of any statement one makes about the score.
For instance, if a concise summary is needed, one could compute the mean of the
score and accompany it with a high-posterior-density credible interval,
capturing the true value with the desired probability. However, if applicable,
the full distribution should be integrated into the decision-making process.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In this article, we have constructed a hierarchical Bayesian model for inferring
the net promoter score for an arbitrary segmentation of a customer base. The
model features shared parameters, which enable information exchange between the
segments. This allows for a more robust estimation of the score, especially in
the case of segments with few observations. The final output of the inference is
a probability distribution over all possible values of the score in each
segment, which lays a solid foundation for the subsequent decision-making. We
have also seen how seamlessly the model can be implemented in practice using
modern tools for statistical inference, such as Stan.</p>

<p>Lastly, note that the presented model is only one alternative; there are many
other. How would <em>you</em> model the net promoter score? What changes would you
make? Make sure to leave a comment.</p>

<h1 id="references">References</h1>

<ul>
  <li>Andrew Gelman et al., <em><a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian Data Analysis</a></em>, Chapman and Hall/CRC,
2014.</li>
  <li>Andrew Gelman, “<a href="https://statmodeling.stat.columbia.edu/2009/10/21/some_practical/">Some practical questions about prior distributions</a>,”
2009.</li>
</ul>]]></content><author><name>Ivan Ukhov</name><email>ivan.ukhov@gmail.com</email></author><summary type="html"><![CDATA[The net promoter score is a widely adopted metric for gauging customers’ satisfaction with a product. The popularity of the score is arguably attributed to the simplicity of measurement and the intuitiveness of interpretation. Moreover, it is claimed to be correlated with revenue growth, which, ignoring causality, makes it even more appealing. In this article, we leverage Bayesian statistics in order to infer the net promoter score for an arbitrary segmentation of a customer base. The outcome of the inference is a distribution over all possible values of the score weighted by probabilities, which provides exhaustive information for the subsequent decision-making.]]></summary></entry></feed>