---
layout: post
title: Sample size determination using historical data and simulation
date: 2019-12-31
math: true
---

In order to test a hypothesis, one has to design and execute an adequate
experiment. Typically, it is neither feasible nor desirable to involve the whole
population. Instead, a relatively small subset of the population is studied, and
given the outcome for this small sample, conclusions are drawn with respect to
the population. An important question to answer is then, What is the minimal
sample size needed for the experiment to succeed? At this point, one might reach
for a thick book in statistics, match the situation at hand with a statistical
test, agree to the terms and conditions of the test, and proceed to estimating
the sample size using the corresponding formulae either manually or via a
software package. In what follows, we shall answer the above question without
any statistical formalism and any mathematical formulae. The only prerequisites
are the availability of historical data describing the status quo and the
ability to write a few lines of code in a programming language of choice.

Before we proceed, this article is inspired by “[There is only one test!][Allen
Downey]” by Allen Downey and “[Statistics without the agonizing pain][John
Rauser]” by John Rauser.

# Problem

For concreteness, the following scenario is considered. Suppose we run a
business and hypothesize that a certain change in the management of promotion
campaigns will have a positive effect on a specific performance indicator of the
business. In order to test the hypothesis, we decide to perform an A/B test.
There are two groups: a control group and a treatment group. The former will be
exposed to the current promotion policy, while the latter to the new one.

We have a level of statistical significance $$\alpha$$ and a level of practical
significance $$\delta$$ in mind. The former puts a limit on the false positive
rate, and the latter prescribes how large the effect should be for us to care;
anything smaller is of no interest to us. Furthermore, we know what statistical
power we would like the test to have, which constrains the false negative rate.

What should the size of each group be?

# Solution

# Implementation

She sells seashells by the seashore.

```{r, cache = TRUE, echo = TRUE}
library(tidyverse)

set.seed(42)

# Artificial data for illustration
observation_count <- 20000
data <- tibble(value = rlnorm(observation_count))

# Metric of interest
metric <- mean
# Statistical significance
alpha <- 0.05
# Statistical power
power <- 0.8
# Practical significance
delta <- 0.1 * metric(data$value)

simulate <- function(sample_size, replication_count) {
  # Function for drawing a single sample of size sample_size
  run_one <- function() sample(data$value, sample_size, replace = TRUE)
  # Function for drawing replication_count samples of size sample_size
  run_many <- function() replicate(replication_count, { metric(run_one()) })

  # Simulation under the null hypothesis
  control_null <- run_many()
  treatment_null <- run_many()
  delta_null <- treatment_null - control_null

  # Simulation under the alternative hypothesis
  control_alternative <- run_many()
  treatment_alternative <- run_many() + delta
  delta_alternative <- treatment_alternative - control_alternative

  # Computation of the critical value
  critical_value <- quantile(delta_null, 1 - alpha)
  # Computation of the statistical power
  power <- 1 - mean(delta_alternative < critical_value)

  list(delta_null = delta_null,
       delta_alternative = delta_alternative,
       critical_value = critical_value,
       power = power)
}

# Number of replications
replication_count <- 1000
# Interval of possible values for the sample size
search_interval <- c(1, 10000)
# Root finding to attain the desired power by varying the sample size
target <- function(n) power - simulate(as.integer(n), replication_count)$power
sample_size <- as.integer(uniroot(target, interval = search_interval)$root)
```

```{r sampling-distribution}
library(tidyverse)

theme_set(theme_minimal(base_size = 14))

result <- simulate(sample_size, replication_count)
tibble(Null = result$delta_null, Alternative = result$delta_alternative) %>%
  gather(group, value) %>%
  ggplot(aes(value, fill = group)) +
  geom_density(alpha = 0.7, color = NA) +
  geom_vline(xintercept = result$critical_value, linetype = 'dashed') +
  labs(x = 'Difference between the treatment and control groups',
       y = 'Sampling distribution') +
  scale_x_continuous(breaks = seq(-1, 1, by = 0.1)) +
  scale_y_continuous(breaks = seq(0, 10)) +
  scale_fill_manual(values=c('#ef8a62', '#67a9cf')) +
  theme(legend.title = element_blank(), legend.position = c(0.9, 0.9))
```

# Conclusion

She sells seashells by the seashore.

# Acknowledgments

I would like to thank [Aaron Rendahl] for the help with the implementation.

[Aaron Rendahl]: http://users.stat.umn.edu/~rend0020/
[Allen Downey]: http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html
[John Rauser]: https://www.youtube.com/watch?v=5Dnw46eC-0o
