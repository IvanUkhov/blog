<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Sample size determination using historical data and simulation | Good news, everyone!</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Sample size determination using historical data and simulation" />
<meta name="author" content="Ivan Ukhov" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In order to test a hypothesis, one has to design and execute an adequate experiment. Typically, it is neither feasible nor desirable to involve the whole population. Instead, a relatively small subset of the population is studied, and given the outcome for this small sample, relevant conclusions are drawn with respect to the population. An important question to answer is then, What is the minimal sample size needed for the experiment to succeed? In what follows, we answer this question using solely historical data and computer simulation, without invoking any classical statistical procedures." />
<meta property="og:description" content="In order to test a hypothesis, one has to design and execute an adequate experiment. Typically, it is neither feasible nor desirable to involve the whole population. Instead, a relatively small subset of the population is studied, and given the outcome for this small sample, relevant conclusions are drawn with respect to the population. An important question to answer is then, What is the minimal sample size needed for the experiment to succeed? In what follows, we answer this question using solely historical data and computer simulation, without invoking any classical statistical procedures." />
<link rel="canonical" href="https://blog.ivanukhov.com/2019/09/25/bootstrap.html" />
<meta property="og:url" content="https://blog.ivanukhov.com/2019/09/25/bootstrap.html" />
<meta property="og:site_name" content="Good news, everyone!" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-09-25T06:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Sample size determination using historical data and simulation" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Ivan Ukhov"},"dateModified":"2019-09-25T06:00:00+00:00","datePublished":"2019-09-25T06:00:00+00:00","description":"In order to test a hypothesis, one has to design and execute an adequate experiment. Typically, it is neither feasible nor desirable to involve the whole population. Instead, a relatively small subset of the population is studied, and given the outcome for this small sample, relevant conclusions are drawn with respect to the population. An important question to answer is then, What is the minimal sample size needed for the experiment to succeed? In what follows, we answer this question using solely historical data and computer simulation, without invoking any classical statistical procedures.","headline":"Sample size determination using historical data and simulation","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.ivanukhov.com/2019/09/25/bootstrap.html"},"url":"https://blog.ivanukhov.com/2019/09/25/bootstrap.html"}</script>
<!-- End Jekyll SEO tag -->
<meta content="assets/favicon.png" property="og:image">
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="shortcut icon" type="image/png" href="/assets/favicon.png"><link type="application/atom+xml" rel="alternate" href="https://blog.ivanukhov.com/feed.xml" title="Good news, everyone!" /><meta name="keywords" content="R, bootstrap, hypothesis testing, sample size determination, simulation"><script async src="https://www.googletagmanager.com/gtag/js?id=G-43DGEP382H"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-43DGEP382H');
  </script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Good news, everyone!</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Sample size determination using historical data and simulation</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-09-25T06:00:00+00:00" itemprop="datePublished">September 25, 2019
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In order to test a hypothesis, one has to design and execute an adequate
experiment. Typically, it is neither feasible nor desirable to involve the whole
population. Instead, a relatively small subset of the population is studied, and
given the outcome for this small sample, relevant conclusions are drawn with
respect to the population. An important question to answer is then, What is the
minimal sample size needed for the experiment to succeed? In what follows, we
answer this question using solely historical data and computer simulation,
without invoking any classical statistical procedures.</p>

<p>Although, as we shall see, the ideas are straightforward, direct calculations
were impossible to perform before computers. To be able to answer this kind of
questions back then, statisticians developed mathematical theories in order to
approximate the calculations for specific situations. Since nothing else was
possible, these approximations and the various terms and conditions under which
they operate made up a large part of traditional textbooks and courses in
statistics. However, the advent of today’s computing power has enabled one to
estimate required sample sizes in a more direct and intuitive way, with the only
prerequisites being an understanding of statistical inference, the availability
of historical data describing the status quo, and the ability to write a few
lines of code in a programming language.</p>

<h1 id="problem">Problem</h1>

<p>For concreteness, consider the following scenario. We run an online business and
hypothesize that a specific change in promotion campaigns, such as making them
personalized, will have a positive effect on a specific performance metric, such
as the average deposit. In order to investigate if it is the case, we decide to
perform a two-sample test. There are the following two competing hypotheses.</p>

<ul>
  <li>
    <p>The null hypothesis postulates that the change has no effect on the metric.</p>
  </li>
  <li>
    <p>The alternative hypothesis postulates that the change has a positive effect on
the metric.</p>
  </li>
</ul>

<p>There will be two groups: a control group and a treatment group. The former will
be exposed to the current promotion policy, while the latter to the new one.
There are also certain requirements imposed on the test. First, we have a level
of statistical significance \(\alpha\) and a level of practical significance
\(\delta\) in mind. The former puts a limit on the false-positive rate, and the
latter indicates the smallest effect that we still care about; anything smaller
is as good as zero for any practical purpose. In addition, we require the test
to have a prescribed false-negative rate \(\beta\), ensuring that the test has
enough statistical power.</p>

<p>For our purposes, the test is considered well designed if it is capable of
detecting a difference as small as \(\delta\) so that the false-positive and
false-negative rates are controlled to levels \(\alpha\) and \(\beta\),
respectively. Typically, parameters \(\alpha\) and \(\delta\) are held constant,
and the desired false-positive rate \(\beta\) is attained by varying the number
of participants in each group, which we denote by \(n\). Note that we do not
want any of the parameters to be smaller than the prescribed values, as it would
be wasteful.</p>

<p>So what should the sample size be for the test to be well designed?</p>

<h1 id="solution">Solution</h1>

<p>Depending on the distribution of the data and on the chosen metric, one might or
might not be able to find a suitable test among the standard ones, while
ensuring that the test’s assumptions can safely be considered satisfied. More
importantly, a textbook solution might not be the most intuitive one, which, in
particular, might lead to misuse of the test. It is the understanding that
matters.</p>

<p>Here we take a more pragmatic and rather general approach that circumvents the
above concerns. It requires only historical data and basic programming skills.
Despite its simplicity, the method below goes straight to the core of what the
famed statistical tests are doing behind all the math. The approach belongs to
the class of so-called bootstrap techniques and is as follows.</p>

<p>Suppose we have historical data on customers’ behavior under the current
promotion policy, which is commonplace in practice. An important realization is
that this data set represents what we expect to observe in the control group. It
is also what is expected of the treatment group provided that the null
hypothesis is true, that is, when the proposed change has no effect. This
realization enables one to simulate what would happen if each group was limited
to an arbitrary number of participants. Then, by varying this size parameter, it
is possible to find the smallest value that makes the test well designed, that
is, make the test satisfy the requirements on \(\alpha\), \(\beta\), and
\(\delta\), as discussed in the previous section.</p>

<p>This is all. The rest is an elaboration of the above idea.</p>

<p>The simulation entails the following. To begin with, note that what we are
interested in testing is the difference between the performance metric applied
to the treatment group and the same metric applied to the control group, which
is referred to as the test statistic:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Test statistic = Metric(Treatment sample) - Metric(Control sample).
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Treatment sample</code> and <code class="language-plaintext highlighter-rouge">Control sample</code> stand for sets of observations, and
<code class="language-plaintext highlighter-rouge">Metric(Sample)</code> stands for computing the performance metric given such a
sample. For instance, each observation could be the total deposit of a customer,
and the metric could be the average value:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Metric(Sample) = Sum of observations / Number of observations.
</code></pre></div></div>

<p>Note, however, that it is an example; the metric can be arbitrary, and this is a
huge advantage of this approach to sample size determination based on data and
simulation.</p>

<p>Large positive values of the test statistic speak in favor of the treatment
(that is, the new promotion policy in our example), while those that are close
to zero suggest that the treatment is futile.</p>

<p>A sample of \(n\) observations corresponding to the status quo (that is, the
current policy in our example) can be easily obtained by drawing \(n\) data
points with replacement from the historical data:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Sample = Choose random with replacement(Data, N).
</code></pre></div></div>

<p>This expression is used for <code class="language-plaintext highlighter-rouge">Control sample</code> under both the null and alternative
hypotheses. As alluded to earlier, this is also how <code class="language-plaintext highlighter-rouge">Treatment sample</code> is
obtained under the null. Regarding the alternative hypothesis being true, one
has to express the hypothesized outcome as a distribution for the case of the
minimal detectable difference, \(\delta\). The simplest and reasonable solution
is to sample the data again, apply the metric, and then adjust the result to
reflect the alternative hypothesis:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Metric(Choose random with replacement(Data, N)) + Delta.
</code></pre></div></div>

<p>Here, again, one is free to change the logic under the alternative according to
the situation at hand. For instance, instead of an additive effect, one could
simulate a multiplicative one.</p>

<p>The above is a way to simulate a single instance of the experiment under either
the null or alternative hypothesis; the result is a single value for the test
statistic. The next step is to estimate how the test statistic would vary if the
experiment was repeated many times in the two scenarios. This simply means that
the procedure should be repeated multiple times:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Repeat many times {
  Sample 1 = Choose random with replacement(Data, N)
  Sample 2 = Choose random with replacement(Data, N)
  Metric 1 = Metric(Sample 1)
  Metric 2 = Metric(Sample 2)
  Test statistic under null = Metric 1 - Metric 2

  Sample 3 = Choose random with replacement(Data, N)
  Sample 4 = Choose random with replacement(Data, N)
  Metric 3 = Metric(Sample 3) + Delta
  Metric 4 = Metric(Sample 4)
  Test statistic under alternative = Metric 3 - Metric 4
}
</code></pre></div></div>

<p>This yields a collection of values for the test statistic under the null
hypothesis and a collection of values for the test statistic under the
alternative hypothesis. Each one contains realizations from the so-called
sampling distribution in the corresponding scenario. The following figure gives
an illustration:</p>

<p><img src="/assets/images/2019-09-25-bootstrap/sampling-distribution-1.svg" alt="" /></p>

<p>The blue shape is the sampling distribution under the null hypothesis, and the
red one is the sampling distribution under the alternative hypothesis. We shall
come back to this figure shortly.</p>

<p>These two distributions of the test statistic are what we are after, as they
allow one to compute the false-positive rate and eventually choose a sample
size. First, given \(\alpha\), the sampling distribution under the null (the
blue one) is used in order to find a value beyond which the probability mass is
equal to \(\alpha\):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Critical value = Quantile([Test statistic under null], 1 - alpha).
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Quantile</code> computes the quantile specified by the second argument given a set of
observations. This quantity is called the critical value of the test. In the
figure above, it is denoted by a dashed line. When the test statistic falls to
the right of the critical value, we reject the null hypothesis; otherwise, we
fail to reject it. Second, the sampling distribution in the case of the
alternative hypothesis being true (the red one) is used in order to compute the
false-negative rate:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Attained beta = Mean([Test statistic under alternative &lt; Critical value]).
</code></pre></div></div>

<p>It corresponds to the probability mass of the sampling distribution under the
alternative to the left of the critical value. In the figure, it is the red area
to the left of the dashed line.</p>

<p>The final step is to put the above procedure in an optimization loop that
minimizes the distance between the target and attained \(\beta\)’s with respect
to the sample size:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Optimize N until Attained beta is close to Target beta {
  Repeat many times {
    Test statistic under null = ...
    Test statistic under alternative = ...
  }
  Critical value = ...
  Attained beta = ...
}
</code></pre></div></div>

<p>This concludes the calculation of the size that the control and treatment groups
should have in order for the upcoming test in promotion campaigns to be well
designed in terms of the level of statistical significance \(\alpha\), the
false-negative rate \(\beta\), and the level of practical significance
\(\delta\).</p>

<p>An example of how this technique could be implemented in practice can be found
in the appendix.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In this article, we have discussed an approach to sample size determination that
is based on historical data and computer simulation rather than on mathematical
formulae tailored for specific situations. It is general and straightforward to
implement. More importantly, the technique is intuitive, since it directly
follows the narrative of null hypothesis significance testing. It does require
prior knowledge of the key concepts in statistical inference. However, this
knowledge is arguably essential for those who are involved in scientific
experimentation. It constitutes the core of statistical literacy.</p>

<h1 id="acknowledgments">Acknowledgments</h1>

<p>This article was inspired by a blog post authored by <a href="http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html">Allen Downey</a> and a talk
given by <a href="https://www.youtube.com/watch?v=5Dnw46eC-0o">John Rauser</a>. I also would like to thank <a href="http://users.stat.umn.edu/~rend0020/">Aaron Rendahl</a> for his
feedback on the introduction to the method presented here and for his help with
the implementation given in the appendix.</p>

<h1 id="references">References</h1>

<ul>
  <li>Allen Downey, “<a href="http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html">There is only one test!</a>,” 2011.</li>
  <li>John Rauser, “<a href="https://www.youtube.com/watch?v=5Dnw46eC-0o">Statistics without the agonizing pain</a>,” 2014.</li>
  <li>Joseph Lee Rodgers, “<a href="https://doi.org/10.1207/S15327906MBR3404_2">The bootstrap, the jackknife, and the randomization
test: A sampling taxonomy</a>,” Multivariate Behavioral Research,
2010.</li>
</ul>

<h1 id="appendix">Appendix</h1>

<p>The following listing shows an implementation of the bootstrap approach in R:</p>

<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="n">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span><span class="w">

</span><span class="n">set.seed</span><span class="p">(</span><span class="m">42</span><span class="p">)</span><span class="w">

</span><span class="c1"># Artificial data for illustration</span><span class="w">
</span><span class="n">observation_count</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">20000</span><span class="w">
</span><span class="n">data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tibble</span><span class="p">(</span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rlnorm</span><span class="p">(</span><span class="n">observation_count</span><span class="p">))</span><span class="w">

</span><span class="c1"># Performance metric</span><span class="w">
</span><span class="n">metric</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="w">
</span><span class="c1"># Statistical significance</span><span class="w">
</span><span class="n">alpha</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.05</span><span class="w">
</span><span class="c1"># False-negative rate</span><span class="w">
</span><span class="n">beta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.2</span><span class="w">
</span><span class="c1"># Practical significance</span><span class="w">
</span><span class="n">delta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">metric</span><span class="p">(</span><span class="n">data</span><span class="o">$</span><span class="n">value</span><span class="p">)</span><span class="w">

</span><span class="n">simulate</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span><span class="w"> </span><span class="n">replication_count</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="c1"># Function for drawing a single sample of size sample_size</span><span class="w">
  </span><span class="n">run_one</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">()</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">data</span><span class="o">$</span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="n">sample_size</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
  </span><span class="c1"># Function for drawing replication_count samples of size sample_size</span><span class="w">
  </span><span class="n">run_many</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">()</span><span class="w"> </span><span class="n">replicate</span><span class="p">(</span><span class="n">replication_count</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">metric</span><span class="p">(</span><span class="n">run_one</span><span class="p">())</span><span class="w"> </span><span class="p">})</span><span class="w">

  </span><span class="c1"># Simulation under the null hypothesis</span><span class="w">
  </span><span class="n">control_null</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">run_many</span><span class="p">()</span><span class="w">
  </span><span class="n">treatment_null</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">run_many</span><span class="p">()</span><span class="w">
  </span><span class="n">difference_null</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">treatment_null</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">control_null</span><span class="w">

  </span><span class="c1"># Simulation under the alternative hypothesis</span><span class="w">
  </span><span class="n">control_alternative</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">run_many</span><span class="p">()</span><span class="w">
  </span><span class="n">treatment_alternative</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">run_many</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">delta</span><span class="w">
  </span><span class="n">difference_alternative</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">treatment_alternative</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">control_alternative</span><span class="w">

  </span><span class="c1"># Computation of the critical value</span><span class="w">
  </span><span class="n">critical_value</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">quantile</span><span class="p">(</span><span class="n">difference_null</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w">
  </span><span class="c1"># Computation of the false-negative rate</span><span class="w">
  </span><span class="n">beta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">difference_alternative</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">critical_value</span><span class="p">)</span><span class="w">

  </span><span class="nf">list</span><span class="p">(</span><span class="n">difference_null</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">difference_null</span><span class="p">,</span><span class="w">
       </span><span class="n">difference_alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">difference_alternative</span><span class="p">,</span><span class="w">
       </span><span class="n">critical_value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">critical_value</span><span class="p">,</span><span class="w">
       </span><span class="n">beta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">beta</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># Number of replications</span><span class="w">
</span><span class="n">replication_count</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1000</span><span class="w">
</span><span class="c1"># Interval of possible values for the sample size</span><span class="w">
</span><span class="n">search_interval</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">10000</span><span class="p">)</span><span class="w">
</span><span class="c1"># Root finding to attain the desired value by varying the sample size</span><span class="w">
</span><span class="n">target</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="n">beta</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">simulate</span><span class="p">(</span><span class="nf">as.integer</span><span class="p">(</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">replication_count</span><span class="p">)</span><span class="o">$</span><span class="n">beta</span><span class="w">
</span><span class="n">sample_size</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.integer</span><span class="p">(</span><span class="n">uniroot</span><span class="p">(</span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">search_interval</span><span class="p">)</span><span class="o">$</span><span class="n">root</span><span class="p">)</span></code></pre></figure>

<p>The illustrative figure shown in the solution section displays the sampling
distribution of the test statistic under the null and alternative for the sample
size found by this code snippet.</p>


  </div><div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'https://blog.ivanukhov.com/2019/09/25/bootstrap.html';
      this.page.identifier = 'https://blog.ivanukhov.com/2019/09/25/bootstrap.html';
    };

    (function() {
      var d = document, s = d.createElement('script');

      s.src = 'https://good-news-everyone.disqus.com/embed.js';

      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript><a class="u-url" href="/2019/09/25/bootstrap.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Good news, everyone!</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Ivan Ukhov</li><li><a class="u-email" href="mailto:ivan.ukhov@gmail.com">ivan.ukhov@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/IvanUkhov"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">IvanUkhov</span></a></li><li><a href="https://www.linkedin.com/in/IvanUkhov"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">IvanUkhov</span></a></li><li><a href="https://www.twitter.com/IvanUkhov"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">IvanUkhov</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Solving problems that a software engineer might encounter in practice—or
invent to sharpen their skills in leisure time
</p>
      </div>
    </div>

  </div>

</footer>
<script type="text/javascript">
      function anchor() {
        for (let header of document.querySelectorAll('h1[id], h2[id]')) {
          header.innerHTML += ` <a href="#${header.id}" aria-hidden="true">#</a>`;
        }
      }
      function theme() {
        document.body.className = 'theme-' + (Math.floor(Math.random() * 6) + 1);
      }
      window.addEventListener('load', anchor);
      window.addEventListener('load', theme);
    </script>
  </body>
</html>
